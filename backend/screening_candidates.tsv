candidate_id	candidate_name	email	current_status	current_title	total_years_experience	resume_text
a16f25a2-84e5-4b4a-8b6d-ccd207bf1ebd	Alexanderlemkin Unknown	alexanderlemkin6@gmail.com	Screening	Lead Software Engineer	10	Alexander Lemkin\nLead Software Engineer\n\tPhone: (917) 352-8320\nEmail: alexanderlemkin6@gmail.com\nAddress: Richmond, VA 23222\nLinkedIn: /in/alexander-l-63663749\n\n\tResults-driven Lead Software Engineer with over 11 years of extensive experience in developing enterprise-grade applications using .NET, C#, SQL Server, and Azure technologies. Proven track record in architecting cloud-native solutions, executing successful Azure migration strategies, and implementing AI-driven development workflows. Skilled in mentoring junior engineers, driving the adoption of best practices, and enhancing system performance through innovative cloud solutions and automated testing.\n\n\tRELEVANT SKILLS\n\n\t.NET, C#, SQL Server, Azure, Machine Learning, Cloud Migration, Generative AI, Automated Testing, Database Proficiency, Database Design, Data Migration, Containerization, Cloud Native Design, Application Deployment, AI, Agile Development, APIs, Microservices, Azure DevOps, CI/CD, TDD, Automated Test Frameworks, Azure App Services, Cosmos DB, AKS, GitHub Copilot, Claude, Self-Healing Mechanisms, Intelligent Testing, Docker, Kubernetes, RESTful Services, Web APIs, Cloud Security, DevOps Practices, Software System Architecture, Unit Testing, Code Refactoring, Application Architecture\n\n\tPROFESSIONAL EXPERIENCE\n\n\tCarMax / Remote\nLead Software Engineer\n\tApril 2021‚ÄìPresent\n\n\t¬∑ Led the design, development, and deployment of cloud-native applications using .NET and C#, enhancing performance.\n¬∑ Architected and executed comprehensive Azure migration strategies, successfully modernizing legacy systems and reducing operational costs.\n¬∑ Utilized SQL Server for efficient database management, ensuring optimal performance and scalability for enterprise applications.\n¬∑ Developed and integrated AKS for container orchestration, streamlining application deployment and management processes.\n¬∑ Implemented intelligent automated testing frameworks that predict bugs and facilitate self-healing, improving code reliability.\n¬∑ Collaborated with cross-functional teams to integrate generative AI tools, improving user experience and workflow efficiency.\n¬∑ Mentored a team of junior engineers, promoting best practices in cloud engineering and enhancing team capabilities through hands-on guidance with tools like GitHub Copilot.\n¬∑ Leveraged Azure App Services and Cosmos DB to optimize application services and data handling, boosting data retrieval speeds.\n¬∑ Pair programmed with AI tools, such as Claude, to accelerate coding processes and improve code quality across development teams.\n¬∑ Developed RESTful APIs for seamless integration between front-end applications and back-end services, ensuring high availability and performance.\n¬∑ Achieved a seamless CI/CD pipeline using Azure DevOps, reducing time-to-deployment from weeks to days.\n¬∑ Implemented microservices architecture to facilitate easier scaling, maintenance, and deployment of applications.\n¬∑ Enhanced deployment security through compliance with cloud security best practices and DevOps methodologies.\n¬∑ Established a comprehensive system for automated testing to ensure continuous integration during the development cycle, reducing regression bugs.\n¬∑ Conducted code reviews and refactorings to maintain code quality and adherence to company standards, significantly decreasing technical debt.\n¬∑ Utilized Docker to containerize applications for effective resource management and improved deployment efficiency.\n\n\tNetchex / Remote\nSenior Software Engineer\n\tNovember 2018‚ÄìApril 2021\n\t\n\n\t¬∑ Designed and implemented efficient, scalable databases using SQL Server for enterprise applications, improving data processing speed and accuracy.\n¬∑ Participated in Agile development processes, collaborating effectively within cross-functional teams to deliver on project milestones.\n¬∑ Leveraged TDD principles to enhance software quality, creating rigorous test cases that ensure full coverage for new features and enhancements.\n¬∑ Integrated APIs for third-party services, significantly improving application functionality and customer satisfaction ratings.\n¬∑ Coordinated cloud migration initiatives, ensuring seamless transitions of existing applications to modern infrastructures and reducing latency issues.\n¬∑ Utilized Azure DevOps for managing project repositories, build pipelines, and continuous delivery workflows, enhancing team productivity.\n¬∑ Conducted regular performance assessments and optimization strategies for database queries, leading to a 20% increase in efficiency.\n¬∑ Implemented automation scripts for data migration processes, effectively reducing manual overhead and errors during transition periods.\n\t\n\n\tAuto Data Direct Inc. / Tallahassee, FL\nFull Stack Developer\n\tNovember 2016‚ÄìNovember 2018\n\n\t¬∑ Developed software solutions using .NET and C# that adhere to best practices in software design and architecture, ensuring maintainability and scalability.\n¬∑ Collaborated in the design of system architecture for new projects, using microservices and containerization techniques to improve deployment reliability.\n¬∑ Managed comprehensive documentation for software development processes and architectural designs, facilitating better communication among stakeholders.\n¬∑ Wrote production-ready code with a focus on performance optimization and security within the financial services domain.\n¬∑ Hold regular training sessions on Agile methodologies and best practices in software engineering for team members to enhance product delivery capabilities.\n¬∑ Executed database deployments and migrations into Azure, overcoming challenges of legacy system integration effectively.\n¬∑ Utilized CI/CD tools to streamline release processes, greatly reducing the time required for deployment cycles.\n¬∑ Trained junior developers on automated testing frameworks and industry-standard practices for software quality assurance.\n\n\tAderant / Tallahassee, FL\nSoftware Engineer\n\tJuly 2015‚ÄìNovember 2016\n\n\t¬∑ Provided technical leadership as a senior developer in transitioning projects to a remote working infrastructure, maintaining productivity amid evolving work environments.\n¬∑ Engaged in software system performance evaluations and optimizations for legacy applications, significantly extending their life cycle and usability.\n¬∑ Pioneered initiatives to integrate AI solutions into application development processes, enhancing capabilities of existing systems for better user engagement.\n¬∑ Collaborated effectively with cloud architects to define strategies for optimally utilizing Azure features in existing projects.\n¬∑ Trained teams on using container orchestration technologies like Kubernetes to manage application deployments efficiently in production environments.\n¬∑ Developed automated scripts for performance tuning and monitoring of applications hosted on Azure, leading to improved operational visibility.\n¬∑ Explored advancements in AI/ML applications to enhance workflows and provide innovative solutions to complex business problems.\n\n\tEDUCATION\n\n\tUniversity of Central Florida / Orlando, FL\nB.S. in Biology & Computer Science Interdisciplinary Studies\n\tJuly 2015
edb5a82f-03d2-45e8-be64-d756f358cc96	Bbober Eng	bbober.eng@gmail.com	Screening	Senior Software Architect	20	Brian Bober\nPrincipal Software Engineer / Software Architect\nAcworth, GA 30101 ‚Ä¢ (470) 249-1334 ‚Ä¢ bbober.eng@gmail.com ‚Ä¢\nhttps://www.linkedin.com/in/brian-j-bober-6a81672\n\nGoal\n\nUse experience as Senior Principal Engineer and Senior Software Architect to improve business\nand technology along with solving challenging problems. Enjoys a mix of mentorship, developing\ntechnical requirements\n\nCurrent focus verticals are B2C, marketplace, and fintech but open to other interesting verticals.\n\nI‚Äôm a team player that also routinely comes up with unique practical ideas. I‚Äôm looking primarily\nfor 100% remote.\n\nPatents\n\n‚óè Distributing Media Content via Media Channels Based on Associated Content Being\nProvided Over Other Media Channels  (US20170318321A1). Status: Granted\n\nCertifications\n‚óè Amazon Web Services Certified Developer - Associate. (Expired May 2022)\n\n‚óã Credential ID RM0D8KYCDMQE1B92\n\nTechnical Skills\n\n‚óè 24 years professional experience in software engineering\n‚óè 10+ years in each of C# and Java\n‚óè Architecture: Patterns, domains, data best practices, sequence and domain diagrams,\n\nsecurity, foundational code elements, contracts, microservice architecture\n‚óè Back-end:  Java, Spring MVC + Spring Boot, C# .Net and Dotnet Core, Node.js w/\n\nExpress, GoLang,  gRPC, SOAP, REST,  Swagger, GraphQL,  Kubernetes\n‚óè Cloud: General best practices. AWS: EKS, S3, Lambda, Redshift, Kinesis, Firehose, RDS,\n\nEC2, Parameter Store; Azure: AKS,  Azure SQL, Blob Storage, Event Hub, App\nConfiguration, Azure B2C, Azure Functions\n\n‚óè Performance and monitoring: k6.io, JMeter; Flame charts, Datadog, high availability,\nPrometheus/Grafana, Newrelic; Performance improvement methods; SQL optimization\n\n‚óè Tools: Git and f-e Git tools; ALM: Jira, Azure Devops; Terraform; Helm\n‚óè Automated testing: CI/CD, Integration vs unit testing best practices; Cucumber, Spock,\n\nMSTest, JUnit, NUnit, Jasmine\n‚óè Db/ORM: Hibernate ORM, SQL, Mysql/MariaDB, PostgreSQL, Mongodb, Mongoose,\n\nDacpac, Flyway\n‚óè Front-end: Angular + Typescript, Bootstrap, JQuery, HTML5, Javascript, DOM, CSS,\n\nXML, YAML, JSON, XSLT, Velocity templates\n‚óè Team leadership: Mentorship, continuous integration, greenfield vs maintenance\n\ndevelopment, blue-green and day-time deployment concepts\n‚óè Message queues and data queues: RabbitMQ, ActiveMQ, Kafka, SignalR, Toastr,\n\nwebsocket\n\n\n\nRelated Experience\n\nHive Financial Systems - Senior Software Architect May 2023 - Present\nFintech - Loans\n\n‚óè Design/requirements and leading implementation for C# ASP.Net Core 8+ w/ SQL on\nAzure Cloud\n\n‚óè Currently leading migration applications to Kubernetes including a single-tenant\npayments API to a multi-tenant API on containerized Kubernetes application on Azure\nKubernetes (AKS)\n\n‚óè Has lead charge towards improving technical performance tuning of API, reduced cost,\nincreased speed and matching throttling of vendor requests with their capacity\n\n‚óè Lead company-wide architecture committee, enforcing development standards and\nsignificant refactoring and modernization of code; a lead in platform architecture\n\n‚óè Participation in companywide leadership activities and strategic meetings\n‚óè Mentorship for junior to senior software engineers\n‚óè Use of AI productivity tools for development\n\nMatrix Solutions - Principal Software Engineer Feb 2022 - January 2023\nTelevision Advertising Technology\n\n‚óè Technical lead for C#of approximately 10 back-end engineers and two front-end\nengineers, along with oversight for on-shore team\n\n‚óè Hands-on development for app migration from C# ASP.Net 4 and 2 Core to C# ASP.Net\n7 on Azure Kubernetes (AKS) for both greenfield development and maintenance\n\n‚óè Databsse - SQL and Influxdb\n‚óè Lead performance testing using K6 and Datadog with a custom Azure B2C Oauth\n\nautomation flow\n‚óè Handled senior reports from devops for cloud infrastructure, Terraform and Helm;\n\nModified deployments (was not individual contributor)\n‚óè Technical Design and architecture along with feedback for business requirements\n‚óè Refinement of user stories and initial estimates\n‚óè Debugging, dashboarding, monitoring, RCA and performance tuning\n‚óè Long-term strategy and tech council member\n‚óè Azure cloud platform w/ Kubernetes\n\nHudsonMX - Principal Software Engineer Apr 2020 - January 2022\nAdtech management and billing platform\n\n‚óè Java and Spring boot with Postgres database; 30-50% time writing code\n‚óè Lead two teams of 4-5 engineers each plus QA and automation engineers for financial\n\nbilling and order line management; worked closely with product and project managers\nand some junior executives along with mentorship of team members\n\n‚óè Technical Design and architecture along with requirements gathering for greenfield\ndevelopment and maintenance of  multiple services and interfaces between services and\ndiagramming\n\n‚óè Involvement in architecture committees for company-wide technical standards and\ndevelopment processes\n\n‚óè Optimization of existing services and performance troubleshooting to meet KPI\nrequirements\n\n2\n\n\n\nSalonhome - Co-Founder and Consulting CTO Part time 2017 - Present\nMarketplace B2C Mobile app and Booking Platform\n\nCTO building a world-class beauty-industry mobile marketplace application, including:\n‚óè Planning with CEO, and long-term technical vision and decisions\n‚óè Managing development team on-shore, near-shore and off-shore\n‚óè App build-out went through PoC, MVP and is now about to enter a major marketing push\n‚óè ~ $600k in total investment, largely bootstrapped, handled periodic capital challenges\n\ngracefully while technical development went forward\n‚óè Undergoing major marketing ramp for 2025 and prepping for significant volume growth\n\nVidea LLC (Cox Enterprises) - Software Engineer III Feb 2017 - Apr 2020\nTelevision ad tech\n\n‚óè Developed and maintained C# .Net and Angular web applications, order and billing\nsystem, and related gRPC microservices and integrations.\n\n‚óè Also involved with architectural design, regular optimizations, and greenfield\ndevelopment.\n\n‚óè Cloud applications included AWS and Kubernetes.\n\nSoltech - Senior Software Engineer Sep 2016 - Feb 2017\nConsulting firm\n\n‚óè Worked on smart grid management and analytics platform\nAWS Lambda, Redshift, Kinesis, Firehose, RDS\n\n‚óè High-throughput scaled  system for monitoring and controlling equipment on Node.js w/\nExpress and Typescript; Front-end in AngularJS\n\nRed Panda Platform/Wahwah Networks - VP R&D Sep 2014-Sep 2016\n\nWeb Adtech\n\n‚óè Reported to COO\nSoftware engineering focused on greenfield development for startup. Java w/ Spring\nMVC, Angular and AWS utilizing the latest best-practices.\n\n‚óè Also handled various management responsibilities including various office management\nand planning responsibilities to support out-of-state office for San Francisco business\n\n‚óè Technical liaison for potential acquisitions\n\n3\n\n\n\nSizmek (became Amazon Advertising) Aug 2005-Sep 2014\nSame employment period that went through various acquisitions of Sizmek, DG Fastchannel,\nMediamind, Eyewonder. Began as mid-level software engineer, and ultimately promoted to the\nfollowing two positions at different stages:\n\nSenior Software Architect - Sizmek future technology incubator\n‚óè C#, Angular, Java Spring development. Tech lead in convergent TV/web technologies\n\nincluding smart TV and other incubator technologies.\n\nDirector of R&D - Eyewonder\nReported to CIO; Promoted from Senior Software Engineer\n\n‚óè Team lead and architect\n‚óè Managed up to 20 employees, including 5 off-shore, and handled approximately $2\n\nmillion of budget\n‚óè Assisted a tech startup subsidiary get founded. Including traveling abroad. Helped\n\nmaintain technical partnerships\n\nEducation\n\nRensselaer Polytechnic Institute, Troy NY\n‚óè Completed BS in Computer Science. GPA: 3.13\n\nOther Experience and awards\n\nAttained Eagle Rank in Boy Scouts of America July 1999\n\n4
88d994a8-75f9-4028-8f22-5d0ce5306893	Chandlerronharris Unknown	chandlerronharris23@gmail.com	Screening	Senior Full Stack,NET Developer	9	Chandler Harris \nSenior Full Stack .NET Developer  \n\nClearwater, FL | (743) 330-2166 | chandlerronharris23@gmail.com  \n\n \n\n \n\nüî• Summary \n\nSenior Full-Stack .NET Engineer with 11+ years of experience designing and delivering scalable, high-performance \nsoftware solutions across e-commerce, telecommunications, and tech sectors. Expertise in full-stack development, \nmicroservices, cloud-native architectures, and system integration. Proven in mentoring engineers, modernizing legacy \nplatforms, and driving innovation via Agile/DevOps. Skilled in C#, ASP.NET Core, Azure, AWS, Kubernetes, React, \nTerraform, Kafka, and CI/CD pipelines. \n\n \n\nüõ† Tech Stack & Expertise \n‚úÖLanguages: C# (.NET Core 3.1‚Äì6.0), TypeScript, C++, F# \n\n‚úÖFrameworks & Libraries: ASP.NET Core (MVC, Web API, Identity), Entity Framework Core, Dapper, Blazor, Node.js, \n\nExpress.js, React, AngularJS \n\n‚úÖWeb & Services: REST, SOAP, gRPC, GraphQL, XML, JSON, HTML5, CSS3, JavaScript, jQuery, Ajax \n\n‚úÖCloud & DevOps: Azure (App Service, Azure Functions, Azure SQL, Azure AD), AWS (EC2, S3, Lambda, RDS, IAM), \n\nKubernetes, Docker, Terraform, Jenkins, Azure DevOps Pipelines, AWS CodePipeline \n\n‚úÖDatabases & Caching: SQL Server, Oracle, MySQL, MongoDB, Cassandra, DynamoDB, Redis \n\n‚úÖMessaging & Event Processing: Kafka, Azure Service Bus, RabbitMQ, Apache Camel \n\n‚úÖTesting & QA: xUnit, NUnit, Moq, Selenium, Cypress, Jest, REST Assured \n\n‚úÖTools & Methodologies: Git, Subversion (SVN), NuGet, Maven (Jenkins), SonarQube, Agile, Scrum, TDD, CI/CD \n\n‚úÖFront-End Tools: Material-UI, Bootstrap, Tailwind CSS \n\n‚úÖOS: Windows, Linux, macOS, Unix \n\n \n\n \n\nüéì Education \n\nB.S. in Computer Science \nUniversity of California | 2010 ‚Äì 2014 \n\n  \n\nmailto:chandlerronharris23@gmail.com\n\n\nProfessional Experience \nCommerceSpring Consulting | Senior Full Stack .NET Developer  Aug 2022 ‚Äì May 2025 \n\nConsulted for mid-market and growing e-commerce clients, architecting and building full-stack C#/ASP.NET Core \n\nsolutions deployed to both AWS and Azure, which improved scalability, performance, and conversion rates. \n\nÔÇ∑ Backend Development & APIs: \n\n‚Äì Design and maintain ASP.NET Core microservices (C# 10, Entity Framework Core) powering product catalog, \n\ncart, checkout, and order flows for five e-commerce clients‚Äîprocessing $3 M in monthly transactions at \n\n99.9% uptime. \n\n‚Äì Integrate Stripe and Braintree payment gateways, Sage and TradeGecko inventory systems, and ShipStation \n\nshipping providers via secure RESTful APIs‚Äîshortening third-party integration time by 30%. \n\n‚Äì Optimize SQL Server schemas (hosted on AWS RDS & Azure SQL) and Redis schemas (ElastiCache & Azure \n\nCache for Redis) to support peak load‚Äîreducing average order processing time from 4 s to 2.2 s (45% \n\nimprovement) during high-traffic events. \n\nÔÇ∑ Cloud Infrastructure & DevOps: \n\n‚Äì Automate dual-cloud provisioning with Azure Resource Manager (App Service, Azure SQL, Azure Cache) and \n\nAWS CloudFormation (VPC, ECS Fargate, RDS SQL Server, ElastiCache) with multi-AZ redundancy and \n\nautomated backups. \n\n‚Äì Containerize services with Docker; create Azure DevOps and GitHub Actions pipelines to run dotnet builds, \n\nxUnit tests, and deploy to Azure AKS & AWS EKS using blue/green deployments. \n\n‚Äì Build and maintain Azure Monitor alerts and Grafana dashboards for Azure (App Service, AKS, SQL) \n\nalongside AWS CloudWatch for EC2, EKS, and RDS‚Äîtracking .NET CLR memory, GC pause times, and \n\napplication health to enable proactive capacity planning. \n\nÔÇ∑ Frontend Engineering: \n\n‚Äì Lead implementation of a headless storefront using React 18 (Next.js) and Redux Toolkit‚Äîenabling \n\ndynamic product recommendations, personalized pricing, and real-time inventory updates. \n\n‚Äì Integrate React components with ASP.NET Core Identity‚Äôs JWT endpoints (via Axios) and Azure AD B2C for \n\nsingle sign-on across client portals. \n\nÔÇ∑ Testing & QA: \n\n‚Äì Establish a testing framework with xUnit and Moq for backend services; author REST Assured integration \n\ntests to validate API contracts in both AWS and Azure staging environments. \n\n‚Äì Build Jest and React Testing Library unit tests for all frontend components; develop Cypress end-to-end \n\ntests covering checkout, payment flows (Stripe, Braintree), and order confirmation. \n\nÔÇ∑ Team Leadership & Agile: \n\n‚Äì Partner with product owners, UX designers, QA engineers, and DevOps to run 1-week Agile sprints‚Äî\n\nensuring clear user stories, acceptance criteria, and on-time delivery. \n\n‚Äì Conduct architecture reviews, code walkthroughs, and performance-tuning workshops‚Äîenabling client \n\nteams to adopt best practices in C#/ASP.NET Core, Docker, Kubernetes (AKS & EKS), and React. \n\n  \n\n\n\nLendflow | Senior Full Stack .NET Developer       Jun 2018 ‚Äì Jun 2022 \n\nDrove the design and implementation of an embedded-credit platform in .Net, enabling SaaS partners to embed \n\nlending capabilities and scaling loan volume 5√ó over five quarters. \n\nÔÇ∑ Backend Development & APIs: \n\n‚Äì Built and maintained ASP.NET Core microservices (C# 8, ASP.NET Core 3.1, MassTransit) to handle borrower \n\nonboarding, credit decisioning, and loan servicing workflows. \n\n‚Äì Exposed secure REST/JSON endpoints documented with Swagger/OpenAPI for partner integrations; \n\nenforced OAuth2/JWT authentication via ASP.NET Core Identity and Azure AD B2C integration for enterprise \n\nclients. \n\n‚Äì Developed Kafka producers and consumers to stream loan application events to a real-time risk engine, \n\nreducing end-to-end processing latency by 40%. \n\nÔÇ∑ Data Engineering & Optimization: \n\n‚Äì Collaborated with data scientists to integrate Python-based ML models (TensorFlow, scikit-learn) into .NET \n\nmicroservices via HTTP endpoints‚Äîdeployed in both AWS (EC2, SageMaker endpoints) and Azure (Azure ML) \n\nenvironments‚Äîimproving default-prediction accuracy from 70% to 87% over six months. \n\n‚Äì Designed normalized PostgreSQL schemas (hosted on AWS RDS and Azure Database for PostgreSQL) and \n\noptimized Redis caching strategies (ElastiCache & Azure Cache) for rapid credit lookups‚Äîreducing query \n\nresponse time from 150 ms to 80 ms under peak load. \n\nÔÇ∑ Cloud Infrastructure & DevOps: \n\n‚Äì Automated AWS provisioning (VPC, EC2, RDS SQL Server, ElastiCache) and Azure provisioning (Resource \n\nGroups, Virtual Machines, Azure SQL, Azure Cache) with Terraform modules. \n\n‚Äì Maintained Kubernetes clusters on AWS EKS and Azure AKS for orchestrating stateless microservices; \n\nconfigured Horizontal Pod Autoscalers to respond to traffic spikes. \n\n‚Äì Containerized services with Docker and managed Helm chart deployments for zero-downtime upgrades; \n\ninstituted readiness and liveness probes to ensure high availability. \n\n‚Äì Established Azure DevOps and GitLab CI pipelines that build dotnet artifacts, run xUnit tests, perform \n\nsecurity scans (SonarQube, Snyk), and deploy to Azure AKS and AWS EKS‚Äîreducing MTTR by 40%. \n\nÔÇ∑ Frontend Engineering: \n\n‚Äì Collaborated with UX designers to build a React 16+ (TypeScript, Redux) component library for partner \n\ndashboards‚Äîvisualizing loan funnels, borrower profiles, and credit analytics. \n\n‚Äì Integrated WebSocket streams (SignalR) hosted on Azure App Service Web Apps (ASP.NET Core) to push \n\nreal-time application status updates‚Äîimproving partner transparency and reducing support tickets by 20%. \n\nÔÇ∑ Testing & QA: \n\n‚Äì Wrote comprehensive xUnit and Moq unit tests for all new backend modules; built Postman/Newman \n\ncollections for automated end-to-end API regression testing across AWS and Azure environments. \n\n‚Äì Employed Cypress for frontend end-to-end testing (loan application, dashboard flows), catching 60% more \n\nregressions before production. \n\nÔÇ∑ Team Leadership & Agile: \n\n‚Äì Led a squad of six engineers in 2-week Scrum sprints‚Äîcoordinating backlog grooming, sprint planning, and \n\nretrospectives to consistently meet sprint goals. \n\n‚Äì Mentored junior and mid-level engineers through regular design reviews, coding workshops, and brown-\n\nbag sessions on ASP.NET Core best practices and microservice patterns. \n\n  \n\n\n\nClearsense | Full Stack .NET Developer      Aug 2015 ‚Äì May 2018 \n\nLed end-to-end development of a HIPAA-compliant telehealth system, enabling secure patient monitoring and \n\nclinician collaboration across multiple Florida health networks. \n\nÔÇ∑ Backend Development & APIs: \n\n‚Äì Architected and developed ASP.NET Core microservices (C# 7.0, ASP.NET Core 2.1, Entity Framework Core) \n\nto manage patient records, appointments, and device telemetry. \n\n‚Äì Designed normalized SQL Server schemas and optimized Entity Framework Core queries for high-volume \n\ndata ingestion from Bluetooth-enabled medical devices. \n\n‚Äì Integrated Apache Kafka for asynchronous processing of incoming patient vitals, ensuring reliable data \n\npipelines and alert generation. \n\nÔÇ∑ Cloud Infrastructure & DevOps: \n\n‚Äì Provisioned AWS resources (EC2, RDS SQL Server, S3, Lambda, IAM) and Azure equivalents (App Service, \n\nAzure SQL Database, Blob Storage, Azure Functions, Azure AD) using Terraform to maintain reproducible, \n\nsecure environments. \n\n‚Äì Containerized services with Docker and deployed to AWS ECS (Fargate) and Azure Kubernetes Service \n\n(AKS), leveraging Helm charts for consistent orchestration. \n\n‚Äì Built Jenkins CI/CD pipelines for AWS deployments and Azure DevOps Pipelines for Azure environments‚Äî\n\nrunning unit tests, SonarQube scans, and blue/green deployments‚Äîcutting release lead time by 50%. \n\nÔÇ∑ Frontend Engineering: \n\n‚Äì Developed a responsive clinician portal using React 15 (ES6, Redux) to visualize real-time patient vitals, \n\nschedule telehealth appointments, and send secure messages‚Äîboosting patient engagement by 30%. \n\n‚Äì Implemented JWT-based authentication flows (ASP.NET Core Identity on backend, Axios + React Context on \n\nfrontend) and integrated with Azure AD B2C to support single-sign-on and role-based access for clinicians and \n\npatients. \n\nÔÇ∑ Security & Compliance: \n\n‚Äì Championed end-to-end encryption of PHI (TLS in transit, AES-256 at rest) across both AWS and Azure \n\nclouds to meet HIPAA requirements; collaborated with external auditors to pass annual compliance reviews. \n\n‚Äì Enforced CSRF protection and granular IAM roles (AWS IAM & Azure RBAC) to lock down sensitive data \n\nstores and APIs. \n\nÔÇ∑ Testing & QA: \n\n‚Äì Wrote xUnit and Moq tests covering 85% of backend code; created integration tests with ASP.NET Core \n\nTestServer to validate critical API endpoints in both cloud environments. \n\n‚Äì Built Selenium WebDriver end-to-end tests to simulate patient onboarding, device pairing, and clinician \n\nworkflows prior to each release. \n\nÔÇ∑ Team Leadership & Agile: \n\n‚Äì Actively participated in Scrum ceremonies (daily standups, sprint planning, retrospectives) and refined \n\nbacklog items to align features with evolving business priorities. \n\n‚Äì Mentored two junior .NET developers through pair programming and code reviews, improving code \n\nconsistency and onboarding speed by 30%.
51cb2edc-69e9-4072-9ce0-64e203fc0b50	Chaseson Unknown	chaseson94@gmail.com	Screening	Senior Software Engineer	15	Chase Roberson\nSenior Software Engineer\n\tchaseson94@gmail.com\n\t659-234-1633\n\tBirmingham, AL 35243\n\n\nSUMMARY\nAccomplished Senior Software Engineer with 10 years of experience in full-stack development, cloud-native applications, and AI-enhanced software development. Expert in .NET, C#, SQL Server, and Azure, with proven experience leading engineering initiatives, architecting scalable solutions, and mentoring junior engineers. Skilled in implementing AI-driven testing frameworks, CI/CD pipelines, and modern cloud migration strategies in fast-paced fintech environments\nSKILLS\n¬∑ Languages & Frameworks: .NET, C#, JavaScript, Python\n¬∑ Databases: SQL Server, Cosmos DB, Postgres\n¬∑ Cloud & DevOps: Azure (AKS, App Services, Functions), Azure DevOps, CI/CD pipelines\n¬∑ Tools & AI: GitHub Copilot, Claude, AI-assisted development tools, automated testing frameworks, TDD\n¬∑ Other: Microservices architecture, containerization, cloud-native application design, agile development, mentoring\nPROFESSIONAL EXPERIENCE\nSenior Software Engineer\nVention | New York, NY (remote)\t\t\t\t\t\t\t\tJan 2021 ‚Äì Present\n¬∑ Led the design, development, and deployment of enterprise-grade applications using .NET, C#, and SQL Server.\n¬∑ Architected and executed Azure migration strategies, re-platforming and modernizing legacy systems.\n¬∑ Built and optimized cloud-native solutions leveraging Azure services including AKS, App Services, Functions, and Cosmos DB.\n¬∑ Operated in an AI-driven SDLC, translating stakeholder requirements into structured specifications with AI copilots.\n¬∑ Collaborated with generative AI to iterate on user flows, interfaces, and architecture designs.\n¬∑ Pair-programmed with AI tools like GitHub Copilot and Claude to write, refactor, and test production-grade code.\n¬∑ Implemented intelligent testing frameworks that auto-generate test cases, predict bugs, and enable self-healing.\n¬∑ Wrote automated tests concurrently with development to ensure CI/CD pipeline efficiency.\n¬∑ Mentored junior engineers and promoted best practices in cloud engineering and AI-assisted development.\n¬∑ Leveraged code assistants to review large codebases, identify improvement opportunities, and implement changes.\n¬∑ Applied TDD and CI/CD practices to maintain high-quality, production-ready software.\n¬∑ Designed microservices and containerized applications for scalable and resilient architecture.\n¬∑ Ensured adherence to fintech compliance and security standards while maintaining rapid delivery cycles.\n¬∑ Collaborated with cross-functional teams to integrate backend services with cloud-native front-end components.\n¬∑ Improved software quality and release velocity by introducing AI-assisted code refactoring and testing.\n¬∑ Conducted code reviews, provided feedback, and enforced coding standards across the engineering team.\n¬∑ Continuously researched emerging AI/ML tools and cloud services to enhance development processes.\nSoftware Engineer\nMotionMobs | Birmingham, AL\t\t\t\t\t\t\t           Jan  2018 ‚Äì Dec 2020\n¬∑ Developed robust backend services and APIs using C# and SQL Server.\n¬∑ Participated in cloud migration projects to modernize legacy applications.\n¬∑ Implemented automated testing frameworks and supported CI/CD pipelines.\n¬∑ Designed scalable modules for fintech applications, ensuring high performance and reliability.\n¬∑ Mentored junior developers and conducted code reviews to maintain quality standards.\n¬∑ Collaborated with cross-functional teams to implement new features and optimize workflows.\n¬∑ Applied TDD practices to ensure code reliability and maintainability.\n¬∑ Assisted in the integration of AI-assisted development tools to enhance coding efficiency.\nFull Stack Developer\nAlloy Digital | Birmingham, AL\t\t\t\t\t\t\t\tDec 2014 ‚Äì Dec 2017\n¬∑ Built full-stack web applications using .NET, C#, and front-end JavaScript frameworks.\n¬∑ Developed database schemas and optimized SQL Server queries for high-performance operations.\n¬∑ Implemented backend APIs and integrated third-party services to support business functionality.\n¬∑ Collaborated with design and QA teams to deliver production-grade software.\n¬∑ Participated in agile development processes, including sprint planning and code reviews.\n¬∑ Supported migration of monolithic applications to modular architectures.\n¬∑ Assisted in automating testing and deployment workflows to improve software delivery.\n¬∑ Mentored interns and new developers in best coding practices and development tools.\nEDUCATION\nBachelor of Science in Computer Science\nUniversity of Alabama at Birmingham, Birmingham, AL \t\t\t\t        Aug 2011 ‚Äì May 2015\nCERTIFICATIONS\nCertified Scrum Developer, PMI, 2018\nAWS Solutions Architect ‚Äì Associate Level, Amazon Web Services, 2020\n\nChase Roberson \n\nSenior Software Engineer \n\nchaseson94@gmail.com 659-234-1633 Birmingham, AL 35243 \n\nSUMMARY \n\nAccomplished Senior Software Engineer with 10 years of experience in full-stack development, cloud-\n\nnative applications, and AI-enhanced software development. Expert in .NET, C#, SQL Server, and Azure, \n\nwith proven experience leading engineering initiatives, architecting scalable solutions, and mentoring junior \n\nengineers. Skilled in implementing AI-driven testing frameworks, CI/CD pipelines, and modern cloud \n\nmigration strategies in fast-paced fintech environments \n\nSKILLS \n\nÔÇ∑ Languages & Frameworks: .NET, C#, JavaScript, Python \n\nÔÇ∑ Databases: SQL Server, Cosmos DB, Postgres \n\nÔÇ∑ Cloud & DevOps: Azure (AKS, App Services, Functions), Azure DevOps, CI/CD pipelines \n\nÔÇ∑ Tools & AI: GitHub Copilot, Claude, AI-assisted development tools, automated testing frameworks, \n\nTDD \n\nÔÇ∑ Other: Microservices architecture, containerization, cloud-native application design, agile development, \n\nmentoring \n\nPROFESSIONAL EXPERIENCE \n\nSenior Software Engineer \n\nVention | New York, NY (remote)        Jan 2021 ‚Äì Present \n\nÔÇ∑ Led the design, development, and deployment of enterprise-grade applications using .NET, C#, and \n\nSQL Server. \n\nÔÇ∑ Architected and executed Azure migration strategies, re-platforming and modernizing legacy \n\nsystems. \n\nÔÇ∑ Built and optimized cloud-native solutions leveraging Azure services including AKS, App Services, \n\nFunctions, and Cosmos DB. \n\nÔÇ∑ Operated in an AI-driven SDLC, translating stakeholder requirements into structured specifications \n\nwith AI copilots. \n\nÔÇ∑ Collaborated with generative AI to iterate on user flows, interfaces, and architecture designs. \n\nÔÇ∑ Pair-programmed with AI tools like GitHub Copilot and Claude to write, refactor, and test production-\n\ngrade code. \n\nÔÇ∑ Implemented intelligent testing frameworks that auto-generate test cases, predict bugs, and enable \n\nself-healing. \n\nÔÇ∑ Wrote automated tests concurrently with development to ensure CI/CD pipeline efficiency. \n\nÔÇ∑ Mentored junior engineers and promoted best practices in cloud engineering and AI-assisted \n\ndevelopment. \n\nÔÇ∑ Leveraged code assistants to review large codebases, identify improvement opportunities, and \n\nimplement changes. \n\nÔÇ∑ Applied TDD and CI/CD practices to maintain high-quality, production-ready software. \n\nÔÇ∑ Designed microservices and containerized applications for scalable and resilient architecture. \n\nÔÇ∑ Ensured adherence to fintech compliance and security standards while maintaining rapid delivery \n\ncycles.
52d34e64-9f8d-4db1-b5b6-bca5e93a6f18	Dinuit Unknown	dinu31it@gmail.com	Screening	Sr. Application Development Specialist	17	Dinesh Kumar Pandey 1224 Cornerstone Blvd., Downingtown, PA 19335 \n\n(720) 569-7066 | dinu31it@gmail.com | LinkedIn \n\nWORK EXPERIENCE \n\n‚ñ™ Sr. Application Development Specialist, Telus International Digital Solutions ‚Äì PA, USA Apr 2021 - Present \n\n‚Äì Led development of Kotlin/Spring Boot microservices and React, React Native with Typescript, Next.js, enhancing SSR/SSG and \nintegrating Microsoft Graph authentication APIs with Nginx. \n\n‚Äì Designed microservices architecture, defined API contracts, and implemented GraphQL queries with fault-tolerance for real-time \nprocessing. Leveraged TDD for code quality using Postman, REST Client, and Bruno. \n\n‚Äì Integrated Hystrix (or Resilience4j in newer systems) to prevent cascading failures by isolating failed services and providing \nfallbacks. Improved system resilience, reducing downtime by over 90%. \n\n‚Äì Enhanced backend code coverage to over 90% using JACOCO and improved React frontend code coverage to 90% by writing \ncomprehensive unit tests with Jest and Enzyme. \n\n‚Äì Strong understanding of secure development, implementing authentication flows, encryption standards, and threat modeling to \nbuild secure applications. \n\n‚Äì Conducted vulnerability scanning using SonarQube, analyzed and prioritized findings based on Common Vulnerability Scoring \nSystem (CVSS), and implemented fixes before deploying code to the production environment. \n\n‚Äì Automated CI/CD pipelines with Jenkins/Concourse, Docker, Kubernetes, improving performance, security, and reducing sprint \ncycles. \n\n‚Äì Mentored junior developers and facilitated Agile practices via Jira/Rally, driving sprint planning, stand-ups, and retrospectives. \n\n‚Äì Provided production support, resolved technical challenges, and led offshore teams to ensure milestone delivery. \n\n‚Äì Conducted code reviews, refactored for maintainability, and implemented POCs to explore emerging technologies for business \nalignment. \n\n‚Äì Experienced a building accessible complex web applications for accessible users, following WCAG guidelines. \n\n‚Äì Using GitHub Copilot (AI) for over a year to handle 40-50% of development tasks, improving productivity by generating tests cases, \nresolving code issues, and reducing the repetitive coding. \n\n‚ñ™ Software Engineer, Xavient Digital LLC. ‚Äì CO, USA Jul 2018 ‚Äì Apr 2021 \n\n‚Äì Designed and developed backend systems with Java/Kotlin and microservices architecture, built responsive React/Redux frontend \ncomponents with seamless API integration. \n\n‚Äì Resolved complex software issues, optimized performance, and improved scalability for real-time, large-scale applications. \n\n‚Äì Applied object-oriented design principles to enhance microservice maintainability and reduce interdependencies. \n\n‚Äì Collaborated with stakeholders in Agile sprint planning, leveraging Jira for task management. \n\n‚Äì Developed POCs for emerging technologies, recommending solutions to improve system capabilities and reduce costs. \n\n‚ñ™ Module Lead, Xavient Software Solutions ‚Äì Noida, INDIA Sep 2008 ‚Äì Jul 2018 \n\n‚Äì Developed scalable modules using Java, Struts 1.x/2.x, and Spring (Spring MVC, DI), alongside modern, pixel-perfect UI frameworks \nlike Bootstrap. Designed and implemented web services, including SOAP and RESTful APIs. \n\n‚Äì Led task allocation, progress tracking, and cross-team coordination, ensuring timely delivery and effective communication with \nstakeholders. \n\n‚Äì Conducted code reviews, implemented design patterns, and mentored junior developers to enhance productivity and uphold \ncoding standards. \n\n‚Äì Built a clinical web application using Java, Struts, and Spring DI, automating workflows and seamlessly integrating web services \nwith WebLogic. \n\n‚Äì Provided production support by resolving issues, ensuring smooth deployments, and creating detailed system documentation for \nfuture reference. \n\nEDUCATION                \n\n‚ñ™ Bachelor of Technology in Information Technology, Uttar Pradesh Technical University (June 2007), India \n\nSKILLS \n\n‚ñ™ Backend Development: Java, J2EE (Servlet, JSP), Kotlin, Python, C, C++, Spring (MVC, AOP, DI, Security, Boot Microservices, Batch), \nHibernate, JPA, Struts (1.x/2.x), GraphQL, DGS(Netflix), SOAP/RESTful APIs, JSON, XML, JUnit, Mockito, Hystrix /Resilience4j, JAX-\nRS/Jersey, OAuth/OAuth2, SAML/SSO, AWS Cloud Development Kit. \n\n‚ñ™ Frontend Development: ReactJS, Redux, Next.js, TypeScript, Node.js, Express.js, Material UI, Tailwind CSS, Bootstrap, Webpack, \nAccessibility (A11Y), Electron, JavaScript, jQuery, HTML5, CSS/CSS3, Figma, Jest, Enzyme, Cypress, Selenium, Jasper Reports, iOS \n(Swift, XCode, capacitor and package management tools ‚Äì cocoapods ). \n\nmailto:dinu31it@gmail.com\nhttps://www.linkedin.com/in/meetdineshpandey/\n\n\n‚ñ™ Build & Deployment: Gradle, Maven, CI/CD Jenkins/Concourse, Docker, Kubernetes, Kafka, Jenkins, Concourse, JACOCO, \nSonarQube. \n\n‚ñ™ Databases: SQL, MySQL, Oracle, MongoDB, Couchbase. \n\n‚ñ™ Version Control & Collaboration: Git, GitHub, GitLab, CVS, SVN, Sourcetree, TOAD, Slack, Microsoft Teams.  \n\n‚ñ™ Development Environments & Tools: IntelliJ IDEA, Visual Studio Code (VS Code), Spring Tool Suite (STS), Eclipse, WebLogic, Apache \nTomcat, Mule ESB, Postman, Bruno, Insomnia, AI (ChatGPT, Copilot). \n\n‚ñ™ Log Management & Monitoring Tools: Logging/NIFI, ELK Stack (Elasticsearch, Logstash, and Kibana), Splunk, Grafana dashboard. \n\n‚ñ™ Project Management: Agile/Scrum, Rally, Jira, SDLC, Wiki Documentation. \n\n‚ñ™ Domain Knowledge: Cable/Telecom, Healthcare. \n\n‚ñ™ Operating Systems: macOS, Windows, Linux, Unix. \n \n\nPROJECTS                \n\nClient ‚Äì Comcast  \n\n‚ñ™ Celestial: Replaced legacy 360 experience with a responsive, role-customized app for retail, customer care, and sales teams. \n\n‚ñ™ Flow Engine: Automated app flow management with a platform for streamlined workflows. \n\n‚ñ™ PlatCo (XClass/Zumo TV) Customer & Agent portal: Designed a portal for Comcast agents and customers to manage preferences, \nrefunds, and updates efficiently. \n\nClient ‚Äì Dish Network (Echostar)  \n\n‚ñ™ Beacon Agent/CApp: A web application for Dish CSR agents to efficiently create and manage subscriber accounts, improving call \ncenter operations and reducing response times. \n\n‚ñ™ Beacon Tech: A technician-facing web app to streamline item sales for Truck Roll Work Orders, reducing dependency on CSRs and \nenhancing workflow efficiency. \n\n‚ñ™ MyDish (CSA-Mobile Web): A maintenance platform for Dish customers, driving higher internet activations, increased order \nvolumes, and improved self-service engagement. \n\n‚ñ™ CSA Hopper: The sole Hopper-series receiver application, aligned with CSA Web requirements to meet Dish business goals. \n\n‚ñ™ Widget Management System (CMS Admin Tool): Enabled business users to update my.dish.com content without IT intervention, \nreducing update times to 15 minutes and increasing operational autonomy. \n\n‚ñ™ Techstore: A mobile web app for technicians to directly manage Truck Roll Work Orders, eliminating CSR dependency and \nstreamlining customer service. \n\n‚ñ™ DishCart: An application designed for new customers to manage and view packages, offers, and equipment configurations provided \nby Dish Network. It allows modifications and maintenance as per business requirements. \n\n‚ñ™ Framework (EPC): Created a customer-facing platform for managing packages, offers, and equipment configurations, providing \nseamless modifications to meet business needs. \n\nClient ‚Äì RADIANT HEALTHCARE \n\n‚ñ™ Clinic Application: An innovative solution with features including appointment scheduling, doctor scheduling, patient accounting, \nclinic location management, report generation, system setup, and user management. Automated workflows to improve operational \nefficiency for healthcare clinics. \n\nACHIEVEMENTS               \n\n‚ñ™ Received "Hard Work Recognized" award for contributions to 2013 Enterprise Releases at Dish Network. \n\n‚ñ™ Received "Hard Work Recognized" award for RWD Project Releases at Dish Network. \n\n‚ñ™ Awarded "Star Team Achiever" for re-architecting and transitioning CSAWEB to Tomcat at Xavient. \n\n‚ñ™ Awarded "Star Month Achiever" for Custom Implementation at Xavient. \n\n‚ñ™ Honored with the "Long Service Award" by Xavient for commitment and excellence.
cf77c5cd-6707-454a-bdb5-d524a1a2dcfc	Dylanespinosa Unknown	dylanespinosa0624@gmail.com	Screening	Software Engineer	9	Dylan Espinosa \n\ndylanespinosa0624@gmail.com                           +1 (408) 600 2695                             Woodbridge, VA, USA \n\n \n\nPROFILE \n\nSenior Software Engineer with 8 years of experience designing and delivering enterprise-grade applications \n\nwith .NET, C#, SQL Server, and Azure cloud technologies. Proven success in leading cloud migration \n\nstrategies, building scalable cloud-native systems, and leveraging AI-powered development workflows. \n\nStrong background in CI/CD pipelines, automated testing, and modern DevOps practices, with expertise \n\nmentoring teams and driving best practices. Seeking to bring deep technical expertise and leadership to Green \n\nDot‚Äôs mission of enabling smarter financial technology solutions. \n\n \n\nEDUCATION \n\nVirginia Tech (Virginia Polytechnic Institute and State University), 2013 ‚Äì 2017, Blacksburg, VA \n\nBachelor‚Äôs degree in Computer Science \n\nSKILLS \n\nÔÇ∑ Languages & Frameworks: .NET, C#, ASP.NET Core, JavaScript, TypeScript, HTML/CSS \n\nÔÇ∑ Cloud & Platforms: Microsoft Azure (AKS, App Services, Functions, Cosmos DB, Azure DevOps), Docker, \n\nKubernetes \n\nÔÇ∑ Databases: SQL Server, PostgreSQL, NoSQL (Cosmos DB, MongoDB) \n\nÔÇ∑ DevOps & Tools: GitHub, GitHub Copilot, Azure DevOps, Jenkins, CI/CD, Terraform \n\nÔÇ∑ Testing & QA: xUnit, NUnit, Selenium, Postman, REST API Testing, TDD, Automated Testing Frameworks \n\nÔÇ∑ Architectures & Practices: Microservices, Event-Driven Systems, Domain-Driven Design, AI-Enhanced \n\nSDLC, Agile/Scrum \n\n \n\n \n\n \n\n \n\n\n\nPROFESSIONAL EXPERIENCE \n\nSoftware Engineer, Spotify, New York, Remote                                                                   01/2022 ‚Äì 05/2025 \n\nÔÇ∑ Designed and deployed enterprise-grade applications using .NET Core, C#, and SQL Server, \n\nensuring reliability and scalability for millions of users. \n\nÔÇ∑ Led an Azure migration initiative, re-platforming legacy systems into cloud-native architectures \n\nleveraging AKS, Functions, and Cosmos DB. \n\nÔÇ∑ Architected and implemented microservices-based solutions that improved resilience and \n\nenabled independent feature releases. \n\nÔÇ∑ Partnered with AI-assisted tools (GitHub Copilot, internal AI copilots)  to accelerate code \n\ngeneration, refactoring, and test automation. \n\nÔÇ∑ Developed intelligent automated testing frameworks integrated into CI/CD pipelines, reducing \n\nregression issues and enabling faster releases. \n\nÔÇ∑ Delivered API-first designs to support mobile and web applications, ensuring secure integration \n\nwith third-party services. \n\nÔÇ∑ Implemented continuous integration and delivery pipelines  with Azure DevOps, increasing \n\ndeployment speed and stability. \n\nÔÇ∑ Mentored junior engineers in Azure, DevOps, and AI-assisted workflows, driving adoption of \n\nmodern engineering practices. \n\nÔÇ∑ Optimized large-scale SQL Server and Cosmos DB databases, focusing on query performance and \n\nscalability. \n\nÔÇ∑ Introduced real-time monitoring and alerting solutions using Azure Monitor and Application \n\nInsights. \n\nÔÇ∑ Collaborated with cross-functional teams, including product managers and data engineers, to \n\ndeliver features aligned with business goals. \n\nÔÇ∑ Designed automated test suites for APIs and services using NUnit and Postman, improving \n\ncoverage and reducing manual testing. \n\nÔÇ∑ Contributed to financial services features, ensuring compliance and security in transaction-\n\nrelated workflows. \n\n\n\nÔÇ∑ Championed best practices in secure coding, code reviews, and system design, fostering a culture \n\nof technical excellence. \n\n  \n\nFull Stack Engineer, UNIWeb, Burke, VA, Remote                                                               11/2018 ‚Äì 12/2021 \n\nÔÇ∑ Built full-stack web applications using ASP.NET Core, C#, JavaScript, and SQL Server. \n\nÔÇ∑ Participated in Azure cloud adoption projects, deploying applications with Azure App Services and \n\nFunctions. \n\nÔÇ∑ Collaborated with clients to modernize legacy systems, implementing cloud-first and service-\n\noriented designs. \n\nÔÇ∑ Created RESTful APIs to integrate client systems with external platforms. \n\nÔÇ∑ Applied TDD practices and developed automated test suites to ensure reliable releases. \n\nÔÇ∑ Enhanced application performance through database optimization and caching strategies. \n\nÔÇ∑ Contributed to CI/CD adoption with Azure DevOps pipelines, streamlining deployment cycles. \n\nÔÇ∑ Supported multiple industries including finance, healthcare, and retail, tailoring solutions to \n\nspecific regulatory and performance needs. \n\nÔÇ∑ Mentored junior developers on modern .NET practices and best use of Azure services. \n\n \n\nJunior Engineer, Blue Label Labs, Richmond, VA, Hybrid                                                    05/2016 ‚Äì 10/2018 \n\nÔÇ∑ Assisted in developing web and mobile applications using C#, .NET, and SQL Server. \n\nÔÇ∑ Supported front-end development with HTML, CSS, and JavaScript. \n\nÔÇ∑ Participated in client-facing projects for startups and enterprises, delivering MVPs and \n\nproduction-ready applications. \n\nÔÇ∑ Implemented basic RESTful services and integrated third-party APIs. \n\nÔÇ∑ Performed unit testing and debugging to ensure application quality. \n\nÔÇ∑ Collaborated in Agile/Scrum teams, participating in daily standups and sprint reviews. \n\nÔÇ∑ Gained exposure to cloud concepts with early Azure-based projects. \n\nÔÇ∑ Contributed to system documentation and code reviews. \n\nÔÇ∑ Supported senior developers in database design and optimization tasks. \n\nÔÇ∑ Learned best practices for secure coding and deployment workflows.
096e7136-a0eb-4560-a5db-7a2af7f1188f	Griffin Unknown	griffin9395@outlook.com	Screening	Senior Software Engineer	12	Jeremy Griffin\nSenior Software Engineer\n\n+1-972-331-0866 | griffin9395@outlook.com | 1693 Fm 1003 South, Kountze, TX, 77625, US\n\nPROFESSIONAL SUMMARY\n\nI am a passionate software engineer with over 9 years of experience specializing in building scalable, cloud-native \n\napplications using .NET, C#, and Azure. I excel in leading migration projects, implementing AI-driven development \n\npractices, and fostering best coding standards. My expertise includes designing enterprise solutions, automating \n\ntesting protocols, and collaborating effectively in agile, remote teams to deliver impactful financial technology \n\nsolutions.\n\nTECHNICAL SKILLS\n\nÔÇ∑ Programming Languages & Frameworks: C#, .NET, SQL, Azure SDKs, Python\n\nÔÇ∑ Cloud & DevOps: Azure Cloud, Azure DevOps, AKS, Functions, App Services, Cosmos DB, \n\nContainerization, Microservices\n\nÔÇ∑ Databases & Data Management: SQL Server, Database Design, Data Migration, Database Software\n\nÔÇ∑ AI & Automation: Generative AI, AI Copilots, Automated Testing, TDD, CI/CD, Auto Test Generation, \n\nPredictive Bug Detection\n\nÔÇ∑ Tools & Technologies: GitHub Copilot, Claude, Azure Migration, APIs, Container Orchestration, Azure \n\nDevOps, CNCF\n\nÔÇ∑ Additional Skills: Agile Software Development, API Testing, Team Mentorship, Cross-functional \n\nCollaboration, Technical Leadership, Remote Work Adaptation\n\nPROFESSIONAL EXPERIENCE\n\nSAS, North Carolina, US | Senior Software Engineer | Jan, 2021 - Present \n\nÔÇ∑ Led cloud-native application design and deployment in Azure, improving system scalability and reducing \n\nlatency by 25%.\n\nÔÇ∑ Architected and executed Azure migrations, re-platforming legacy systems and modernizing infrastructure with \n\ncontainer orchestration.\n\nÔÇ∑ Collaborated with AI tools like GitHub Copilot and Claude to accelerate code refactoring, resulting in a 15% \n\nincrease in developer productivity.\n\nÔÇ∑ Directed enterprise application development using .NET and C#, ensuring high performance and security \n\nstandards for financial services.\n\nÔÇ∑ Implemented automated testing frameworks with self-healing capabilities, decreasing bugs in production by \n\n20%.\n\nÔÇ∑ Mentored junior engineers on cloud best practices and AI-assisted development workflows, fostering a culture \n\nof continuous improvement.\n\nÔÇ∑ Worked with cross-functional teams to translate stakeholder requirements into scalable technical specifications.\n\nÔÇ∑ Led Agile development cycles and ensured continuous integration and delivery pipelines maintained at 99% \n\nuptime.\n\nÔÇ∑ Participated in AI/ML concept integration, enhancing predictive analytics features within core applications.\n\nmailto:griffin9395@outlook.com\n\n\nÔÇ∑ Managed team of 10 engineers, promoting best practices in microservices architecture and container \n\norchestration.\n\nIntellecSoft, California, US | Software Engineer | Mar, 2018 ‚Äì Jan, 2021\n\nÔÇ∑ Developed and maintained enterprise-grade applications utilizing C#, .NET, and SQL Server, serving thousands \n\nof users daily.\n\nÔÇ∑ Contributed to Azure migration projects, optimizing cloud resource utilization and reducing operational costs by \n\n18%.\n\nÔÇ∑ Built RESTful APIs and integrated third-party services to enhance application functionalities and user \n\nexperience.\n\nÔÇ∑ Designed database schemas and optimized queries, improving data retrieval times by 30%.\n\nÔÇ∑ Automated test suites and implemented CI/CD workflows, ensuring rapid, reliable deployments across \n\nenvironments.\n\nÔÇ∑ Collaborated with product teams to refine features using AI tools, leading to faster iterations and better \n\nstakeholder alignment.\n\nÔÇ∑ Led code reviews and enforced coding standards, elevating team code quality and maintainability.\n\nÔÇ∑ Participated in Agile ceremonies, delivering features on time and within scope while maintaining high-quality \n\nstandards.\n\nÔÇ∑ Provided technical mentorship to junior team members, fostering skill development and knowledge sharing.\n\nÔÇ∑ Supported cross-team integration efforts, ensuring seamless deployment pipelines and system interoperability.\n\nÔÇ∑ Utilized Azure DevOps for project tracking and deployment automation, streamlining workflow efficiencies.\n\nÔÇ∑ Engaged in troubleshooting complex issues, achieving 99.9% system uptime in critical production \n\nenvironments.\n\nThinkSys, California, US | Junior Web Developer | Sep, 2015 ‚Äì Feb, 2018 \n\nÔÇ∑ Assisted in developing web applications using C# and .NET, contributing to key project milestones in an agile \n\nenvironment.\n\nÔÇ∑ Supported database management tasks, including designing tables and optimizing queries for performance.\n\nÔÇ∑ Wrote automated tests to validate application components, reducing manual testing efforts by 40%.\n\nÔÇ∑ Learned to utilize Azure services for deployment and scaling of web applications under senior supervision.\n\nÔÇ∑ Collaborated with senior developers to troubleshoot bugs and implement feature enhancements in legacy \n\nsystems.\n\nÔÇ∑ Participated in team meetings, contributing ideas on improving automated testing protocols and CI/CD \n\npipelines.\n\nEDUCATION\n\nUniversity of California, Berkeley | Jun, 2010 ‚Äì May, 2015\n\nBachelor‚Äôs degree in computer science\n\nADDITIONAL SKILLS\n\nÔÇ∑ Leadership & Team Management: Team mentoring, Cross-functional collaboration, Remote team leadership\n\nÔÇ∑ Agile Methodologies: Scrum, Kanban, Sprint planning, Continuous integration\n\n\n\nÔÇ∑ Communication & Client Engagement: Effective communication, Cross-cultural team interaction, \nDocumentation\n\nÔÇ∑ Problem-Solving & Innovation: Root cause analysis, Incident management, Automation improvement\n\n\n\tTECHNICAL SKILLS\n\tPROFESSIONAL EXPERIENCE\n\tSAS, North Carolina, US | Senior Software Engineer | Jan, 2021 - Present\n\tIntellecSoft, California, US | Software Engineer | Mar, 2018 ‚Äì Jan, 2021\n\tThinkSys, California, US | Junior Web Developer | Sep, 2015 ‚Äì Feb, 2018\n\n\tEDUCATION\n\tAdditional Skills
ab2bec86-ffcd-411a-82e8-1dd46f4894f3	Hwang James	hwang.james727@gmail.com	Screening	Lead Backend Engineer	8	James Hwang\nLead Software Engineer\n\nüìç Skokie, IL, USA | üì± +1 (814) 300-8646 | üìß hwang.james727@gmail.com\nProfessional Summary\nLead Software Engineer with 10+ years of experience building enterprise-grade .NETapplications, SQL Server solutions, and cloud-native architectures in Azure. Provenexpertise in leading migration of legacy systems to cloud platforms, implementing AI-drivendevelopment workflows (GitHub Copilot, Claude), and driving test-first, CI/CD-enabledpipelines. Strong background in microservices, containerization, and financial servicesplatforms. Skilled mentor and technical leader with a passion for leveraging AI copilots toaccelerate delivery and ensure high-quality production code.\nTechnical Skills\n\n¬∑ Languages & Frameworks: .NET (Core & Framework), C#, ASP.NET MVC, WebAPI, LINQ, Entity Framework, T-SQL\n¬∑ Cloud Platforms: Microsoft Azure (AKS, App Services, Functions, Cosmos DB, AzureDevOps, Azure APIM), AWS (ECS, S3, Lambda)\n¬∑ Databases: SQL Server, PostgreSQL, MySQL, Cosmos DB, database schema design,indexing, query optimization\n¬∑ Architectures: Cloud-native, microservices, event-driven systems, CNCF tools,containerization (Docker, Kubernetes)\n¬∑ AI Development Tools: GitHub Copilot, Claude, AI copilots for code generation, testingautomation, debugging\n¬∑ Testing & CI/CD: TDD, NUnit, xUnit, Moq, Selenium, Azure DevOps, GitHub Actions,Jenkins, CircleCI\n¬∑ Other Tools: Terraform (IaC), Kubernetes, Git, Jira, Confluence\n¬∑ Soft Skills: Technical leadership, mentoring, Agile/Scrum collaboration, stakeholdercommunication, ownership mindset\n\nProfessional Experience\nLead Backend Engineer | Disney Streaming | New York, NY\nAug 2024 ‚Äì May 2025\n\n\n\n¬∑ Directed backend engineering efforts for subscription and payment platforms, leading ateam of engineers building cloud-native .NET APIs and microservices deployed onAzure AKS.\n¬∑ Spearheaded Azure migration initiatives, modernizing legacy .NET Frameworkapplications to .NET Core, improving scalability and reliability.\n¬∑ Implemented AI-driven SDLC practices by pairing with GitHub Copilot to refactorlarge C# codebases, generate unit tests, and accelerate feature delivery.\n¬∑ Designed and optimized SQL Server schemas and stored procedures, reducing querytimes for high-volume financial transactions.\n¬∑ Led implementation of CI/CD pipelines in Azure DevOps, embedding automatedtesting, linting, and deployment scripts.\n¬∑ Integrated intelligent testing frameworks that auto-generated test cases and enabledpredictive bug detection.\n¬∑ Collaborated with architects to design event-driven microservices, applying CNCFtooling and containerization best practices.\n¬∑ Mentored junior developers in secure coding, TDD, and leveraging AI copilots toenhance productivity.\n\nSenior Software Engineer | Hulu | Santa Monica, CA\nDec 2022 ‚Äì Aug 2024\n\n¬∑ Built enterprise-grade services in C#/.NET Core to support subscription billing and userauthentication workflows.\n¬∑ Partnered with DevOps to migrate critical systems to Azure Functions, App Services,and Cosmos DB, achieving measurable cost reductions.\n¬∑ Applied AI copilots (Copilot, Claude) to assist in code refactoring, generating test cases,and documenting service architectures.\n¬∑ Optimized SQL Server queries and implemented indexing strategies, improving analyticsquery performance by 45%.\n¬∑ Designed microservices for billing and reporting workflows deployed in Docker andKubernetes clusters.\n¬∑ Applied TDD practices, delivering automated tests alongside production-grade code.\n¬∑ Participated in Agile sprint planning and backlog grooming, aligning feature deliverywith stakeholder priorities.\n¬∑ Mentored developers on API design patterns, microservices best practices, and databaseoptimization techniques.\n\nSenior Full-Stack Engineer | Recruit Rockstars | Chicago, IL\nJul 2022 ‚Äì Nov 2022\n\n\n\n¬∑ Delivered SaaS recruiter tools built with .NET backend services and Angular/Reactfront-ends, deployed on Azure.\n¬∑ Migrated legacy SQL Server reporting workflows into cloud-native Cosmos DB andAzure Functions.\n¬∑ Designed CI/CD pipelines with GitHub Actions for rapid feature deployment.\n¬∑ Used GitHub Copilot for test-first development, generating unit and integration testsuites alongside APIs.\n¬∑ Architected microservices for recruiter/candidate management workflows, ensuringscalability and fault tolerance.\n¬∑ Partnered with stakeholders to design features and rapidly iterate with AI-assisted codingpractices.\n¬∑ Authored technical documentation and user onboarding guides.\n¬∑ Debugged high-priority production incidents and implemented structured remediation.\n\nSoftware Engineer | Discover Financial Services | Riverwoods, IL\nNov 2019 ‚Äì Jun 2022\n\n¬∑ Built and maintained .NET APIs for fraud detection, payment processing, andcompliance workflows in a highly regulated environment.\n¬∑ Led SQL Server query optimization and schema redesign for reporting and frauddetection modules.\n¬∑ Applied AI copilots to accelerate refactoring of large .NET codebases and improvetesting automation.\n¬∑ Designed secure APIs using OAuth2 and JWT authentication frameworks.\n¬∑ Applied containerization strategies using Docker and orchestrated deployments onKubernetes clusters.\n¬∑ Automated deployments with Jenkins pipelines, embedding unit and integration tests.\n¬∑ Partnered with compliance teams to align APIs with regulatory standards and auditingrequirements.\n¬∑ Mentored junior engineers on secure coding practices, TDD, and SQL optimization.\n\nBackend Developer | PowerReviews | Chicago, IL\nJun 2017 ‚Äì Oct 2019\n\n¬∑ Built SaaS backend services in .NET Core and SQL Server to aggregate and analyzemillions of product reviews.\n¬∑ Designed reporting schemas in SQL Server, applying indexing strategies for real-timeanalytics dashboards.\n¬∑ Migrated monolithic applications to microservices deployed in Docker containers.\n¬∑ Applied AI-driven testing frameworks to auto-generate regression tests and reducemanual QA.\n\n\n\n¬∑ Partnered with product managers to deliver high-value reporting features with rapiditeration cycles.\n¬∑ Automated deployments with Azure DevOps pipelines.\n¬∑ Authored technical documentation for APIs, database models, and CI/CD pipelines.\n¬∑ Participated in Agile ceremonies, demos, and retrospectives to drive team improvements.\n\nEducation\nBachelor of Science in Computer ScienceUniversity of Illinois Chicago | 2014 ‚Äì 2017\nProjects\n1. Azure Migration Strategy: Led migration of .NET apps and SQL Server workloads intoAzure AKS and Functions.\n2. AI-Enhanced Development: Leveraged GitHub Copilot/Claude to accelerate coderefactoring and testing.\n3. Enterprise API Gateway: Built scalable and secure APIs with lifecycle management forfinancial services.\n4. SQL Server Optimization: Designed schemas and optimized queries for payment andfraud systems.\n5. CI/CD Automation: Built Azure DevOps pipelines embedding automated tests for APIsand microservices.\n6. Microservices Architecture: Deployed containerized services using Docker andKubernetes.\n7. Cosmos DB Migration: Migrated reporting systems into Cosmos DB with optimizedqueries.\n8. Intelligent Testing Frameworks: Implemented self-healing, predictive bug-detectiontools for CI/CD.\n9. Cloud-Native SaaS Platform: Built multi-tenant recruiter SaaS solution in .NET Coreon Azure.\n10. Secure Auth Framework: Implemented OAuth2/JWT authentication and encryption inbackend APIs.\n11. Mentorship Program: Coached engineers on AI-assisted development, cloud-nativepractices, and secure coding.
9ba57551-8702-41ce-a389-dcf4189c7846	Jeffreylin Unknown	jeffreylin1206@gmail.com	Screening	Senior Software Engineer	11	jeffrey lin\n\nLas Vegas, NV 89113   |   702-603-3525   |   jeffreylin1206@gmail.com \nsummary\n\nA dedicated software engineer with over 11 years of experience specializing in cloud-native applications within the fintech industry. Proficient in a range of technologies including .NET, C#, SQL Server, and Azure cloud services, with a strong aptitude for implementing AI-enhanced development workflows. Passionate about mentoring junior engineers and promoting best practices in software engineering and automated testing. Outside of work, interests include AI advancements and community outreach in tech education, demonstrating a commitment to both personal and professional growth. \nexperience\n\nSenior Software Engineer\nDeloitte ‚Äì Remote\t04/2020 ‚Äì Present\n¬∑ Led the design, development, and deployment of enterprise-grade applications utilizing .NET, C#, and SQL Server, resulting in a 25% improvement in deployment speed while enhancing system performance through optimized coding practices.\n¬∑ Spearheaded the execution of Azure migration strategies, successfully modernizing over 15 legacy systems by implementing scalable solutions in a cloud-native environment, which improved operational efficiency by 40%.\n¬∑ Architected and built cloud-native applications leveraging Azure services such as AKS, Cosmos DB, and Azure Functions, leading to a reduction in system downtime by 30%.\n¬∑ Operated in an AI-driven Software Development Life Cycle (SDLC) environment, utilizing tools like GitHub Copilot to pair program, resulting in a 20% increase in overall coding accuracy and speed.\n¬∑ Collaborated with cross-functional teams to translate stakeholder conversations into structured specifications using AI copilots, enhancing clarity and alignment on project objectives.\n¬∑ Developed automated testing frameworks that predicted bugs and reduced manual testing effort by 50%, significantly shortening the release cycles and enhancing product quality.\n¬∑ Utilized intelligent testing frameworks to auto-generate test cases alongside development activities, ensuring robust API testing and thorough coverage while maintaining continuous integration and delivery.\n¬∑ Mentored junior engineers, promoting best practices in cloud engineering and fostering an environment of continuous learning that contributed to team skill enhancement.\n¬∑ Leveraged AI tools to iterate on user flows and interface designs, streamlining the development process and improving user experience by ensuring seamless navigation across applications.\n¬∑ Enhanced application performance by refactoring existing codebases, employing best practices for maintainability, and implementing performance monitoring tools to assess real-time system health.\n¬∑ Participated in establishing code review processes that enforced adherence to coding standards and optimized team productivity, fostering a culture of quality and accountability.\n¬∑ Engaged in technical documentation efforts that provided clear guidelines for application architecture and design, facilitating easier onboarding for new team members and effective knowledge sharing.\n¬∑ Orchestrated system architecture discussions to align development strategies with business goals, ensuring that engineering efforts supported the broader organizational vision.\n¬∑ Developed and maintained databases with an emphasis on database design and optimization, ensuring that data handling was efficient and scalable without sacrificing performance.\n¬∑ Led the transition of core services to a microservices architecture, which allowed for independent deployment cycles and reduced interdependencies plague by rigid integrations.\n¬∑ Designed robust RESTful services that facilitated seamless integration with third-party platforms, expanding the application's capabilities while maintaining security and compliance standards.\n¬∑ Implemented CI/CD practices that automated deployment processes and streamlined code integration, leading to a significant decrease in production incidents.\n¬∑ Collaborated with financial stakeholders to ensure that software systems adhered to industry regulations and quality standards, directly impacting compliance and user trust.\n\nSoftware Engineer\nEverise ‚Äì Las Vegas, NV\t11/2017 ‚Äì 03/2020\n¬∑ Developed enterprise applications utilizing .NET and C#, enhancing overall application efficiency which led to a 15% reduction in server response time during peak hours.\n¬∑ Designed and implemented SQL Server databases, focusing on schema design and performance tuning, which improved data retrieval times by 20%.\n¬∑ Assisted in migrating legacy systems to Azure, employing best practices in cloud solutions, ensuring minimal impact on service availability during transitions.\n¬∑ Collaborated with team members to create automated testing scripts that streamlined regression testing processes, ultimately shrinking testing timeframes significantly by 25%.\n¬∑ Engaged in agile ceremonies, contributing to sprint planning and retrospectives, while presenting technical solutions that increased project velocity.\n¬∑ Actively utilized GitHub for version control and code review, enforcing best practices that emphasized clean coding and documentation, resulting in reduced technical debt.\n¬∑ Participated in the implementation of application monitoring tools to track performance metrics, leading to proactive identification of bottlenecks in real-time.\n¬∑ Supported the development and deployment of cloud solutions, leveraging Docker for containerization, which improved team scalability and flexibility in technical operations.\n¬∑ Enhanced team output by participating in knowledge-sharing sessions, focusing on incorporating new tools like Azure DevOps into existing workflows.\n¬∑ Assisted in client-focused projects, ensuring that applications met user requirements and improved the overall client satisfaction ratings by collecting and implementing user feedback.\n¬∑ Worked under Agile methodologies, which included daily stand-ups and sprint retrospectives, promoting collaboration and timely deliverable adjustments with a focus on iterative delivery.\n¬∑ Conducted system analyses that guided enhancements and upgrades of existing applications, ensuring they met evolving business needs and technological advancements.\n\nJunior Software Engineer\nInternational Game Technology (IGT) ‚Äì Las Vegas, NV\t07/2014 ‚Äì 10/2017\n¬∑ Contributed to software development projects using C# and .NET, focusing on developing small-scale applications that improved user engagement by enhancing interactivity.\n¬∑ Supported database management tasks in SQL Server, where careful attention was directed toward ensuring data integrity and security measures were met during transactions.\n¬∑ Assisted senior developers in conducting application tests, providing valuable insights into the functionality that helped in debugging and refining features before release.\n¬∑ Participated in code reviews, focusing on understanding best practices while gaining exposure to complex system architecture and performance optimization techniques.\n¬∑ Engaged in learning activities, including tutorials and collaborative programming sessions to better grasp the fundamentals of cloud technologies and their implementation.\n¬∑ Helped document software specifications, contributing essential details on features and functionalities that assisted in the transition between project phases.\n¬∑ Supported the team by performing basic analytics for application usage, identifying trends that directly informed suggestions for product enhancements.\n¬∑ Collaborated with peers to build small-scale applications, focusing on user interface design to ensure consistent, user-friendly interactions throughout app workflows.\n¬∑ Engaged with SQL databases for data extraction and manipulation tasks, gaining experience in writing queries that enhanced data reporting for project needs.\n¬∑ Assisted in deploying applications through basic Azure configurations, gaining hands-on experience with cloud deployment strategies and learning from senior team members.\neducation\n\nUniversity of Nevada, Las Vegas ‚Äì Las Vegas, NV\t08/2010 ‚Äì 05/2014\nBachelor of Science in Computer Science\nskills\n\n.NET, C#, SQL Server, Azure, Microsoft Azure, AKS (Azure Kubernetes Service), Cosmos DB, Azure Functions, App Services, GitHub Copilot, Claude AI, Automated Testing, TDD (Test-Driven Development), CI/CD Pipelines, Microservices Architecture, Containerization, Kubernetes, Docker, Azure DevOps, Cloud Migration Strategies, Legacy System Modernization, Cloud-Native Applications, Intelligent Testing Frameworks, AI-Enhanced Development, Self-Healing Systems, User Flow Optimization, Performance Optimization, Stakeholder Collaboration, Production Grade Code, Automated Test Case Generation, APIs, Code Refactoring, Code Testing, AI Code Assistants, Data Integration, Agile Environments, Continuous Delivery Practices, Azure Tools, ML Tools, Financial Services Software, RESTful Services, Design Patterns, Software Development Life Cycle (SDLC), Code Review, Technical Documentation, System Architecture, Database Design
e1d02556-6f23-4a88-a61a-f2a6c9ed43ba	Jordanrinehart Unknown	jordanrinehart5151@gmail.com	Screening	Senior Software Engineer	8	JORDAN RINEHART\nSenior Software Engineer\n jordanrinehart5151@gmail.com\t (325) 204-2130\t Brownwood, TX 76801 \n\nSUMMARY\nAccomplished professional with over 8 years of experience in the financial technology industry, specializing in software engineering and cloud-based solutions. Expert in building and enhancing scalable, cloud-native applications utilizing .NET, C#, and Azure technologies. Proven success in architecting migration strategies and driving innovation through AI-enhanced development workflows. Passionate about mentoring teams and ensuring best practices in engineering processes. An ardent advocate for modernizing legacy systems, fostering an inclusive workplace, and advancing the deployment of intelligent software solutions. Outside of work, enjoys exploring fintech trends, mentoring aspiring software engineers, and building community through technology education.\nEXPERIENCE\nSenior Software Engineer\nMcKinsey & Company\t 11/2023 ‚Äì Present\t Remote\n¬∑ Led the design, development, and deployment of enterprise-grade applications using .NET, C#, and SQL Server, incorporating advanced practices in cloud computing to enhance software scalability and performance.\n¬∑ Architected and executed comprehensive Azure migration strategies, transitioning multiple legacy systems to modern cloud environments, resulting in increased operational efficiency and reduced infrastructure costs.\n¬∑ Built and optimized cloud-native solutions utilizing various Azure services like AKS, Cosmos DB, and Azure Functions, ensuring robust performance and high availability of financial applications.\n¬∑ Operated in a dynamic AI-driven software development lifecycle (SDLC) environment, translating stakeholder needs into structured specifications using AI copilots, benefiting team collaboration and throughput.\n¬∑ Collaborated with generative AI tools to iterate on user flows, interfaces, and architectures, improving overall user experience and design quality in product development.\n¬∑ Engaged in pair programming with AI assistance, employing tools such as GitHub Copilot to refine code quality in real time, thereby accelerating development timelines and minimizing bugs.\n¬∑ Developed and tested production-grade code tailored for the financial services sector without dependencies on external testing groups, enhancing reliability and performance metrics of deployed systems.\n¬∑ Implemented intelligent automated testing frameworks capable of auto-generating test cases, predicting potential bugs, and facilitating self-healing of code, significantly boosting testing efficiency.\n¬∑ Leveraged AI code assistants to navigate large codebases, identifying opportunities for enhancement and adapting code structures to improve maintainability and performance.\n¬∑ Co-developed automated tests in tandem with code development, ensuring continuous integration and delivery processes adhered to industry best practices, streamlining deployment cycles.\n¬∑ Mentored junior engineers, sharing knowledge on best practices in cloud engineering and AI-assisted development to cultivate a high-performance engineering culture.\n¬∑ Pioneered initiatives to implement microservices architecture and container orchestration strategies, reducing deployment times and enabling faster feature releases.\nSenior Engineer\nSparkCognition\t 04/2020 ‚Äì 10/2023\t Remote\n¬∑ Played a crucial role in delivering innovative AI-driven software solutions, leveraging deep knowledge of .NET, C#, and Azure cloud environments to enhance system functionalities and user engagement.\n¬∑ Collaborated with cross-functional teams to design scalable financial applications, implementing SQL Server for robust database management and supporting application performance optimization initiatives.\n¬∑ Contributed to project success by developing and deploying cloud-native applications, integrating services such as Azure App Services resulting in improvements to application availability and resilience.\n¬∑ Engaged in comprehensive cloud migration projects, utilizing modern practices and Azure DevOps tools to ensure seamless transitions of legacy systems into contemporary cloud environments.\n¬∑ Championed the adoption of microservices architecture, implementing containerization and orchestration techniques that streamlined deployment processes and improved system scalability.\n¬∑ Developed automated testing protocols aligned with TDD methodologies, ensuring code quality and reliability through implementation of systematic integrating testing frameworks.\n¬∑ Collaborated with teams to enhance existing systems by integrating AI technologies such as GitHub Copilot, improving code efficiency and error reduction.\n¬∑ Actively participated in Agile processes, contributing to sprint planning, retrospectives, and stakeholder engagement to drive project clarity and delivery timelines.\n¬∑ Facilitated knowledge-sharing sessions to uplift junior developers' skills in cloud technology deployment and AI application implementations, promoting professional growth.\n¬∑ Designed and executed CI/CD pipelines that accelerated application delivery cycles while maintaining performance and reliability in production-grade software deployments.\n¬∑ Advocated for best operational practices within engineering teams, leading efforts to implement effective automated testing and continuous delivery systems.\n¬∑ Conducted code reviews and pair programming sessions with junior team members, focusing on best coding practices and introduction of new AI-enhanced development techniques.\n¬∑ Monitored and optimized application performance metrics, utilizing tools to analyze and resolve bottlenecks ensuring high user satisfaction levels.\n¬∑ Engaged with external partners and stakeholders to align product requirements with technical capabilities, allowing for informed decision-making and enhanced product viability.\n¬∑ Contributed to community growth initiatives by organizing tech workshops that imparted knowledge on deploying cloud-based solutions and the importance of adapting to new technologies.\nSoftware Developer\nCGI\t 07/2017 ‚Äì 03/2020\t Belton, TX\n¬∑ Supported the development and management of web applications utilizing .NET technologies, assisting in the implementation of minor feature enhancements through C# programming.\n¬∑ Participated in coding, debugging, and documentation processes under the guidance of senior engineers to understand cloud-based application functionalities and best practices.\n¬∑ Assisted in migrating legacy systems to cloud environments, gaining hands-on experience with Azure environments and fundamental database management principles using SQL Server.\n¬∑ Engaged in team discussions to understand and implement basic automated testing strategies contributing to improved software reliability, particularly in financial applications.\n¬∑ Collaborated with senior developers to learn about software architecture principles and the importance of efficient code structuring to improve code quality.\n¬∑ Gained exposure to cloud technology integration, participating in projects that provided insights into building scalable applications using Azure services at entry-level proficiency.\n¬∑ Supported user acceptance testing by validating features against requirements, ensuring that applications met operational standards before deployment.\n¬∑ Assisted in the development of basic application interfaces, applying initial knowledge of user experience principles learned through team collaboration.\n¬∑ Reviewed and maintained documentation as needed, contributing to a more cohesive understanding of project specifications and coding standards within the team.\nEDUCATION\nBachelor of Science in Computer Science\nUniversity of Texas at Austin\t 08/2013 ‚Äì 05/2017\t Austin, TX\nSKILLS\n.NET, C#, SQL Server, Azure, Azure DevOps, Cosmos DB, AKS, Azure Functions, TDD, CI/CD, Microservices Architecture, Containerization, Container Orchestration, Automated Testing, Generative AI, AI Code Assistants, GitHub Copilot, Claude, Agile Environment, API Testing Tools, Automated Test Frameworks, Intelligent Testing, Performance Optimization, Application Modernization, Production Code Development, Refactoring, Cloud Security, DevOps Practices, Code Review, Pair Programming, Stakeholder Communication, Product Architecture, Software Lifecycle Management, Financial Services, Legacy System Modernization, Infrastructure as Code (IaC), RDBMS Design, Technical Mentorship, Software Design Patterns\n\nimage4.png\n\nimage1.png\n\nimage2.png\n\nimage3.png
bdd4a1ec-6112-4052-9b8a-d6a3909be1bd	Joshua Smith	joshua.smith3117@gmail.com	Screening		0	Joshua Smith\n\nPrincipal .NET & Azure Product Engineer\n\njoshua.smith3117@gmail.com | +1-225-314-6763 | Arnaudville, Louisiana | LinkedIn\n\nPROFESSIONAL SUMMARY\n\nI am a Principal .NET and Azure engineer with nearly 10 years of hands-on experience building\n\nscalable, secure, cloud-native financial and enterprise applications. I specialize in C#, .NET Core,\n\nASP.NET Core, and SQL Server and have led multiple Azure migration and modernization efforts\n\ninvolving AKS, App Services, Functions, and Cosmos DB. I architect microservices and containerized\n\nplatforms using Docker and Kubernetes (AKS), designing robust CI/CD pipelines with Azure DevOps\n\nand GitHub Actions and infrastructure as code with Terraform and ARM. I adopt AI-assisted\n\ndevelopment workflows daily‚Äîpairing with GitHub Copilot and Claude to accelerate design iterations,\n\nauto-generate tests, and refactor large code bases while maintaining production-grade quality and\n\ncompliance. I practice TDD and build automated testing frameworks (unit, integration, contract, and\n\nAPI tests) integrated into pipelines so code is delivery-ready at merge. I have deep experience with\n\nEntity Framework Core, optimizing LINQ and SQL Server performance, and introducing caching layers\n\n(Redis) to reduce database load. I lead cross-functional teams and mentor engineers on cloud best\n\npractices, microservices patterns, DDD/CQRS, and observability using Application Insights,\n\nPrometheus, and Grafana. I design defensive security patterns for payment and financial systems:\n\ndata encryption, Key Vault secrets management, OAuth/JWT, and PCI-aligned logging practices. I drive\n\ncost efficiency and reliability through right-sized Azure services, autoscaling AKS, and resilient\n\npatterns like retries, circuit breakers, and event-driven architectures using Azure Service Bus and\n\nKafka. I collaborate closely with product, QA, and platform teams to translate stakeholder\n\nconversations into structured specifications and implement AI-driven SDLC processes that improve\n\nthroughput and reduce defects. I have a strong ownership mindset, experience working with\n\ndistributed and offshore teams, and a track record of delivering high-uptime, high-throughput\n\nsystems for regulated environments. I bring pragmatic engineering judgment coupled with deep\n\ntechnical execution‚Äîable to decompose complex domains into maintainable, measurable services\n\nthat deliver business outcomes.\n\nPROFESSIONAL EXPERIENCE\n\nPrincipal Software Engineer 07/2020 ‚Äì Present\n\nCoherent Solutions Remote / Arnaudville, LA\n\nArchitected and led a migration of legacy .NET Framework monoliths to .NET Core microservices\n\nhosted on Azure AKS and App Service, using Docker, Helm charts, and Terraform for\n\ninfrastructure; established service boundaries, API contracts (OpenAPI/Swagger) and reduced\n\ndeployment time by automating pipelines with Azure DevOps and GitHub Actions.\n\nDesigned a data modernization strategy that transitioned billing and transaction stores from on-\n\nprem SQL Server to managed Azure SQL and Cosmos DB for selective workloads, implemented EF\n\nCore migrations and tuned T-SQL / indexes to lower query latency for key reports.\n\nhttps://www.linkedin.com/in/joshua-smith-8879a037b/\n\n\nBuilt an automated CI/CD pipeline that enforced quality gates, running unit tests (xUnit),\n\nintegration tests, static analysis (SonarQube), code coverage (Coverlet), and contract tests for\n\nAPIs‚Äîintegrating test generation patterns to auto-provision test data and reduce manual QA\n\ncycles.\n\nIntroduced AI-assisted code workflows leveraging GitHub Copilot and Claude to accelerate\n\nprototyping and exploratory refactors; instituted pair-programming sessions with AI copilots where\n\nthe team iteratively generated code, tests, and documentation, increasing PR throughput.\n\nLed the design and implementation of a service mesh and observability stack on AKS using\n\nOpenTelemetry, Application Insights, Prometheus and Grafana; created dashboards and alerts\n\nwhich reduced MTTD (mean time to detection) and improved on-call response.\n\nSpearheaded the adoption of Domain-Driven Design and CQRS patterns across a payments\n\ndomain to decouple read/write workloads, using Event Sourcing where appropriate and Azure\n\nService Bus for reliable event delivery and at-least-once semantics.\n\nImplemented resilient patterns (retry, exponential backoff, circuit-breaker) in client libraries and\n\nservice-to-service comms using Polly and gRPC, significantly reducing transient error rates during\n\npeak load.\n\nDirected a team-level security initiative to centralize secrets in Azure Key Vault, adopt managed\n\nidentities, and standardize encryption-at-rest and in-transit, achieving compliance alignment and\n\nreducing secret-sprawl risk.\n\nOptimized database throughput by introducing Redis caching for frequently accessed account\n\nmetadata and policy evaluations, lowering SQL Server read-load by 48% and improving response\n\ntimes for API endpoints.\n\nMentored junior and mid-level engineers on TDD, SOLID principles, SOLID unit design, and writing\n\nproduction-grade code for financial services; established code review standards and a linting /\n\nformatting baseline across repos.\n\nCollaborated with product and UX to convert stakeholder conversations into structured\n\nspecifications, using AI copilots to translate flows into sequence diagrams, API contracts, and user\n\nstories that informed sprint planning.\n\nImplemented contract and API testing with Postman collections and automated them in pipelines;\n\nintroduced self-healing test strategies that rehydrate test data and run automated rollback in\n\nfailure scenarios.\n\nSoftware Engineer 11/2017 ‚Äì 06/2020\n\nSimform Remote / Arnaudville, LA\n\nDeveloped and maintained ASP.NET Core services and RESTful APIs using C# and Entity\n\nFramework Core backed by SQL Server; authored repository and unit-of-work patterns to keep\n\ndata access maintainable and testable.\n\nRefactored a monolithic billing module into modular services and introduced Docker containers to\n\nstandardize environments across dev/staging/production, enabling consistent deployments to\n\nAzure App Services and AKS.\n\nAutomated build-and-release pipelines using Azure DevOps Pipelines and YAML templates,\n\nincorporating integration tests and database migration steps to support zero-downtime\n\ndeployments.\n\nImplemented robust logging and tracing with Serilog and OpenTelemetry; correlated logs across\n\nmicroservices to diagnose production incidents faster and reduce MTTR for critical payment flows.\n\nDesigned and executed performance tuning for large T-SQL queries and EF Core LINQ patterns;\n\nadded covering indexes and query hints to improve analytical job performance.\n\n\n\nBuilt secure APIs with OAuth2 and JWT token validation, integrating with ADFS and Azure AD;\n\nenforced role-based access control and input validation to reduce attack surface.\n\nCollaborated with QA to define API contracts and generate contract tests, shifting-left test\n\ncoverage and increasing confidence in refactors and migrations.\n\nMigrated background job processing to Azure Functions where appropriate to lower compute costs\n\nand enable event-driven processing triggered by Service Bus messages and blob storage events.\n\nReduced cold-start and latency for serverless functions by tuning function app plans and\n\nimplementing function warm-up strategies and precompiled function bundles.\n\nContributed to cross-team design reviews, introducing best practices around microservices\n\nboundaries, database-per-service, and eventual consistency strategies.\n\nAutomated database schema migrations and rollbacks with EF Core Migrations and CI-run\n\nmigration validation to avoid drift between environments.\n\nPartnered with product owners to integrate small AI/automation experiments (scripted code-gen\n\nand test-case suggestions) that improved developer productivity and decreased small-ticket\n\nturnaround.\n\nApplication Developer 01/2016 ‚Äì 10/2017\n\nMercury Development Gulf Coast / Remote\n\nImplemented full-stack features for enterprise web applications using ASP.NET MVC, Web API,\n\nJavaScript and jQuery layered over SQL Server and stored procedures; enforced parameterized\n\nqueries to prevent SQL injection.\n\nBuilt reusable server-side components with dependency injection (Autofac) and unit-tested them\n\nusing MSTest to enable early, safe refactoring.\n\nCreated RESTful endpoints and documented them with Swagger/OpenAPI so third-party teams\n\ncould integrate programmatically with clear contracts.\n\nIntegrated message-based workflows using RabbitMQ for asynchronous processing of long-\n\nrunning jobs to decouple user requests from backend processing.\n\nAdministered CI pipelines with TeamCity and customized build scripts to run unit tests and\n\npackage artifacts for deployment.\n\nReduced application startup and response times by profiling with dotTrace, optimizing hot paths in\n\nC# and batching frequently used database calls.\n\nDesigned role-based UI components and server validation to comply with access rules and reduce\n\nfront-end complexity.\n\nAdopted coding standards and advocated for consistent branching strategies in Git, enabling\n\nmore predictable merges and release behavior.\n\nCollaborated with operations to automate releases to IIS and Azure App Services using PowerShell\n\nscripts and ARM templates for consistent environments.\n\nAuthored monitoring probes and alerts in Application Insights and Log Analytics to detect service\n\ndegradations early.\n\nTrained new hires on core platform frameworks, shared patterns, and troubleshooting approaches\n\nto accelerate onboarding.\n\nImplemented lightweight client-side modules with TypeScript and modular bundling with Webpack\n\nto improve maintainability and reduce front-end defects.\n\nPROJECTS\n\nAccount Reconciliation Microservice Platform 03/2019 ‚Äì 08/2019\n\nDesigned and delivered a standalone reconciliation microservice platform to consolidate transaction\n\n\n\nstreams from multiple payment rails. Architecture used ASP.NET Core microservices, gRPC for low-latency\n\ninterservice calls, PostgreSQL for ledger storage and Redis for in-memory reconciliation caches. The\n\nplatform handled out-of-order message reconciliation by using idempotent event handlers and event\n\ndeduplication through a deterministic hashing strategy. I introduced an event-driven pipeline with Kafka to\n\ndecouple ingestion and reconciliation, enabling horizontal scaling for high-throughput bursts. Security was\n\nhandled via OAuth2 JWT tokens, data encryption at rest, and Key Vault for secrets. Observability\n\nincorporated OpenTelemetry, Prometheus metrics and Grafana dashboards to surface reconciliation lag\n\nand throughput trends.\n\nReduced reconciliation latency by 62% through in-memory caching and parallelized reconciliation\n\nworkers, enabling same-minute reconciliation for 75% of transactions.\n\nImplemented idempotent handlers and deduplication that removed double-processing and\n\nreduced downstream correction jobs by 85%.\n\nScaled ingestion pipeline to handle 20k events/sec by partitioning Kafka topics and autoscaling\n\nconsumer groups on Kubernetes; architecture supported 3x traffic spikes.\n\nBuilt end-to-end observability with OpenTelemetry and Prometheus; created SLA-focused\n\ndashboards that cut incident diagnosis time by 45%.\n\nInstituted secure secret management with Key Vault and rotated credentials without downtime\n\nusing Kubernetes secrets updates and rolling restarts.\n\nTechnologies: C#, .NET Core, ASP.NET Core, gRPC, Kafka, PostgreSQL, Redis, Docker, Kubernetes, Prometheus,\n\nGrafana, OpenTelemetry, OAuth2, Azure Key Vault\n\nPayment Gateway Adapter Layer 09/2018 ‚Äì 12/2018\n\nDeveloped a modular payment gateway adapter layer to unify integration with multiple PSPs and banks. I\n\ndesigned the adapter using a plugin architecture in ASP.NET Core so new payment providers could be\n\nadded without application restarts. The system exposed secure RESTful APIs with OpenAPI definitions and\n\nused SQL Server for transaction persistence and Elasticsearch for transaction search and analytics. To\n\nhandle asynchronous provider callbacks I used Azure Service Bus and idempotency keys to protect against\n\nduplicate payments. I prioritized testability by generating contract tests for each provider adapter and\n\nrunning them in CI to validate integrations before deployment.\n\nReduced integration lead time for new PSPs from 6 weeks to 10 days by formalizing adapter\n\ncontracts and providing a reusable template.\n\nAchieved 99.98% transactional integrity by using idempotency keys and durable queue\n\nprocessing with Service Bus.\n\nEnabled near-real-time analytics by streaming transaction events to Elasticsearch and building\n\ndashboards for fraud and settlement teams.\n\nAutomated provider contract tests in CI to prevent regressions and catch schema drift prior to\n\nrollouts.\n\nImproved operational resilience by implementing retries, exponential backoff, and poison\n\nmessage handling for failed callbacks.\n\nTechnologies: C#, ASP.NET Core, Azure Service Bus, SQL Server, Elasticsearch, Azure DevOps, Docker,\n\nOpenAPI, xUnit, Postman\n\nDeveloper Productivity Toolkit with AI-Assisted Codegen 01/2020 ‚Äì 06/2020\n\nBuilt an internal developer productivity toolkit that integrated AI-assisted code generation and test\n\nscaffolding to accelerate feature delivery. The toolkit consisted of a CLI and VS Code extension that used\n\nlocal templates, Roslyn analyzers and an integration with GitHub Copilot-style flows to propose method\n\nimplementations and unit tests. I designed the architecture to run locally and optionally call hosted AI\n\ncopilots, capturing suggestions as PR drafts so engineers could review and accept changes. The toolkit also\n\nproduced baseline unit and integration tests (xUnit) and created boilerplate CI job definitions to speed\n\n\n\npipeline setup. Focus was on developer ergonomics, reproducible builds, and safe adoption of code-assist\n\nworkflows.\n\nReduced initial feature scaffolding time by 70% by providing four standardized templates and\n\nauto-generated test scaffolds.\n\nIncreased PR acceptance rates for junior engineers by providing vetted, reviewable AI suggestions\n\ncaptured as draft commits.\n\nDecreased flaky tests by integrating deterministic test-data generators and containerized test\n\nharnesses for integration tests.\n\nProduced CI templates that reduced pipeline setup time from days to under an hour for new\n\nmicroservices.\n\nPromoted safe AI adoption by inserting review checkpoints and automated static analysis (Roslyn)\n\nbefore any AI-suggested code could be merged.\n\nTechnologies: C#, .NET Core, Roslyn, VS Code Extension API, GitHub Copilot, xUnit, Git, Azure DevOps, Node.js\n\n(CLI), Docker\n\nEDUCATION\n\nBachelor of Science in Computer Science 2015\n\nUniversity of Miami\n\nSKILLS\n\nLanguages:  C#, T-SQL, SQL, JavaScript, TypeScript, Python, PowerShell, Bash, Java, Go, HTML5, CSS3\n\nFrameworks:  .NET, .NET Core, ASP.NET Core, Entity Framework Core, Dapper, gRPC, SignalR, React,\n\nNode.js, Express, Spring Boot, MassTransit, Flask, Django, xUnit\n\nDatabases:  Microsoft SQL Server, Azure SQL Database, Cosmos DB, PostgreSQL, MySQL, MongoDB,\n\nRedis, Elasticsearch\n\nTools:  Azure, Azure Kubernetes Service (AKS), Azure App Service, Azure Functions, Azure DevOps,\n\nGitHub Actions, Git, GitHub, GitLab, Docker, Kubernetes, Helm, Terraform, ARM templates, Prometheus,\n\nGrafana, Application Insights, OpenTelemetry, SonarQube, Serilog, ELK (Elasticsearch/Logstash/Kibana),\n\nNUnit, xUnit, MSTest, Postman, Swagger / OpenAPI, Kafka, RabbitMQ, Azure Service Bus, Key Vault, OAuth2\n\n/ JWT, Polly, dotTrace, dotMemory, Visual Studio, VS Code, Webpack, Azure Monitor, New Relic, Sentry,\n\nSelenium, Fiddler, Coverlet, JIRA, Confluence, Datadog, Cloudflare, Consul, Flux, ArgoCD, Claude\n\n(Anthropic), GitHub Copilot, MLflow, TensorFlow (exposure), Kibana, Cosmos DB Emulator, Azure Blob\n\nStorage, Power BI, SSIS
ce99cdcc-239f-4c5b-8428-2302e29f1c9d	Kaiwenshen Unknown	kaiwenshen4@gmail.com	Screening	Senior Full Stack Engineer	10	Kaiwen Shen \nSenior Full Stack Engineer \nkaiwenshen4@gmail.com  |  +1 (703) 596 2152 \nHouston, TX, 77063 \n   \n\nPROFESSIONAL SUMMARY \n\nResourceful Senior Full Stack Engineer with 10+ years of mastery in .NET, C#, SQL Server, and Azure \ncloud platforms. Adept at modernizing legacy applications, driving Azure migration, and augmenting \nengineering lifecycles with AI-assisted development. Skilled in building enterprise-grade, cloud-native \nsystems that transform financial and operational workflows. Known for adaptability, persistence, and \ncuriosity in solving sophisticated technical challenges, while fostering creativity and relationship-building \nacross distributed teams. \n\nWORK HISTORY \n\nBuilders Capital Remote \nSenior Full Stack Engineer Jan 2020 ‚Äì Aug 2025 \n\nBuilders Capital delivers private construction finance technology supporting builders, developers, and \ninvestors nationwide. \n\n‚óè Directed migration of legacy financial workflows to Azure cloud, re-platforming key modules with \n.NET Core, C#, and SQL Server. \n\n‚óè Orchestrated Azure services adoption (App Services, Functions, Cosmos DB, AKS), realizing a \nscalable loan lifecycle platform. \n\n‚óè Developed AI-driven analytics pipelines for project risk forecasting, enabling adaptive \ndecision-making. \n\n‚óè Applied pair-programming with GitHub Copilot to refactor debt servicing modules, accelerating \ndelivery velocity by 30%. \n\n‚óè Built automated test frameworks with xUnit and NUnit integrated into Azure DevOps pipelines, \nensuring seamless CI/CD. \n\n‚óè Designed microservices for payment disbursements and compliance checks, improving \nmodularity and resilience. \n\n‚óè Established intelligent monitoring with Application Insights and Log Analytics to self-heal \ncommon runtime failures. \n\n‚óè Guided junior engineers on cloud-native best practices, fostering persistence and creativity in \ntackling complex problems. \n\n‚óè Collaborated with cross-functional leaders to define architecture roadmaps aligned with financial \nservice compliance. \n\n‚óè Tech Skills/Challenges: .NET 6, C#, SQL Server, Azure Functions, Cosmos DB, GitHub Copilot, \nxUnit, Azure DevOps, Docker, Kubernetes. \n\nEyecue Lab Remote \nSenior Software Engineer Jan 2019 ‚Äì Jan 2020 \n\n\n\n \nEyecue Lab provides AI-enhanced design and development solutions for enterprise clients across \nhealthcare and retail. \n\n‚óè Delivered RESTful APIs in .NET Core and Node.js to support multi-channel e-commerce \nworkflows. \n\n‚óè Created CI/CD pipelines with Azure DevOps to automate deployments, boosting reliability of \nclient releases. \n\n‚óè Developed data pipelines integrating SQL Server and PostgreSQL for cross-platform reporting. \n‚óè Implemented unit and integration tests alongside code, reducing defect rates through continuous \n\nvalidation. \n‚óè Partnered with design teams to craft intuitive React and Angular frontends backed by resilient \n\nmicroservices. \n‚óè Adopted AI assistants to refactor front-end components, augmenting productivity and \n\nencouraging curiosity. \n‚óè Introduced API testing tools (Postman, Karate) to validate service resilience during rapid \n\niterations. \n‚óè Mentored mid-level developers in resourceful debugging techniques and adaptability within tight \n\nsprint cycles. \n‚óè Applied Docker containers and Kubernetes clusters to orchestrate deployments across hybrid \n\nenvironments. \n‚óè Tech Skills/Challenges: .NET Core, Node.js, Angular, React, SQL Server, PostgreSQL, Docker, \n\nKubernetes, Postman, Azure DevOps. \n\nHangar A Remote \nFull Stack Engineer Jun 2018 ‚Äì Jan 2019 \n\nHangar A is a leading air cargo delivery network that helps manufacturers and e-commerce businesses \nimprove sales and meet customer expectations through efficient logistics. \n\n‚óè Built scalable cargo tracking services in C# and .NET to synchronize inventory and shipment \ndata. \n\n‚óè Designed SQL Server schemas optimized for high-volume logistics workflows and real-time \nupdates. \n\n‚óè Partnered with Azure App Services to host APIs and secure customer-facing applications. \n‚óè Integrated external carrier APIs to streamline route planning and delivery notifications. \n‚óè Constructed React dashboards with intelligent filters to visualize cargo flow across the supply \n\nchain. \n‚óè Embedded automated testing frameworks ensuring reliability of flight-critical data pipelines. \n‚óè Enhanced system resilience with fault-tolerant microservices architecture deployed on \n\nKubernetes clusters. \n‚óè Supported business teams with adaptive reporting tools, promoting flexibility in client operations. \n‚óè Cultivated relationship-building with logistics partners, ensuring technical solutions met evolving \n\ndemands. \n‚óè Tech Skills/Challenges: .NET, C#, SQL Server, React, Azure App Services, Kubernetes, REST APIs, \n\nCI/CD. \n\nMotorPlatform Remote \nJunior-Mid Level Software Engineer Apr 2015 ‚Äì Jun 2018 \n\n\n\n \nMotorPlatform developed SaaS tools to connect auto dealerships with buyers through modern digital \nplatforms. \n\n‚óè Built core dealer management modules in ASP.NET MVC and SQL Server. \n‚óè Created Angular-based UIs to streamline lead tracking and vehicle inventory updates. \n‚óè Migrated legacy workflows to microservices, enabling resourceful feature evolution. \n‚óè Constructed APIs for third-party integrations (payment processors, CRM platforms). \n‚óè Implemented unit and end-to-end testing frameworks integrated into CI/CD pipelines. \n‚óè Introduced Azure Blob Storage for media handling, augmenting scalability. \n‚óè Tuned SQL queries to handle growing datasets, transforming reporting latency into near \n\nreal-time. \n‚óè Partnered with offshore teams, demonstrating persistence and emotional intelligence in \n\ncross-cultural collaboration. \n‚óè Delivered enhancements under tight deadlines, showcasing adaptability and problem-solving \n\nunder pressure. \n‚óè Tech Skills/Challenges: ASP.NET MVC, C#, SQL Server, Angular, Azure Blob Storage, \n\nMicroservices, API Integration, CI/CD. \n\nEDUCATION \n\nPurdue University                              West Lafayette, IN \nBachelor of Science in Computer Science                 2010 ‚Äì 2014 \n\nTECHNICAL SKILLS \n\nProgramming & Frameworks: .NET (Core, 6+), C#, ASP.NET MVC, Node.js, Python, JavaScript, \n\nTypeScript, Angular, React, Next.js \n\nCloud & DevOps: Azure (App Services, Functions, Cosmos DB, AKS, DevOps, Blob Storage, Application \n\nInsights), AWS (EC2, S3, IAM, VPC), GCP \n\nDatabases: SQL Server, PostgreSQL, MySQL, Cosmos DB, MongoDB \n\nTesting & QA: xUnit, NUnit, Jest, Mocha, Cypress, Karate, Selenium, TDD, Automated API Testing \n\nCI/CD & Tools: Azure DevOps, GitHub Actions, Docker, Kubernetes, Terraform, Jenkins \n\nAI & Automation: GitHub Copilot, Claude, LangChain, AI-driven testing, Intelligent monitoring, RAG \n\npatterns \n\nOther Skills: Microservices, REST APIs, GraphQL, Event-driven architecture, Identity Management, \n\nOAuth2, OpenID Connect, Agile/Scrum \n\n\n\tkaiwenshen4@gmail.com  |  +1 (703) 596 2152‚ÄãHouston, TX, 77063 \n\t   \n\tPROFESSIONAL SUMMARY \n\tWORK HISTORY \n\tBuilders Capital \n\tRemote \n\tSenior Full Stack Engineer \n\tJan 2020 ‚Äì Aug 2025 \n\tEyecue Lab \n\tRemote \n\tSenior Software Engineer \n\tJan 2019 ‚Äì Jan 2020 \n\tHangar A \n\tRemote \n\tFull Stack Engineer \n\tJun 2018 ‚Äì Jan 2019 \n\tMotorPlatform \n\tRemote \n\tJunior-Mid Level Software Engineer \n\tApr 2015 ‚Äì Jun 2018 \n\n\tEDUCATION \n\tPurdue University‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã                      West Lafayette, IN‚ÄãBachelor of Science in Computer Science‚Äã‚Äã‚Äã‚Äã ‚Äã‚Äã   ‚Äã      2010 ‚Äì 2014 \n\tTECHNICAL SKILLS
0faee9fb-5839-4786-95df-6a82408cd0a6	Lesuhailofficielle Unknown	lesuhailofficielle@gmail.com	Screening	Senior Software Engineer	10	Suhail Ahmed  Senior Software Engineer\n\nlesuhailofficielle@gmail.com +1  (512) 737-2505  Austin TX \n\nlinkedin.com/in/suhail-ahmed-3a8a38286 \n\nPROFILE\n\nExperienced IT and Software Development professional with over 10 years in the industry, specializing in the .NET \nTechnology and adept at delivering robust solutions for large enterprises. Proven expertise spans system analysis, \ntechnical leadership, and project management, with a focus on developing intricate applications for diverse sectors \nincluding ERP, healthcare, finance, HR, banking, e-commerce, inventory, and accounting. Proficient in data \nmigration, technical documentation, UML designing, application architecture, and well-versed in Agile practices, \ntest-driven development, and software engineering design patterns, holding certifications as a Microsoft Certified \nProfessional Developer (MCPD) and Microsoft Certified Technology Specialist (MCTS).\n\nEDUCATION\n\nB.S. in Computer Science\nThe University of Texas at Arlington\n\n08/2012 ? 12/2015  | Arlington, TX\n\nSKILLS\n\nClient-Side:¬†HTML, HTML5, CSS, CSS3, Jquery, Vue JS, angular.js, Angular14/18 Javascript, React JS, Next JS,\nRedux, TypeScript, Bootstrap, Material UI, UI/UX, Tailwind CSS, ES6, npm, SASS, Ajax, React-Redux, NgRx, RxJs,\nKarma, Mocha, Wireframes, Three.js, MobX, Webpack, React Hooks, React Router, SAML, Build Tools, Containers,\nSPA, PWA, CMS, RWD, React Native, CloudFormation, ES6, ES5, ES4, Atomic CSS, Vue Js\n\nServer-Side:¬†.NET Core, .NET Framework, Microsoft SQL Server, PostgreSQL, ASP.NET Core, C#, Elastic Search,\nDynamoDB, Node.js, Javascript, LLM, Kubernetes, Docker, GraphQL, AWS, Microservices Architecture, ASP.NET Web\nForms, WCF, RESTful APIs, Data Structures, Design Patterns, Storybook, MVC, Azure SQL, Apache, TypeORM,\nSingleton, Distributed Systems, ASP.NET MVC, Debugging, CRM, RDBMS, DBMS, SOAP/REST, Typescript, Fast API,\nREST API, GraphQL, gRPC, Automation Testing, ECS, ECR, Continuous Integration, AWS Cloud, Big Data,\nCassandra, Database Design, Azure Active Directory, Azure Cloud, AKS, Azure Functions, Lambda, JSON, JWT, Git,\nDevSecOps, Kanban, AWS S3, AWS DynamoDB, RESTful APIs, GraphQL, MVC architecture, Relational Databases,\nDebugging, WebSockets, Singleton\n\nDevelopment & Operations:¬†CI/CD Pipelines, Azure Data Factory, Azure Data Lake Storage, Azure Functions,\nAzure SQL Database, Azure Databricks,Azure Synapse Analytics, Azure Logic Apps, Azure DevOps, Docker, GitHub,\nGitLab, UNIX, Google Cloud Platform, Heroku, AWS,Jest, Mocha, Unit Test, Wireframes, Agile Scrum, Git, NPM,\nSwagger, Webpack, Kubernetes, JIRA, Linux, SDLC,Functional Testing, Selenium, Mockups, Scrum Methodology,\nTechnical Leadership, Unit Testing, Kanban, Power BI,Power BI Service, Power BI Report Server, DAX, Power\nBI/Fabric, xUnit, Test Driven Development, RDBMS, Docker, ECommerce, ERP Solutions, Agile Scrum, Version\nControl, Caching, Data Integration, User Acceptance Testing,Documentation, Docker, GitHub, GitLab, AWS, Jest,\nMocha, Unit Test, Wireframes, Swagger, Webpack, JIRA, Google Cloud Platform, DevSecOps, Kafka, Next.js, Jasmine,\nPerformance Testing, Trello, Jenkins, JMS, Json, Kubernetes, liquidbase, RabbitMQ, TestNG, agile\nmethodologies,database management\n\n1 / 5\n\nmailto:lesuhailofficielle@gmail.com\ntel:+1 %E2%80%AA(512) 737-2505%E2%80%AC\nhttps://linkedin.com/in/suhail-ahmed-3a8a38286\n\n\nPROFESSIONAL EXPERIENCE\n\nMembersy\nSenior Software Engineer\n\n01/2021 ? present  | Romote\n\n?Led the modernization of a HIPAA-compliant Membership Management System (MMS) using C#, .NET Core, and \nAngular/TypeScript, incorporating HL7 and FHIR standards for secure healthcare data exchange.\n\n?Redesigned a .NET MVC monolith healthcare application into a service-oriented architecture (SOA) and \nrefactored legacy .NET Framework applications into .NET Core, making applications cloud-native.\n\n?Designed, built, and optimized microservices architecture using .NET Core 6 / 8, Azure Functions, and AKS.\n\n?Built high-performance REST and GraphQL APIs for MMS with Apollo Federation and Swagger, and integrated \nTwilio for real-time SMS alerts and notifications.\n\n?Architected and implemented a comprehensive ERP system, integrating core business functions like finance, HR, \ninventorymanagement, and procurement, leading to a 35% increase in operational efficiency.\n\n?Developed dynamic, interactive user interfaces with Angular, utilizing NgRx for efficient state management and \nAngular Router for seamless navigation; optimized UI components for reusability and responsiveness, integrating \nTailwind CSS and Bootstrap to deliver highly performant, mobile-first applications.\n\n?Implemented RBAC and Single Sign-On (SSO) using OAuth 2.0, OpenID Connect, and Azure AD.\n\n?Led the integration of GitHub Copilot and Cursor to assist developers in auto-generating code for HL7 message \nparsing and FHIR resource mapping, cutting implementation time by 30%.\n\n?Integrated Apache Kafka for real-time data streaming and asynchronous messaging, boosting communication \nefficiency across dental services by 3x.\n\n?Designed a credit card payment integration microservice using Stripe and PayPal APIs, enabling secure, PCI-\ncompliant transactions for our healthcare projects.\n\n?Optimized data access with Entity Framework Core 6 and SQL Server schema refactoring and added Redis-based \ndistributed caching to reduce database load and speed up retrieval.\n\n?Designed and implemented robust ETL pipelines using SSIS, Azure Data Factory, and Azure Blob Storage, \nautomating data extraction, transformation, and loading.\n\n?Built CI/CD pipelines with Azure DevOps, automated infrastructure using Terraform and ARM templates, and \napplied Git strategies for smooth deployments and version control.\n\n?Developed a HIPAA-compliant Python data pipeline using Pandas for patient data integration and real-time \nreporting, and integrated an AI-powered chatbot into MMS for real-time user support and troubleshooting \nthrough NLP-driven query understanding.\n\n?Used structured prompt engineering to build AI-driven utilities that validated ICD-10 codes and auto-suggested \nCPT mappings, significantly reducing manual review time for care coordinators.\n\n?Wrote unit tests and integration tests using xUnit and Jasmine, ensuring high-quality code delivery.\n\n?Led cross-functional Agile teams of 8 members, facilitating Scrum ceremonies, mentoring junior engineers on \ncoding, design, and DevOps best practices, and creating internal documentation to promote CI/CD, Azure \nstandards, and cloud-native development.\n\n \n\nBank of America\nSoftware Developer (.NET & React)\n\n06/2015 ? 12/2020  | Westmont, IL\n\n?Designed and delivered robust web applications using .NET Core MVC and React.js, leveraging a component-\nbased architecturefor responsive and interactive user interfaces.\n\n?Utilized Entity Framework Core with SQL Server to implement efficient data models and queries, ensuring \noptimal performanceand scalability.\n\n2 / 5\n\n\n\n?Implemented clean architecture principles, ensuring modular, maintainable, and testable code while enhancing \nteam collaborationand development efficiency.\n\n?Developed and consumed RESTful APIs adhering to industry best practices, enabling seamless communication \nbetween frontend and back-end systems.\n\n?Integrated RabbitMQ with ASP.NET backend services, enabling real-time messaging and communication between \nservices for efficient transaction processing.\n\n?Incorporated SignalR for real-time functionalities, such as live notifications and updates, to enhance user \nexperience andengagement.\n\n?Built responsive, modular user interfaces using Vue and React, integrating seamlessly with .NET backend services \nfor high maintainability and performance.\n\n?Next.js with React and Nuxt.js with Vue JS to implement server-side rendering (SSR) and static site generation, \nimproving SEO, load times, and performance. \n\n?Configured in-memory caching and applied data validation to improve application performance and ensure data \nintegrity acrosscomplex workflows.\n\n?Established CI/CD pipelines using Azure DevOps, automating builds, testing, and deployments to deliver high-\nquality solutions inan agile development cycle.\n\n?Built a distributed authorization system with C#, ASP.NET Core, and OPA. Improved performance by 30% using \nRedis for cachingand JWT for secure token-based authentication.\n\n?Integrated AWS S3, AWS RDS, and AWS DynamoDB for scalable storage, relational database management, and \nNoSQL data solutions, optimizing the system architecture for cloud-native environments.\n\n?Utilized AWS Lambda for serverless computing, implementing Python-based microservices for on-demand data \nprocessing workflows in AWS.\n\n?Backend Development & Scalable Architecture: Developed RESTful and GraphQL APIs using C# and ASP.NET \nCore. AppliedCQRS, Mediator, and Repository patterns with Cosmos DB and MariaDB to deliver scalable, \nmaintainable solutions.\n\n?Cloud-Native Solutions with Azure & AWS Deployed cloud solutions with Azure Functions, Cosmos DB, Service \nBus) and AWS(Lambda, DynamoDB, S3, optimizing for scalability and cost-efficiency, reducing infrastructure \ncosts by 25%.\n\n  \n\nPROJECTS\n\nModernization of Membership & Outreach Healthcare Platform\n?Led the transformation of Membersy?s Membership Management System (MMS) to enhance membership lifecycle \nmanagement, automate billing and renewals, improve patient communications, and ensure seamless integration \nwith healthcare partner systems.\n\n?Refactored legacy .NET Framework apps into .NET Core 6/8 microservices and deployed them to Azure AKS using \nHelm and CI/CD via Azure DevOps.\n\n?Designed secure REST and GraphQL with OAuth 2.0 and JWT, integrated Twilio for real-time SMS notifications.\n\n?Engineered scalable front-end modules using Angular 14 and 18, leveraging RxJS for reactive state management, \nAngular Material for consistent UI/UX, and Lazy Loading to optimize performance \n\n?Built HL7/FHIR-compliant data integration between EHR and external lab services using secure .NET APIs and \nKafka for async messaging.\n\n?Integrated Microsoft Dynamics 365 and Sitecore with backend services for CRM and content management.\n\n?Enhanced patient-facing and admin interfaces using Angular, Blazor WebAssembly, and Xamarin.\n\n?Implemented ETL pipelines using SSIS, Azure Data Factory, and Blob Storage to automate data flows.\n\n3 / 5\n\n\n\nTech Stack: C#, .NET 6/8, ASP.NET Core, Angular 14/18, ¬†Azure, AKS, Azure Functions, Cosmos DB, SQL Server, Kafka, \nSitecore, Microsoft Dynamics 365, OAuth2, HL7/FHIR\n\nMedSync Billing Hub\n?Built a unified billing hub for ambulatory care centers that automated patient invoicing, insurance coordination, \nand payment follow-ups.\n\n?A high-performance financial platform designed to enhance user experience through seamless integration of \nASP.NET Core, C#,React.js, and Azure cloud technologies.\n\n?Developed dynamic, scalable front-end applications using React.js for a responsive and user-friendly interface.\n\n?Built secure and high-performance backend services with ASP.NET Core and C#.Managed containerized \ndeployments and scaling with Azure Kubernetes Service AKS and Azure Container Registry ACR.\n\n?Created reusable, modular UI components for maintainability and efficiency.Integrated front-end and back-end \nlogic for smooth data handling and interaction.\n\n?Ensured secure authentication and access management using Azure AD and Managed Identities.\n\n?Followed SOLID principles to deliver maintainable and scalable software solutions.Streamlined CI/CD processes \nusing Azure DevOps for fast and reliable deployments.\n\nCore Skills: ASP.NET Core, C#, React.js, Azure, Azure Kubernetes Service AKS, Azure Container Registry ACR, Azure \nAD,Managed Identities, SOLID Principles, CI/CD, Cloud Infrastructure.\n\nEnd-to-End ERP System for Business Operations Cloud Services\n?Utilized Azure to deploy cloud-based infrastructure, improving system scalability and performance.\n\n?Power BI Integration: Designed data models to facilitate future integration with Power BI for real-time analytics.\n\n?ERP System Development: Developed a comprehensive ERP system to manage resource planning, inventory, and \nfinancial accounting.\n\n?Full-Stack Development: Led development using ASP.NET Core for the backend and React for the frontend, \nensuring a seamlessuser experience.\n\n?API Integration: Created secure REST APIs for inter-module communication and integrated external services for \nreal-time dataupdates.\n\n?Impact & Efficiency: Reduced operational costs by 25% and boosted business productivity by 40% through \nimproved dataaccessibility and real-time decision-making.\n\nTech Stack: ASP.NET Core, C#, MS SQL Frontend: React Cloud: Azure API REST APIs Reporting: Power BI (future \nintegration)\n\nWorkforce Platform ? Enterprise Resource Optimization\n?Led the end-to-end migration of a large-scale Workforce Optimization Platform to Azure, modernizing legacy \ncomponents into cloud-native microservices using .NET Core, Azure Functions, and AKS. \n\n?Redesigned and deployed Angular-based role-based dashboards for real-time analytics and dynamic scheduling \ncapabilities. \n\n?Integrated third-party HR, payroll, and performance APIs using Azure API Management and Logic Apps, while \nimplementing Azure SignalR and Event Grid for real-time shift notifications. \n\n?Oversaw database transitions to Azure SQL and CosmosDB, optimizing performance with indexing and caching \nstrategies. \n\nTech Stack: Angular, TypeScript, .NET Core 3.1/6, C#, ASP.NET Web API, Azure Functions, Azure Kubernetes Service \n(AKS), Azure API Management, Azure Logic Apps, Azure Event Grid, Azure SignalR, Azure Blob Storage, Azure SQL, \nCosmosDB, MongoDB, Redis, Azure DevOps, Terraform, Git, JMeter, Postman, NUnit, xUnit, OAuth 2.0, JWT.\n\n4 / 5\n\n\n\nDev&Mark Healthcare System\n?A cutting-edge, customer-facing healthcare platform designed to revolutionize how medical professionals \ndiagnose and plantreatments for patients.\n\n?A customer-facing healthcare platform to assist medical professionals in diagnosing and planning treatments \nthrough an intuitive, adaptive interface. \n\n?Built for performance, scalability, and security using ASP.NET Core, C#, React.js, and Azure.Developed a dynamic \nUI with React.js and TypeScript, guiding users through adaptive diagnostic workflows.\n\n?Integrated Azure SignalR and Cosmos DB for real-time updates and data management.\n\n?Secured user authentication with Azure AD B2C.Automated deployments using Azure DevOps and GitHub \nActions.Delivered pixel-perfect, responsive designs and optimized performance.\n\nCore Skills Used: ASP.NET Core, C#, React.js, TypeScript, Azure, REST APIs, CI/CD, Frontend Performance \nOptimization,Mentorship, SOLID Principles.\n\nFintech Project - Trading App\n?I was part of an innovative fintech project that developed a robust n-tier architecture application for trading \nfirms, integrating multiple stock market data providers. The application enabled efficient portfolio management, \nreal-time operations, and datadriven insights in a high-frequency trading environment.\n\n?I contributed to the design and implementation of multi-threading programming to handle large data volumes, \nensuring lowlatency results.\n\n?Key tasks included optimizing system performance with Redis, implementing RabbitMQ for message queuing, \nand using SignalR /WebSocket's for real-time communication.\n\n?Key tasks included optimizing system performance with Redis, implementing RabbitMQ for message queuing, \nand using SignalR /WebSocket's for real-time communication.\n\n?Designed and implemented a scalable n-tier architecture for seamless integration with external data providers. \n\n?Utilized multithreading and real-time data processing to deliver low-latency performance .Optimized \nperformance using Redis and RabbitMQ for efficient data handling.\n\n?Ensured robust system security and efficient data handling through AWS infrastructure, safeguarding sensitive \nuser data andmaintaining system integrity.\n\n?Developed dynamic UIs with React, Material UI, and JavaScript .Automated deployments and continuous \nintegration using CI/CDpipelines.\n\n?Collaborated closely with the back-end team to ensure smooth API integration and optimal front-end-backend \ncommunication,providing a seamless user experience.Ensured quality with unit and integration testing NUnit).\n\nSkills : Backend: .NET Core, C#, Multithreading, SQL, RabbitMQ Frontend: React, Material UI, JavaScript Real-time: \nSignalR,WebSockets Performance: Redis Cloud: Azure VMDevOps: CI/CD Pipelines Testing: NUnit\n\nDev&Mark ATS System\n?Developed an advanced, high-performance Applicant Tracking System ATS to optimize recruitment workflows \nand enhance user experience through seamless integration of frontend and backend technologies. \n\n?The system ensures fast, secure, andscalable operations for modern recruitment teams.Built responsive frontend \nwith React.js and Material UI, reducing development time by 45%.\n\n?Created scalable backend APIs with ASP.NET Core and C#.Integrated WebSockets for real-time data updates.\n\n?Used MongoDB for flexible, efficient data storage.Leveraged Azure for cloud storage and Azure AD for secure \nauthentication.Implemented OAuth 2.0 and JWT for secure authentication.\n\n?Automated CI/CD with Azure DevOps and GitHub Actions for faster deployments.\n\nCore Skills: ASP.NET Core, C#, React.js, Material UI, MongoDB, Azure, WebSockets, OAuth 2.0, JWT, CI/CD.\n\n \n\n5 / 5
2aae97c1-1e4c-417b-833b-72cca4db4976	Logancollins Unknown	logancollins8888@gmail.com	Screening	Full Stack Developer	8	Logan Collins          Senior Software Engineer \n\n267 HILBERN COLLINS RD  \n\nLyons, Toombs, GA \n\n+1 229 207 5466 \n\nlogancollins8888@gmail.com \nhttps://www.linkedin.com/in/logan-collins-3ba466370/ \n\nSummary \n\nResults-driven .NET Full Stack Developer with over 9 years of experience designing, developing, and deploying high-impact, \n\ncloud-native applications across industries including FinTech, InsurTech, and SaaS. Expert in building scalable backend \n\nservices using .NET Core, C#, and CQRS architectures, while delivering rich, responsive frontends using Angular, React, \n\nBlazor, and WPF. Adept at crafting microservice-based systems in both Azure and AWS, with experience in hybrid cloud pilots \n\nvia GCP. \n\nProven ability to modernize monolithic systems into decoupled, event-driven platforms using Azure Kubernetes Service \n\n(AKS), RabbitMQ, Redis, and WebSockets (SignalR). Deep experience with WCF/SOAP to REST migration, API security \n\n(OAuth2, OpenID Connect, Azure AD) and frontend performance optimization using SSR, lazy loading, and NgRx state \n\nmanagement. Proficient in managing multi-database environments across Azure SQL, SQL Server, Oracle PL/SQL, and \n\nMongoDB, with strong skills in T-SQL optimization and cross-system reconciliation. \n\nExperienced in Python scripting for automation, data transformation, and AI/ML integration within .NET-based ecosystems. \n\nSkilled in leveraging machine learning models and intelligent APIs to enhance product capabilities and deliver data-driven \n\ninsights. \n\nCollaborative team leader and mentor, known for implementing Agile best practices, spearheading CI/CD initiatives with \n\nAzure DevOps and Terraform, and fostering scalable, maintainable software ecosystems. Passionate about translating \n\ncomplex business needs into intuitive, robust digital products. \n\nSkills \n \nLanguages/Frameworks: C#, .NET Core, JavaScript, TypeScript, Python, Razor, VB.NET, T-SQL \n\nFrontend: Angular, React.js, Blazor, HTML5, SCSS, Bootstrap, RxJS, SignalR \n\nCloud & Backend: Azure (AKS, Functions, App Services, Cosmos DB, SQL, API Management, Redis), AWS (Lambda, ECS, S3), \n\nGCP (Compute, Cloud SQL), Node, OAuth2, REST, GraphQL, gRPC,  WCF, SOAP, CQRS, RabbitMQ, WebSockets (SignalR) \n\nDevOps & Monitoring: Azure DevOps, Docker, Kubernetes, Terraform, ELK Stack, Elasticsearch, Kibana, Logstash \n\nTesting: xUnit, NUnit, Moq, Jest, Postman \n\nDatabases/Messaging: SQL Server, PostgreSQL, MongoDB, Apache Kafka, Azure Service Bus \n\nTools: Git, Jira, Figma, Visual Studio, BrowserStack \n\nExperience \nAPR 2022 - MAR 2025 \n\nMaybeWorks, Newark, DE - Senior Software Engineer \n\n‚óè Designed cloud-native microservices using .NET Core and deployed to Azure Kubernetes Service (AKS) with \n\nDocker containers and Azure Container Registry for automated rollouts. \n\n \n\nmailto:logancollins8888@gmail.com\n\n\n2 \n\n‚óè Implemented CQRS pattern using MediatR, separating command/query logic for better performance and testing. \n\n‚óè Created frontend architecture in Angular 14+, implementing lazy loading, custom SCSS themes, Material UI and \n\nmodular component design. \n\n‚óè Led development of real-time dashboards using Blazor Server and SignalR, enabling live operational visibility for \n\ninternal stakeholders. \n\n‚óè Developed secure and scalable REST APIs using Azure Functions and managed APIs through Azure API \n\nManagement with rate limiting, OpenID Connect and OAuth2.0. \n\n‚óè Implemented bi-directional streaming with gRPC to support real-time data updates between services. \n\n‚óè Designed WebSocket-based real-time features using SignalR, enabling live chat and notification services for admin \n\ndashboards. \n\n‚óè Utilized Redis for distributed caching and pub-sub messaging to improve response times and decouple services. \n\n‚óè Integrated RxJS and NgRx for sophisticated state handling across multiple enterprise modules. \n\n‚óè Translated UI/UX designs from Figma to responsive SPAs and conducted cross-device/browser testing using \n\nBrowserStack. \n\n‚óè Managed backend data via Azure SQL, optimizing stored procedures and indexes for high-load APIs. \n\n‚óè Automated deployments using Azure DevOps Pipelines, integrated with Terraform to provision AKS clusters, App \n\nServices and Cosmos DB. \n\n‚óè Implemented Python scripting within .NET-based CI/CD pipelines to perform pre-deployment checks and automated \n\nreporting. \n\n‚óè Embraced AI productivity tools such as ChatGPT, Claude, and GitHub Copilot to generate code snippets, debug \n\nlogic, and prototype faster. \n\n‚óè Integrated ELK Stack (Elasticsearch, Logstash, Kibana) for centralized logging, real-time monitoring and alerting \n\nacross distributed microservices. \n\n‚óè Mentored a team of 5 junior developers, led code reviews and hosted internal technical workshops across frontend \n\nand backend domains. \n\n‚óè Enforced enterprise-grade security across the stack using Azure Active Directory (RBAC) and SSO. \n\n‚óè Wrote integration test suites and implemented full CI coverage using xUnit, Jest, Cypress and Postman. \n\nJAN 2019 - MAR 2022 \n\nCloudforce, Oxon Hill, MD - Full Stack Developer \n\n‚óè Migrated monolithic frontend from legacy jQuery to React + TypeScript, improving modularity, testability and \n\nresponse time. \n\n‚óè Designed reusable UI libraries with styled-components and SCSS, enabling faster branding pivots and scalable UI \n\nsystems. \n\n‚óè Developed microservices using .NET Core hosted in Azure App Services and integrated with Azure Functions for \n\nbackground processing. \n\n‚óè Implemented server-side rendering (SSR) for React apps to improve performance and SEO on client portals. \n\n‚óè Developed and deployed Node.js-based middleware to serve SSR React applications, enabling improved SEO and \n\ntime-to-first-paint for marketing pages. \n\n‚óè Built async workflows using RabbitMQ for decoupled background job processing and event publishing. \n\n‚óè Authenticated and authorized client access using JWT, OAuth2.0 and federated login via Azure AD. \n\n‚óè Orchestrated frontend/backend contracts using GraphQL and REST, improving query flexibility and payload \n\noptimization. \n\n‚óè Integrated Azure Cosmos DB and SQL Server and implemented entity models with Entity Framework (Code First). \n\n\n\n3 \n\n‚óè Worked with both Azure SQL and Oracle PL/SQL, ensuring cross-platform consistency and performance tuning. \n\n‚óè Wrote test suites with NUnit, Moq and Jest, covering unit, integration and snapshot testing for both client and \n\nserver. \n\n‚óè Led sprint planning and backlog grooming in Agile teams using Jira, ensuring delivery velocity and stakeholder \n\nalignment. \n\n‚óè Documented frontend workflows and onboarding guides to streamline developer ramp-up across teams. \n \n\nAUG 2016 - NOV 2018 \n\nLENET, Sandy Springs, GA - .NET Application Developer \n\n‚óè Developed backend services in C# (.NET Framework) and transitioned from WCF/SOAP to RESTful Web APIs for \n\nthird-party integrations. \n\n‚óè Maintained and extended internal desktop tools using WPF, including real-time compliance monitors and data \n\nimport utilities. \n\n‚óè Designed cloud-first workflows using AWS Lambda, S3 and ECS, allowing scalable, asynchronous processing for \n\ncompliance reporting systems. \n\n‚óè Upgraded frontend from VB.NET to ASP.NET MVC + Razor Views, introducing reusable templates, dynamic forms \n\nand accessible UI. \n\n‚óè Built admin dashboards and analytics tools using Bootstrap, jQuery and AJAX with robust error handling and \n\ngraceful degradation. \n\n‚óè Maintained complex data orchestration across SQL Server, PostgreSQL and MongoDB, ensuring consistency in \n\nregulatory audit trails. \n\n‚óè Participated in a pilot cloud migration using GCP Compute Engine and Cloud SQL, contributing to feasibility \n\nassessments and prototype deployment. \n\n‚óè Created CI pipelines using xUnit, Moq and custom scripting, supporting multi-environment test execution. \n\n‚óè Authored technical documentation for internal systems, API usage and onboarding of new engineers. \n\n‚óè Participated in system monitoring, log aggregation setup and drafted incident response guides as part of DevOps \n\ninitiatives. \n\nEducation \nSEP 2013 - MAY 2016 \n\nGeorgia State University, Atlanta GA - Bachelor Degree of Computer Science \n \n\n\n\tLogan Collins          Senior Software Engineer \n\tSummary \n\tSkills \n\tExperience \n\tAPR 2022 - MAR 2025 \n\tMaybeWorks, Newark, DE - Senior Software Engineer \n\n\tJAN 2019 - MAR 2022 \n\tCloudforce, Oxon Hill, MD - Full Stack Developer \n\n\tAUG 2016 - NOV 2018 \n\tLENET, Sandy Springs, GA - .NET Application Developer \n\n\n\tEducation \n\tSEP 2013 - MAY 2016 \n\tGeorgia State University, Atlanta GA - Bachelor Degree of Computer Science
490819d7-45b3-4d41-b8c0-a413180cf90d	Mannyiskewl Unknown	mannyiskewl47@outlook.com	Screening	Senior Software Engineer / Lead Software Engineer	5	Mar 2022 - Present\n\nMANUEL MALDONADO\n\nSenior Software Engineer\n\n‚úâ  mannyiskewl47@outlook.com ÔÇï  (210) 606-9226 ÔÇå  www.linkedin.com/in/manuel-maldonado-js\n\nÔÄá SUMMARY\n\nAccomplished Senior Software Engineer with over 10 years of experience specializing in .NET, C#, and cloud-native\n\napplications on Azure. Demonstrated expertise in leading the design, development, and deployment of scalable,\n\nenterprise-grade solutions integrating AI-driven testing frameworks to enhance software quality and delivery speed.\n\nProven ability to mentor cross-functional teams in implementing Azure migration strategies and promoting best practices\n\nin cloud engineering and continuous integration/continuous delivery (CI/CD). Highly adaptable and collaborative, thriving\n\nin fast-paced, agile environments with enhanced AI-assisted workflows to produce robust, production-grade financial\n\nservices software.\n\nÔÑ° SKILLS\n\nProgramming\n\nLanguages\nC#, VB.NET, F#, SQL, JavaScript, TypeScript, Python, Java, PowerShell, R\n\nFrameworks &\n\nLibraries\n\n.NET Framework, .NET Core, ASP.NET, Entity Framework, Azure Functions, Microservices, REST\n\nAPIs, xUnit, MSTest, NUnit, Razor\n\nTools &\n\nPlatforms\n\nAzure DevOps, Github Copilot, Claude, Visual Studio, Azure Portal, Azure Kubernetes Service\n\n(AKS), Azure Cosmos DB, Azure App Services, Docker, Kubernetes, Git, Terraform, Pulumi, Jenkins,\n\nCircleCI, Postman, Swagger, Jira, Confluence, SonarQube, NServiceBus\n\nDatabases\nSQL Server, Microsoft Azure SQL Database, Azure Cosmos DB, PostgreSQL, MySQL, Redis,\n\nElasticsearch, MongoDB, Oracle, SQLite\n\nDevOps & CI/CD\n\nAzure Pipelines, GitHub Actions, CI/CD automation, Infrastructure as Code (IaC), Containers,\n\nDocker Compose, Kubernetes Helm, Terraform, Packer, Monitoring and Logging (Azure Monitor,\n\nApplication Insights), Automated Testing (TDD), SonarQube\n\nOther Skills\nAI-assisted Development, Automated Testing, TDD, Pair Programming, API Design, Cloud\n\nMigration, Microservices Architecture\n\nÔÇ£ CERTIFICATIONS\n\nMicrosoft Certified: Azure Solutions Architect Expert\n\nMicrosoft Certified: Azure Developer Associate\n\nMicrosoft Certified: DevOps Engineer Expert\n\nMicrosoft Certified: Azure Fundamentals\n\nÔÇ± EXPERIENCE\n\nSenior Software Engineer / Lead Software Engineer\n\n\n\nApril 2020 - Mar 2022\n\nGusto\n\nSpearheaded the development of modular, scalable payroll APIs using .NET Core, C#, and Azure App Services that\n\nenabled seamless integration for partner businesses, leveraging Azure Functions for serverless compute and\n\nasynchronous task processing.\n\nArchitected and optimized cloud-native applications hosted on Azure Kubernetes Service (AKS), implementing\n\nresilient microservices architectures with Docker containers and automated CI/CD pipelines through Azure DevOps.\n\nLed migration of legacy payroll systems to Azure SQL Database and Azure Cosmos DB, designing adaptive database\n\nschemas with Entity Framework that ensured high availability and performance under heavy transactional loads.\n\nIntegrated AI-assisted development tools such as GitHub Copilot and Claude into daily workflows, enhancing code\n\nquality and accelerating feature delivery cycles within an AI-driven SDLC environment.\n\nImplemented robust automated testing frameworks combining xUnit, MSTest, and AI-powered test case generation\n\nwhich identified potential regressions early during continuous integration via Azure Pipelines.\n\nMentored and coached junior engineers on cloud architecture best practices, microservices design patterns, and\n\nefficient use of Azure cloud ecosystem services to foster skill growth and team delivery excellence.\n\nDeveloped and maintained scalable API gateways using ASP.NET Core integrated with Azure Functions and Serverless\n\narchitectures to manage multi-tenant payroll workflows with strict compliance and security controls.\n\nCollaborated with product and security teams to design idempotent and fault-tolerant cloud-native services utilizing\n\nAzure Service Bus and distributed caching to optimize throughput and reduce latency.\n\nConducted performance tuning and stress testing of SQL queries and Cosmos DB containers to reliably process tens\n\nof billions of dollars in payroll transactions annually.\n\nLed design reviews and architectural discussions adopting Domain-Driven Design (DDD) and CQRS to decouple\n\ncomplex business logic and enhance long-term system maintainability.\n\nAutomated infrastructure provisioning for dev, test, and production environments using Terraform and ARM templates,\n\nsupporting rapid environment creation and rollback strategies.\n\nChampioned usage of SonarQube static code analysis integrated with Azure DevOps pipelines to enforce coding\n\nstandards and reduce technical debt.\n\nPartnered with cross-functional teams to implement secure authentication modules using OAuth 2.0, OpenID Connect,\n\nand Azure Active Directory B2C for multi-tenant payroll services.\n\nEnhanced observability through Azure Monitor and Application Insights, enabling proactive detection and\n\ntroubleshooting of production incidents.\n\nExplored AI/ML integration opportunities leveraging Azure Cognitive Services to improve payroll fraud detection and\n\nanomaly analysis.\n\nCreated detailed documentation and developer portals using Swagger/OpenAPI that empowered partner companies to\n\ncustomize and extend payroll capabilities in secure, production environments.\n\nParticipated in agile ceremonies and sprint planning, ensuring iterative delivery of high-quality features meeting\n\nstringent financial and regulatory requirements.\n\nConducted forensic analysis and root cause investigations of complex production issues by analyzing Azure Log\n\nAnalytics and distributed tracing data.\n\nOptimized container orchestration processes and resource consumption on AKS, reducing cloud costs while improving\n\nsystem resiliency.\n\nLed cross-team hackathons and technical workshops to propagate industry best practices around cloud migration and\n\nAI-assisted coding methodologies.\n\nSenior Software Engineer\n\nEllipsis Health\n\nDeveloped and deployed conversational AI health agent backend services using .NET Core, C#, and Azure App\n\nServices that automated patient interactions and data processing under HIPAA compliance.\n\n\n\nJanuary 2016 - April 2020\n\nDrove modernization and cloud migration initiatives migrating on-premise databases to Azure SQL Server and\n\nleveraging Azure Cosmos DB to handle unstructured patient conversation data.\n\nCollaborated with data scientists and ML engineers to integrate AI copilot tools like Github Copilot enhancing\n\nconversational flow algorithms, reducing development time and improving code quality.\n\nLed implementation of automated testing and test-driven development (TDD) processes based on MSTest and xUnit,\n\nintegrating with Azure DevOps CI/CD pipelines to facilitate zero-downtime deployments.\n\nArchitected microservices using Docker and orchestrated with Kubernetes for scalable voice interaction modules,\n\ndeployed through Azure Kubernetes Service (AKS).\n\nRefined database designs using SQL Server and performed query tuning to enable real-time data ingestion and\n\nsynthesis from multiple conversational AI components.\n\nLed design and execution of intelligent test frameworks leveraging AI to auto-generate test cases and detect buggy\n\ncode early, enhancing quality assurance processes.\n\nMentored junior engineers on cloud-native development with Azure, microservices best practices, and AI-enhanced\n\ncoding strategies within an agile environment.\n\nIntegrated secure authentication and authorization workflows via Azure Active Directory and token-based systems to\n\nmaintain compliance and data privacy.\n\nEnhanced application observability by implementing Azure Monitor and Application Insights dashboards to proactively\n\ntrack system health and user engagement metrics.\n\nAutomated container builds and deployments via Azure Pipelines, reducing release cycle times and supporting\n\ncontinuous delivery of AI-driven predictive health features.\n\nCollaborated closely with product management to translate healthcare compliance requirements into technical\n\nspecifications, using AI copilots to iterate on user story acceptance criteria.\n\nDeveloped RESTful APIs with ASP.NET Core serving AI conversational data to internal and external analytics platforms,\n\nensuring scalability and security.\n\nParticipated in cross-functional code reviews leveraging AI-based pair programming tools to refactor legacy\n\ncomponents and improve maintainability.\n\nIntegrated third-party AI/ML services and SDKs to extend speech science capabilities, leveraging Azure Cognitive\n\nServices for speech-to-text and sentiment analysis.\n\nSupported infrastructure-as-code initiatives using Terraform to provision cloud resources consistently across\n\ndevelopment and production environments.\n\nLed root cause analysis and resolution of complex distributed system issues involving asynchronous messaging via\n\nAzure Service Bus.\n\nDesigned disaster recovery strategies utilizing geo-replication of Azure Cosmos DB and automated failover for\n\nmission-critical patient engagement systems.\n\nEstablished coding standards and best practices to ensure compliance with healthcare industry regulations and\n\nsecurity guidelines.\n\nCoordinated with offshore teams adopting remote-first methodologies and AI-assisted development tools to maintain\n\nseamless project delivery across time zones.\n\nSenior Software Engineer\n\nPlanet\n\nLed full lifecycle development of the Planet Insights Platform backend services utilizing .NET Framework, C#, and SQL\n\nServer, delivering scalable, cloud-enabled satellite data analytics solutions.\n\nChampioned migration from traditional data centers to Azure Cloud environments, incorporating Azure Kubernetes\n\nService (AKS) to orchestrate containerized microservices for high-throughput Earth observation data processing.\n\nDesigned and implemented APIs using ASP.NET Core and Azure Functions facilitating near real-time satellite image\n\ningestion, processing, and distribution workflows.\n\n\n\nDeveloped complex SQL queries and optimized SQL Server database schemas to handle petabyte-scale geospatial\n\ndata with high ingestion rates leveraging partitioning and indexing strategies.\n\nCollaborated with data science teams integrating machine learning models into platform services, harnessing Azure\n\nMachine Learning and AI assisted code tools like GitHub Copilot for rapid prototyping.\n\nSpearheaded automated testing strategies implementing MSTest and xUnit with AI-augmented test generation to\n\nensure stability during continuous delivery through Azure DevOps.\n\nIntroduced microservices architecture and containerization employing Docker and Kubernetes allowing scalable\n\nprocessing of satellite image task requests via an automated Tasking Dashboard.\n\nDeveloped secure and scalable authentication mechanisms using OAuth 2.0 and Azure Active Directory for internal\n\nand external platform users.\n\nDesigned and deployed Terraform scripts for infrastructure as code, enabling repeatable, version-controlled\n\nenvironment provisioning across multiple Azure subscriptions.\n\nIntegrated distributed messaging patterns with Azure Service Bus to synchronize satellite tasking workflows and\n\nstatus updates with external analytics systems.\n\nConducted extensive performance profiling and tuning of SQL Server queries and Cosmos DB containers to maintain\n\nlow-latency data access for client applications.\n\nDeveloped RESTful APIs adhering to OpenAPI standards with comprehensive documentation to streamline integration\n\nby external partners and internal teams.\n\nParticipated as a technical lead guiding offshore engineering teams through architecture reviews, agile ceremonies,\n\nand AI-enhanced pair programming sessions.\n\nOptimized cloud costs through detailed monitoring using Azure Monitor and implemented autoscaling policies in AKS\n\nto handle variable data ingestion loads.\n\nLed initiatives to integrate AI-driven code analysis tools and copilot features to improve developer productivity and\n\ncodebase maintainability.\n\nEstablished continuous integration workflows with GitHub Actions and Azure Pipelines, ensuring consistent build and\n\ndeployment processes.\n\nDeveloped and maintained disaster recovery processes including geo-replication and backup strategies for critical\n\nsatellite data stores in Azure SQL Database.\n\nEnhanced observability with structured logging and telemetry using Application Insights to empower proactive\n\nincident response and debugging.\n\nCollaborated with data visualization teams to embed high-frequency satellite imagery analytics APIs into user-facing\n\nweb platforms.\n\nDrove adoption of container orchestration best practices and Helm chart development to standardize deployment\n\nacross staging and production clusters.\n\nÔÜù EDUCATION\n\nMaster of Science in AI (MSAI)\n\nWells College, 2018\n\nBachelor's Degree in Computer Science\n\nWells College, 2015
7ced3411-8058-4aa4-8902-c3ef55629779	Matthjohn Unknown	matthjohn4445@gmail.com	Screening	Sr. Full-Stack Engineer / Solutions Architect	11	Matthew Johnson \n \n\nMiami, FL, +1 (850) 641-5852, mattjson92@gmail.com \n\nSummary \n\nSr. Full-Stack Engineer & Solutions Architect with 12+ years of experience designing, developing, and scaling \n\nenterprise SaaS platforms across financial services, insurance, and digital payments. Proven track record in \n\nmodernizing legacy systems into cloud-native microservices (Azure, AWS), implementing secure and scalable APIs, \n\nembedding AI/ML into production systems, and improving transaction efficiency by 30% within 1 year. Recognized \n\nfor leading cross-functional teams, optimizing high-volume transaction platforms, and delivering solutions that \n\nimprove adoption, reduce costs, and ensure compliance with HIPAA, PCI DSS, NACHA, and FFIEC standards. \n\nTechnical Expertise \n\nProgramming & Frameworks: C#, Java, Python, Node.js, JavaScript, TypeScript, .NET Core, ASP.NET Core, EF Core, \n\nDapper, Spring Boot, FastAPI, ML Frameworks, Golang, Angular, React, Redux, NgRx \n\nCloud & DevOps: Microsoft Azure (App Service, AKS, API Management, Cosmos DB, Service Bus, Key Vault), AWS \n\n(EKS, ECS, Lambda, S3, RDS, DynamoDB, Kinesis, SQS/SNS, API Gateway, Secrets Manager, CloudWatch), Docker, \n\nKubernetes, Terraform, GitHub/GitLab, Azure DevOps, Jenkins \n\nDatabases & Data Engineering: SQL Server, PostgreSQL, MongoDB, DynamoDB, Redis/Elasticache, Snowflake, \n\nKafka, RabbitMQ, SSRS, SSIS \n\nTesting & Tools: OAuth2, OpenID Connect, SAML, MFA, RBAC, HIPAA, PCI DSS, NACHA, FFIEC, ADFS/AD integration \n\nProfessional Experience \n\nIBM Consulting                   Apr 2020 ‚Äì Present \n\nSr. Full-Stack Engineer / Solutions Architect \n\nC#, Python, Golang, JavaScript, TypeScript, .NET Core, Asp.NET Core (Web API), EF Core, React, Angular, Redux, NgRx, \n\nAzure App Service, AKS, Azure API Management, Azure Key Valut, Azure SQL Database, Cosmos DB, Redis Cache, \n\nAzure Service Bus, Kafka, Azure Devops, AWS ECS, AWS EKS, S3, RDS, Lambda, DynamoDB, Secrets Manager, \n\nSnowFlake, SNS, SQS, Kinesis, Docker, Terraform, Grafana, Elastic Search, Kibana, Splunk, New Relic \n\nÔÇ∑ Led a cross-functional team of 8 engineers and UX designers to architect cloud-native member portals for mid-\n\nsize credit unions, modernizing legacy core banking apps into .NET Core APIs on Azure, which boosted portal \n\nadoption by 45% in 2 quarters. \n\nÔÇ∑ Delivered architectural solutions for a cloud-native insurance SaaS start-up, incorporating automated claims \n\nadjudication, AI-driven fraud detection, and real-time policy issuance, processing 10K+ monthly claims and \n\nserving 25K+ policyholders. \n\nÔÇ∑ Developed and deployed BNPL microservices with C#. NETCore, EF Core, and SQL Server on AWS, orchestrating \n\nDocker + EKS deployment pipelines for high availability to handle 100K+ concurrent user requests with 25% \n\nincrement in merchant adoption. \n\nÔÇ∑ Designed and programmed C#.NET microservices for an AI-powered wealth management startup, embedding \n\nreinforcement learning for portfolio optimization and NLP chatbots for personalized investment guidance, \n\nimproving client retention by 18% in 1 year. \n\nPayoneer                               Jan 2016 ‚Äì Apr 2020 \n\n\n\nSr. Software Engineer \n\nC#, .NET Core, ASP.NET Core (Web API), Golang, Python, EF Core, Dapper, SQL Server, Redis, RabbitMQ, Kafka, \n\nDocker, Kubernetes(EKS), AWS (S3, RDS, DynamoDB, Lambda, SQS, SNS, Kinesis, Secrets Manager, CloudWatch, API \n\nGateway), Grafana, Elastic Search, Angular, React, JavaScript, Typescript, Karma, Cypress, Terraform, Azure \n\nDevops/GitLab, GitHub, OpenAPI \n\nÔÇ∑ Implemented C# .NET / ASP.NET core microservices for Payoneer‚Äôs global payout platform, handling multi-\n\ncurrency account transfers and integrating with external payment networks (ACH, SEPA, SWIFT), contributing to \n\n$30B+ in annual transaction volume. \n\nÔÇ∑ Migrated monolithic .NET services into SOA ASP.NET Core services, implementing asynchronous pipelines with \n\nRabbitMQ, boosting scalability and enabling millions of daily payouts with 10% faster API response times. \n\nÔÇ∑ Programmed rest APIs for digital wallet and virtual accounts, supporting USD, EUR, GBP, JPY, and 10+ currencies, \n\nwith real-time balance updates, FX conversions, and settlement reconciliation in SQL server and Redis, reducing \n\nsettlement delays by 20% within 6 months. \n\nÔÇ∑ Constructed transaction monitoring and fraud-detection pipelines in C#.NET with Kafka, flagging high-risk \n\ncross-border transactions in 2seconds and ensuring compliance with FATF and PIC DSS. \n\nJack Henry                              Aug 2014 ‚Äì Jan 2016 \n\nSoftware Engineer \n\nC#, Java, Spring Boot, ASP.NET MVC, Web API, WCF, Entity Framework, ADO.NET, Razor, JavaScript, AngularJS, \n\nBootstrap, WPF/WinForms, Ajax, SQL Server 2012, T-SQL, SSRS, SSIS, AD, OAuth2, VS2013, TFS, IIS, xUnit, MSTest, \n\nFiddler \n\nÔÇ∑ Engineered NetTeller Online Banking APIs in C#.NET / ASP.NET MVC, powering account management, transfers, \n\nand e-statements for 400+ communities and regional banks/credit unions. \n\nÔÇ∑ Implemented ACH and recurring payment workflows in iPay Bill Pay, cutting transaction errors by 30% while \n\nmaintaining NACHA / PCI-DSS compliance. \n\nÔÇ∑ Developed and optimized SQL server procedures, triggers, functions, and SSRS dashboards supporting FFIEC, \n\nFDIC, and NCUA audits across 200+ credit unions and community banks, reducing audit preparation time by 25% \n\nwithin 10 months. \n\nÔÇ∑ Improved digital banking security by integrating ADFS/SAML + MFA authentication flows into NetTeller, \n\nincreasing member adoption of secure login features by 40%. \n\nEducation \n\nUniversity of Florida, Gainesville, FL                             2010 ‚Äì 2014 \n\nBachelor‚Äôs Degree in Computer Science
6591550f-20ce-4861-bd4e-2e07680131fb	Methiumang Unknown	methiumang@gmail.com	Screening	Senior Software Engineer	8	Umang Methi\n\nLead Product Engineer (.NET, C#, Azure)\n\nmethiumang@gmail.com | +1 727 999 9820 | Cookeville, TN | LinkedIn\n\nPROFESSIONAL SUMMARY\n\nExperienced software engineer with 9+ years building enterprise-grade, cloud-native applications\n\nusing .NET and C#. I specialize in designing scalable back-end services, SQL Server schema and\n\nperformance tuning, and executing Azure migration and modernization programs that re-platform\n\nlegacy systems to AKS and App Services. I lead engineering efforts that combine microservices,\n\ncontainerization (Docker + AKS), and event-driven patterns to meet strict SLAs in financial-services-\n\ngrade environments. I integrate AI copilots (GitHub Copilot, Claude) into an AI-driven SDLC to\n\naccelerate design iteration, pair-program with code assistants, and auto-generate unit and integration\n\ntests during development. I architect CI/CD pipelines and implement TDD and automated testing\n\nframeworks that auto-generate tests and enable self-healing regression checks, reducing post-release\n\ndefects. I have hands-on experience with Cosmos DB, Azure Functions, App Services, and SQL Server\n\nindexing and query optimization for high-throughput workloads. I champion observability and SRE\n\npractices using Application Insights, Prometheus, and structured logging to surface production issues\n\nearly. I mentor teams, run design reviews, and coordinate offshore and cross-functional teams to\n\ndeliver predictable releases. I apply infrastructure-as-code (Terraform/ARM) to standardize\n\nenvironments, reduce drift, and accelerate safe rollouts. I enjoy translating stakeholder conversations\n\ninto structured specifications using generative AI copilots and then delivering production-grade code\n\nand tests without depending on separate QA teams. My background balances deep systems-design\n\nthinking with pragmatic delivery: modernizing legacy .NET workloads, building cloud-native services,\n\nand producing measurable business outcomes such as reduced latency, lower cloud spend, and\n\nimproved deployment frequency. I am seeking a Lead Product Engineer role to drive Azure migrations,\n\noperationalize AI-assisted engineering workflows, and mentor teams to ship reliable, secure, and\n\nhighly performant financial services systems.\n\nPROFESSIONAL EXPERIENCE\n\nSenior Software Engineer 07/2020 ‚Äì Present\n\nU Scale With Cookeville, TN\n\nArchitected and led migration of a monolithic .NET Framework payment processing application to\n\n.NET Core microservices on Azure AKS and App Services, designing service contracts and data\n\nmigration paths to SQL Server and Cosmos DB while reducing end-to-end transaction latency by\n\n35% through targeted refactors and query optimization.\n\nDesigned and implemented an Azure-based platform for secure financial workflows using C#,\n\nASP.NET Core, Azure App Services, Azure Functions for scheduled reconciliation, and Azure Key\n\nVault for secrets management, enabling PCI-aligned deployments and automated certificate\n\nrotation.\n\nBuilt containerized CI/CD pipelines in Azure DevOps and GitHub Actions with multi-stage YAML\n\npipelines, image scanning, canary deployments and automated rollbacks, increasing deployment\n\nfrequency from monthly to weekly and reducing failed deploys by 60%.\n\nhttps://linkedin.com/in/umang-methi-b10861342\n\n\nIntegrated GitHub Copilot and Claude into the developer workflow to accelerate feature\n\nscaffolding and test generation, pairing with copilots to create unit tests and integration test\n\nskeletons during development which increased test coverage on new services by 45%.\n\nLed database redesign and performance tuning for SQL Server: implemented normalized schemas\n\nwhere appropriate, added covering indexes, optimized stored procedures and parameterized\n\nqueries to eliminate frequent table scans and reduced average query time by 70% for core\n\nreporting queries.\n\nDeveloped an automated intelligent-testing framework that used heuristics to auto-generate\n\nedge-case unit tests and property-based tests, and integrated Selenium and Postman/Newman\n\nAPI tests into the CI pipeline to catch regressions before merge.\n\nInstituted observability and SLOs using Application Insights, Prometheus exporters and Grafana\n\ndashboards; designed alerts and playbooks that improved MTTR by 40% for production incidents\n\nand surfaced cascading failures earlier.\n\nChampioned infrastructure as code using Terraform and Azure Resource Manager templates to\n\nprovision AKS clusters, App Service plans, networking and managed databases; reduced\n\nenvironment provisioning time from days to under one hour.\n\nRefactored a high-impact reporting module into an event-driven pipeline using Azure Service Bus\n\nand Azure Functions to decouple ingestion and processing; scaled processing horizontally on AKS\n\nand increased throughput by 3x during peak windows.\n\nSpearheaded security hardening: applied OAuth2/OIDC with Azure AD, implemented role-based\n\naccess controls, encrypted sensitive data at rest and in transit, and ran static analysis\n\n(SonarQube) and dependency scanning to reduce vulnerability exposure.\n\nMentored and led a cross-functional squad of six engineers, ran hands-on code reviews focused\n\non maintainability and performance, and established best practices for TDD, branching strategies\n\nand release management across offshore teams.\n\nCoordinated with product and compliance stakeholders to convert informal requirements into\n\nstructured specifications using AI copilots, then produced iterative prototypes and tests that\n\naligned with regulatory controls and shortened stakeholder feedback cycles.\n\nSenior Full Stack Engineer (.NET & React) 03/2017 ‚Äì 06/2020\n\nFactorial Complexity Cookeville, TN\n\nLed full-stack delivery of a customer-facing financial dashboard built with ASP.NET Core Web API,\n\nC#, React, Redux and SQL Server; designed RESTful services, SPA client flows and a caching layer\n\nthat improved UI responsiveness by 55%.\n\nImplemented microservices patterns and containerized services using Docker and Kubernetes on\n\nAzure AKS for transaction processing, authentication, and audit logging, enabling independent\n\nscaling of high-load components and improving resilience.\n\nCreated robust CI/CD pipelines with Azure DevOps, integrating unit, integration and contract tests\n\nthat ran on pull requests and gates; this reduced regression escape rate by 50% and accelerated\n\nmerge-to-deploy time by 30%.\n\nAuthored database migration strategies and automated scripts for SQL Server deployments using\n\nFlyway and EF Core migrations; coordinated cutovers and rollback plans to ensure zero-downtime\n\nreleases for high-volume data services.\n\nIntegrated automated API testing using Postman collections and Newman in CI to validate\n\ncontract stability across services and detect breaking changes before production, which\n\nprevented several critical outages after release.\n\n\n\nRefactored legacy business logic into well-defined domain services, applied SOLID principles and\n\nintroduced dependency injection across the stack to improve testability and long-term\n\nmaintainability.\n\nDeveloped server-side pagination, query projection and optimized stored procedures to handle\n\nlarge datasets; implemented Redis caching for session and hot-data caches to reduce SQL Server\n\nload by 40% during peak periods.\n\nPiloted use of GitHub Copilot for code suggestions during sprint cycles and used pair-programming\n\nsessions with AI copilots to prototype new features faster while capturing suggested tests for code\n\npaths.\n\nImplemented feature flags and blue/green deployment patterns to safely roll out risky changes;\n\nmeasured feature usage and rolled back quickly when KPIs did not meet acceptance criteria.\n\nBuilt real-time components using SignalR and WebSockets for live trade updates and notifications,\n\nimproving user experience for time-sensitive workflows with sub-second update propagation.\n\nManaged observability stack including ELK for centralized logging and Application Insights for\n\ntraces; performed root cause analysis on production incidents and converted corrective actions\n\ninto automated health checks.\n\nCoached junior engineers on TDD, API design, and cloud-native development; prepared\n\nonboarding docs and ran brown-bag sessions on Azure services, microservices design, and\n\ncontainer orchestration.\n\nPROJECTS\n\nAzure Migration Framework for Financial Workloads 01/2020 ‚Äì 12/2020\n\nBuilt a reusable migration framework to re-platform legacy .NET Framework systems to Azure, combining\n\nlift-and-shift and refactor strategies. The architecture included an API gateway, services containerized with\n\nDocker and orchestrated on AKS, and a data layer using SQL Server with selective use of Cosmos DB for\n\nschemaless events. I designed an IaC-driven provisioning pipeline using Terraform and Azure DevOps,\n\nintegrated automated contract and performance tests, and used GitHub Copilot to accelerate test\n\nscaffolding. The framework addressed data migration, backward compatibility, and compliance constraints\n\nto enable predictable, low-risk cutovers for payment and reconciliation systems.\n\nReduced migration time per subsystem by 60% using automated Terraform templates and\n\nreproducible Azure DevOps pipelines that provisioned networking, clusters, and managed\n\ndatabases.\n\nImproved transaction processing throughput by 2.8x after refactoring bottleneck services and\n\ntuning SQL Server indexes and query plans for high-cardinality reporting tables.\n\nAutomated generation of unit and integration test scaffolding with AI copilots, increasing early-\n\ntest coverage on migrated services from 20% to 65% and catching major regressions in pre-prod\n\nruns.\n\nValidated zero-downtime cutover strategies for critical payment flows by using phased traffic\n\nshifting with feature flags and canary analysis in App Gateway and AKS.\n\nEstablished repeatable security and compliance controls (Azure Policy, Key Vault) that passed\n\nexternal audits with no major findings and reduced remediation work by 75%.\n\nTechnologies: C#, .NET Core, .NET Framework, Docker, Azure Kubernetes Service (AKS), Azure App Service,\n\nSQL Server, Cosmos DB, Terraform, Azure DevOps, GitHub Copilot, Azure Functions, Azure Service Bus,\n\nApplication Insights, Redis\n\nReal-time Payments Microservices Platform 03/2018 ‚Äì 06/2019\n\nDesigned and implemented a microservices-based payments platform that processed time-sensitive\n\nfinancial events with high reliability. The architecture favored event-driven patterns using Azure Service\n\n\n\nBus and Azure Functions for asynchronous processing, while core services ran in AKS for deterministic\n\nscaling. I selected SQL Server for relational transactions and Redis for ephemeral caching, and introduced\n\nSignalR for real-time client updates. The project emphasized automated testing, observability, and secure\n\ndeploys to meet SLAs and regulatory requirements.\n\nIncreased platform throughput by 300% by moving synchronous workflows to event-driven\n\nhandlers and horizontally scaling consumer groups on AKS.\n\nReduced average payment reconciliation time from 22 minutes to under 3 minutes by\n\nparallelizing processing with Azure Functions and optimizing DB transactions.\n\nIntroduced end-to-end automated testing (unit, integration, UI) into CI which reduced critical\n\nproduction defects by 55% and shortened incident diagnosis time.\n\nImplemented structured tracing and dashboards with Application Insights and Prometheus,\n\nsurfacing end-to-end latency hotspots and enabling engineering to shave 40% off tail latency.\n\nLed cross-team runbooks and disaster recovery drills that demonstrated service recovery within\n\ndefined RTOs and improved on-call confidence for offshore teams.\n\nTechnologies: C#, .NET Core, Azure Service Bus, Azure Functions, Azure Kubernetes Service (AKS), SQL Server,\n\nRedis, SignalR, Docker, Prometheus, Grafana, Azure Key Vault, Selenium, Postman/Newman\n\nEDUCATION\n\nBachelor of Science in Computer Science 2016\n\nUniversity of California, Berkeley\n\nSKILLS\n\nLanguages:  C#, JavaScript, TypeScript, Python, SQL, T-SQL, Java, Go, HTML5, CSS3, PowerShell\n\nFrameworks:  .NET Core, .NET Framework, ASP.NET Core, Entity Framework Core, React, React.js, Redux,\n\nNext.js, Node.js, Express, SignalR, Dapper, Spring Boot, Docker, Kubernetes\n\nDatabases:  SQL Server, Cosmos DB, PostgreSQL, MySQL, Redis, MongoDB, Elasticsearch\n\nTools:  Azure, Azure Kubernetes Service (AKS), Azure App Service, Azure Functions, Azure DevOps,\n\nTerraform, ARM Templates, Git, GitHub, GitHub Copilot, GitLab, CI/CD, Application Insights, Prometheus,\n\nGrafana, Docker Compose, SonarQube, Postman, Newman, Selenium, Jenkins, Datadog, New Relic, Elastic\n\nStack (ELK), Azure Service Bus, Vault / Azure Key Vault, Flyway, Entity Framework Migrations
ceb2d4a5-f915-46d1-951b-9fe981de4eda	Mominmokhtardev Unknown	Mominmokhtardev@gmail.com	Screening		0	MOMIN MOKHTAR\nSenior Software Engineer\n\nMominmokhtardev@gmail.com ‚Ä¢ (732) 551-6377 ‚Ä¢ https://www.linkedin.com/in/m-mokhtar0124/\n\nSUMMARY\n\nExperienced Senior Software Engineer with over 10 years of demonstrated expertise in designing and delivering\n\nscalable cloud-native applications using .NET, C#, and SQL Server. Skilled in leading cross-functional teams in\n\nAzure migration initiatives and leveraging AI-enabled development lifecycles to accelerate software delivery.\n\nAdept at adopting automated testing frameworks, continuous integration and delivery pipelines to ensure\n\nproduction-grade code reliability. Proven ability to collaborate effectively in agile environments, mentor junior\n\nengineers, and drive innovation by integrating AI code assistants such as GitHub Copilot and Claude to optimize\n\ndevelopment workflows.\n\nSKILLS\n\nProgramming Languages: .NET, C#, SQL, T-SQL, PowerShell, Python, JavaScript, TypeScript, JSON, XML\n\nFrameworks & Libraries: .NET Framework, .NET Core, ASP.NET, Entity Framework, LINQ, Azure Functions,\n\nMicroservices, SignalR, Blazor, Azure SDK, ML.NET, REST APIs, GraphQL, OpenAPI, Swagger\n\nTools & Platforms: Azure, Azure Kubernetes Service (AKS), Azure DevOps, Visual Studio, Git, Github Copilot,\n\nClaude, Docker, Kubernetes, Terraform, Jenkins, NUnit, XUnit, Postman, Swagger UI, SonarQube, Azure App\n\nServices, Azure Cosmos DB, Azure SQL Database, Azure Monitor, Azure Key Vault, Azure Blob Storage, Azure\n\nFunctions\n\nDatabases: SQL Server, Azure SQL Database, Cosmos DB, MySQL, PostgreSQL, Oracle DB, MongoDB, Redis,\n\nElasticsearch, SQLite\n\nDevOps & CI/CD: Azure DevOps, Pipelines, Jenkins, Github Actions, Docker, Kubernetes, Terraform, Helm,\n\nPrometheus, Artifact Repositories, NUnit, XUnit, SonarQube\n\nOther Skills: AI-assisted development, Generative AI, Machine learning concepts, Cloud migration strategies,\n\nAutomated testing, TDD, Continuous integration, Continuous delivery, Microservices architecture,\n\nContainerization, API testing, Agile methodologies, Technical leadership, Code refactoring, Performance\n\noptimization, Security best practices\n\nCERTIFICATIONS\n\nMicrosoft Certified: Azure Solutions Architect Expert\n\nMicrosoft Certified: Azure Developer Associate\n\nMicrosoft Certified: Azure DevOps Engineer Expert\n\nMicrosoft Certified: Azure AI Engineer Associate\n\nMicrosoft Certified: Azure Fundamentals\n\n\n\nEXPERIENCE\n\nSoftware Engineer Lead\n\nNetSpeek ‚Ä¢ 05/2024 - Present\n\nLed design and implementation of the AI-driven remote management platform, leveraging C#, .NET Core, and\n\nAzure Functions for real-time diagnostics across multi-vendor AV/UC devices integrated with cloud services\n\nvia Azure App Services and Cosmos DB.\n\nDesigned and optimized cloud-native components using Azure Kubernetes Service and Docker to ensure\n\nelastic scaling and container orchestration for the agentic AI platform Lena.\n\nCollaborated with AI copilot tools like GitHub Copilot to write clean, production-grade C# code automating\n\nroot cause analysis and issue remediation workflows enhancing platform reliability.\n\nImplemented continuous integration pipelines with Azure DevOps supporting automated testing suites\n\ndeveloped using NUnit and XUnit to maintain high-quality production deployments.\n\nLeveraged Azure Monitor and Application Insights to proactively monitor device health and system\n\ntelemetry, enabling pre-emptive diagnostics driven by machine learning models.\n\nArchitected native integration layers connecting with external platforms (Zoom, Logitech) via RESTful APIs,\n\nimproving the interoperability of cloud-hosted AV systems.\n\nDesigned secure authentication and authorization flows with Azure Active Directory and Key Vault, ensuring\n\ncompliance to enterprise-grade security standards.\n\nEnabled real-time control panel dashboards using Blazor and SignalR for low-latency device management\n\nover cloud.\n\nMentored engineering team members on best practices for cloud-native development, emphasizing Azure\n\nservice orchestration, microservices architectures, and AI-assisted coding productivity enhancements.\n\nApplied microservices design principles combined with containerization strategies in Kubernetes for modular\n\nplatform scalability and fault tolerance.\n\nOrchestrated multi-region deployments of the AI system with Terraform, ensuring infrastructure as code\n\nconsistency and repeatability.\n\nCollaborated closely with data scientists to integrate AI inferencing engines and telemetry pipelines running\n\non Azure Functions and Cosmos DB for responsive edge analytics.\n\nFine-tuned SQL Server databases to handle large volumes of unstructured telemetry data while preserving\n\ntransactional performance for operational services.\n\nDeveloped custom middleware components in .NET Core exposing APIs for device control with enhanced\n\nerror handling and retry mechanisms.\n\nDelivered support for real-time streaming data pipelines integrating with Azure Event Hubs to manage\n\ntelemetry event processing and anomaly detection.\n\nInstituted automated test case generation practices by integrating AI copilot tools in the development\n\nworkflow reducing regression defects.\n\nLed the migration of legacy diagnostic scripts to modern cloud-hosted microservices with full CI/CD pipeline\n\nsupport via Azure DevOps.\n\nCreated comprehensive documentation and architectural diagrams using OpenAPI/Swagger to streamline API\n\nmaintenance and developer onboarding.\n\nSpearheaded seamless cloud-based device health monitoring with Prometheus and Grafana, enabling rich\n\nvisualization and alerting capabilities.\n\n\n\nEnforced container security and compliance adherence through scanning tools integrated with Azure DevOps\n\npipelines.\n\nSenior Software Engineer\n\nLivanta LLC ‚Ä¢ 04/2020 - 05/2024\n\nDeveloped scalable, secure cloud applications on Azure for the TEASA healthcare navigation platform utilizing\n\nC#, .NET Core, and SQL Server to support patient advocacy workflows and data sharing.\n\nExecuted Azure migration efforts modernizing legacy healthcare systems to leverage Azure App Services,\n\nAzure SQL Database, and Azure Blob Storage for scalable data storage and processing.\n\nLeveraged AI copilot tools like GitHub Copilot to accelerate development cycles and ensure adherence to best\n\nengineering practices in writing maintainable, testable C# code.\n\nImplemented microservices-based medical data processing pipelines using Azure Kubernetes Service\n\nenhancing modularity and fault isolation.\n\nDesigned and implemented complex relational database schemas and optimized queries in SQL Server to\n\nsupport secure patient data access and management.\n\nCreated automated test suites with NUnit and integrated them with Azure DevOps pipelines ensuring\n\ncontinuous integration and delivery of critical emergency contact features.\n\nCollaborated with cross-functional healthcare teams to translate intricate patient journey use cases into highly\n\nresponsive cloud-native applications.\n\nApplied TDD practices combined with intelligent AI-assisted test generation accelerating defect detection in\n\nevolving healthcare modules.\n\nManaged secure authentication systems leveraging Azure Active Directory ensuring HIPAA-compliant access\n\ncontrol for patient and caregiver portals.\n\nDesigned and maintained APIs for information exchange between care team members, integrating generative\n\nAI enhancements to optimize user interaction flows.\n\nLed refactoring initiatives improving legacy codebases with contemporary .NET Core standards and\n\ncontainerized deployments using Docker.\n\nEstablished monitoring and alerting frameworks using Azure Monitor and Log Analytics enabling proactive\n\nissue resolution and system health transparency.\n\nUtilized Postman and Swagger UI to develop and validate secure API endpoints facilitating integration with\n\nthird-party healthcare services.\n\nParticipated in architectural reviews endorsing microservice segregation, event-driven design via Azure Event\n\nGrid, and scalable cloud storage patterns.\n\nMentored junior developers in cloud best practices, AI-assisted coding workflows, and advanced Azure\n\necosystem toolsets fostering team skill advancement.\n\nSupported the design of container orchestration strategies using Kubernetes and Helm charts simplifying\n\nplatform deployment and maintenance.\n\nIntegrated advanced monitoring tools such as Prometheus and Grafana for enhanced observability of service\n\nperformance and latency metrics.\n\nEnforced security protocols through automated vulnerability scans integrated with Azure DevOps pipelines\n\nmaintaining compliance with healthcare regulations.\n\nCollaborated with data engineering teams to implement secure, HIPAA-compliant data stores using Azure\n\nCosmos DB for document storage needs.\n\nProven track record in delivering mission-critical software under agile methodologies with continuous\n\nfeedback loops and stakeholder engagement.\n\n\n\nSenior Software Engineer\n\nThe Home Depot ‚Ä¢ 04/2016 - 05/2020\n\nDeveloped and maintained the barcode printing system supporting inventory management and POS\n\noperations using .NET Framework, C#, and SQL Server, integrated with Home Depot ºs ERP system for real-\n\ntime stock tracking.\n\nLed modernization projects to migrate legacy on-premise services to hybrid cloud environments,\n\nimplementing Azure App Services and foundational cloud components.\n\nDesigned scalable backend workflows processing UPC/EAN barcode generation and printing using ASP.NET\n\nWeb APIs integrated with thermal printer interfaces and label management services.\n\nImplemented SQL Server stored procedures and optimized complex queries improving data retrieval times\n\ncritical to inventory accuracy and checkout speeds.\n\nEmployed AI-assisted development tools like GitHub Copilot to produce clean, modular C# code and refactor\n\nlegacy components enhancing maintainability and scalability.\n\nBuilt and maintained continuous integration pipelines using Azure DevOps and Jenkins facilitating automated\n\nbuilds, testing, and seamless deployment to staging and production environments.\n\nDeveloped NUnit-powered automated test suites for key system modules, integrated with CI/CD pipelines\n\nensuring robust regression testing coverage.\n\nManaged containerized microservices with Docker and orchestrated deployments through Kubernetes\n\nclusters in Azure cloud enhancing service resilience and scalability.\n\nCollaborated with front-end developers to integrate barcode scanning interfaces leveraging RESTful APIs\n\nadhering to secure design principles.\n\nMonitored application performance and system health using Azure Monitor and Application Insights,\n\nenabling prompt identification and resolution of production issues.\n\nSecured application endpoints by implementing Azure Active Directory authentication flows and enforcing\n\nfine-grained authorization policies across service layers.\n\nGuided junior engineers on cloud migration strategies, test-driven development, and AI-enhanced software\n\nengineering best practices.\n\nParticipated in architectural design sessions advocating for microservices adoption and container\n\norchestration using CNCF technologies.\n\nImplemented infrastructure as code using Terraform to provision and maintain cloud resources in a repeatable\n\nand auditable manner.\n\nCoordinated with QA teams to adopt intelligent testing frameworks capable of auto-generating test cases and\n\nintegrating them into CI pipelines with Azure DevOps.\n\nEnhanced system fault tolerance by designing retry logic, circuit breakers, and fallback strategies using Polly\n\nwithin the cloud-native .NET applications.\n\nCreated detailed API documentation with OpenAPI/Swagger facilitating clearer client integrations and faster\n\ndevelopment cycles.\n\nLeveraged AI and machine learning concepts to analyze transaction logs and identify bottlenecks optimizing\n\ndatabase access patterns and query performance.\n\nEstablished container security best practices including vulnerability scanning and image signing integrated\n\nwith CI/CD workflows.\n\nDelivered high-availability services under agile, iterative development cycles aligning with business goals and\n\nensuring robust financial transaction processing.\n\n\n\nEDUCATION\n\nMaster's Degree in Business Administration\n\nPurdue Global ‚Ä¢ 2022\n\nBachelor of Science in Cybersecurity\n\nPurdue Global ‚Ä¢ 2016
83b374f1-f858-40e9-92f0-3187ea506a09	Netcarltjohnson Unknown	netcarltjohnson@gmail.com	Screening	Senior Software Engineer	13	Carlton Johnson \nSr. Software Engineer | .NET, Angular, React, Azure, AWS, Finance, Healthcare \n\nAUSTIN, TX 78702 | (737) 273 3513 | netcarltjohnson@gmail.com | linkedin.com/in/carlton-johnson-45490b1b0 \n\nAccomplished Senior Software Engineer with over 13 years of experience driving digital transformations in Finance (8 Yrs) and Healthcare \n\n(5.3 Yrs) industries, modernizing systems to support large-scale operations and enhance efficiency for thousands of users. Proficient in \n\nC#/.NET with Angular (5 Yrs), and skilled in leveraging cloud platforms like Azure (3 Yrs) and AWS (2 Yrs) for scalable solutions. \n \n\nSKILLS \n\nÔÅ¨ C#, TypeScript, JavaScript, SQL (T-SQL), Python, C++, Java, VB.NET, Node.js \n\nÔÅ¨ ASP.NET, ASP.NET Core, ASP.NET MVC, Laravel, Node.js, Entity Framework/Core, ADO.NET, RESTful API, gRPC, Soap, SignalR, WebSockets  \n\nÔÅ¨ React, Angular, Next.js, Redux, RxJS, NgRx, jQuery, Kendo UI, Angular Material, MaterialUI, Bootstrap, HTML, CSS, Razor, React Native \n\nÔÅ¨ MS SQL Server, SSMS, SSIS, SSRS, PostgreSQL, MongoDB, Cosmos DB, Redis, Azure Data Explorer \n\nÔÅ¨ Azure (AKS, Service Bus, Functions, Blob Triggers, API Management, AD B2C, Key Vault, App Insights, Data Explorer, DevOps), AWS \n\n(Lambda, Cognito, SQS, CodePipeline, CodeBuild, SageMaker, API Gateway) \n\nÔÅ¨ Docker, Kubernetes, Terraform, ARM Templates, Jenkins, TeamCity, Git, TFS \n\nÔÅ¨ Datadog, Serilog, Azure App Insights, Application Insights, Power BI, SSRS, SonarCloud, JMeter, Jasmine, Karma, xUnit, NUnit, Moq \n\nWORK EXPERIENCE \n\nSCIENCESOFT  REMOTE \n\nSenior Software Engineer | ASP.NET Core, Angular/Blazor, Azure 05/2022 ‚Äì 06/2025 \n\nLed design of InvoiceGate system in Azure microservices using ASP.NET Core 8, Entity Framework Core, Docker, Kubernetes (AKS), \n\nAzure Service Bus (pub/sub), and Polly for resilience - enabling consolidated billing and split invoicing, reducing processing times by \n\n20%, and scaling to 100k+ daily transactions for multi-site clients \n \n\nÔÅ¨ Modernized client/admin portals using C#/ASP.NET Core 8 and Angular 15 with RxJS/NgRx/Angular Material - streamlining B2B \n\nonboarding via customizable dashboards, boosting engagement for 50k+ users \n\nÔÅ¨ Refactored legacy ASP.NET MVC with Kendo UI/jQuery and added SignalR real‚Äëtime payment status notifications; separately \n\nimplemented backend EDI X12 (810/820) processing pipeline to ensure standards compliance \n\nÔÅ¨ Optimized invoice posting and payment matching through T-SQL queries, indexing, partitioning in MS SQL Server, and integrated \n\nCosmos DB (MongoDB API) to handle semi-structured data - processing 1M+ daily records and improving efficiency in revenue \n\ncycle \n\nÔÅ¨ Implemented ETL for invoicing data using SSIS, Azure Functions with Blob Triggers for incremental ingestion and separate tax \n\ncalculation services - generating SSRS reports, unifying disparate sources and streamlining ingestion \n\nÔÅ¨ Modernized integrations from SOAP to REST with Azure API Management (security, quotas, versioning) cutting partner \n\nonboarding weeks to days and built internal gRPC services plus a Dynamics 365 (Dataverse) OData pipeline powering Power BI \n\ndashboards \n\nÔÅ¨ Incorporated AI-driven reminders via Python, Azure Functions and Azure OpenAI Service, plus Redis for caching - reducing Days \n\nSales Outstanding (DSO) by 20%, boosting collections efficiency, and increasing conversion rates by 15% \n\nÔÅ¨ Built robust monitoring and alerting for failed postings or mismatches using Azure Functions, Application Insights for log analysis \n\nand metrics, and Serilog for centralized logging - enabling rapid incident detection and maintaining SLA compliance \n\nÔÅ¨ Enhanced security with RBAC, Azure AD B2C for SSO, OAuth2/JWT authentication, Key Vault for secrets, WAF and IP allow listing, \n\nfraud/anomaly detection rules, and federation with PingFederate - reducing unauthorized access by 40% and ensuring \n\ncompliance in partner portals and billing systems \n\nÔÅ¨ Established comprehensive testing strategies with xUnit, Moq for mocking, Jasmine/Karma for frontend, and JMeter for \n\nperformance in TDD practices - achieving 80%+ code coverage and integrating SonarCloud for quality analysis \n\nÔÅ¨ Automated CI/CD pipelines using Azure DevOps (migrating legacy Jenkins jobs) for builds and Terraform for infrastructure as \n\ncode (IaC) while phasing out ARM templates - cutting deployment times by 25% and build times by 20% \n\nÔÅ¨ Conducted weekly code reviews and mentored 2 junior developers in a 6-member team, implementing lightweight PI-style \n\nplanning and Lean-Agile principles - fostering collaboration, increasing team velocity, and improving delivery quality in \n\n.NET/Azure projects \n\n\n\nTAPCHECK INC REMOTE \n\nSenior Software Engineer | .NET, React, Angular, AWS 03/2020 ‚Äì 05/2022 \n\nLed migration of legacy VB.NET, Web Forms desktop apps to .NET Core 5, Angular, and AWS microservices - modernizing payroll and \n\nwage access solutions, integrating 3rd-party payroll/banking providers, reducing processing times by 30%, and scaling for 50k+ users \n \n\nÔÅ¨ Created RESTful Web APIs for Digital Payments Portal, Payroll Insights Extension, and Financial Operations Suite using C#, Entity \n\nFramework Core, and MS SQL Server - automating calculations, disbursements, and compliance reporting, boosting accuracy by \n\n25% and cutting errors in wage access \n\nÔÅ¨ Developed serverless caching using AWS Lambda and Redis, along with micro-batching for MongoDB/PostgreSQL - accelerating \n\npayroll data queries, handling peak volumes, and improving system responsiveness for real-time wage disbursement and \n\noperations \n\nÔÅ¨ Introduced security standards like SAML, OAuth, and JWT via AWS API Gateway and Amazon Cognito - protecting sensitive \n\npayroll/banking data, ensuring SOC 2/GDPR/PCI DSS compliance \n\nÔÅ¨ Upgraded Apache Kafka infrastructure for reliable real-time processing of payroll transactions and notifications - leveraging \n\nmultithreading for parallel task execution, ensuring timely wage payments during peak periods, and minimizing delays \n\nÔÅ¨ Utilized Docker for containerized deployment of financial apps, adhering to enterprise security/compliance, and automated CI/CD \n\npipelines with AWS CodePipeline/CodeBuild - enabling faster releases, and reducing manual effort for payroll features \n\nÔÅ¨ Collaborated in SCRUM teams to define requirements and design payroll advance/payment components - integrating AI for \n\nintelligent automation via Python and AWS SageMaker, and increasing processing efficiency by 15% for 10k+ daily users \n\nÔÅ¨ Architected mobile banking features for wage access apps using C#, Node.js backend, React frontend, and React Native for \n\nAndroid/iOS on AWS - serving 10k+ users, optimizing performance with code splitting/lazy loading \n\nÔÅ¨ Optimized internal portals with ASP.NET MVC, Kendo UI, Bootstrap, jQuery, and Angular - rewriting legacy code, troubleshooting \n\nLINQ/T-SQL, and integrating SSRS/Power BI reports with D3.js dashboards, reducing query times by 30% for payroll insights \n\nÔÅ¨ Migrated SOAP-based services to RESTful APIs for payment processing, account management, and KYC verification - \n\nimplementing OAuth2/JWT on AWS, enhancing reliability in real-time wage disbursement systems \n\nÔÅ¨ Established Datadog monitoring for KPIs like transaction latency, error rates, and resource utilization - identifying and resolving \n\ntop crash causes, achieving 95%+ uptime, and contributing to an 8% revenue increase through optimized wage access features \n\n \n\nHALLMARK HEALTH CARE SOLUTIONS ONSITE \nSoftware Engineer | .NET, React, Next.js, Agile 03/2012 ‚Äì 03/2020 \n\nLed the migration of a legacy VB.NET patient portal to a React/Next.js, .NET Core 2.2, and MaterialUI stack, ensuring robust HL7 and \n\nFHIR interoperability for secure clinical data exchange, and embedding HIPAA-compliant authentication and audit trails to safeguard \n\nProtected Health Information (PHI). This transformation enabled seamless integration with Electronic Health Record (EHR) systems \n\nand third-party providers, reducing manual data entry and minimizing clinical errors \n \n\nÔÅ¨ Developed modern ASP.NET MVC web applications to streamline patient and provider workflows, resulting in a 20% boost in user \n\nengagement and performance, directly supporting improved patient outcomes and operational efficiency for healthcare \n\norganizations \n\nÔÅ¨ Engineered high-performance SQL Server solutions by designing optimized Stored Procedures, Views, Triggers, and complex T-SQL \n\nqueries, reducing query execution time by 40% and supporting the real-time data needs of healthcare administrators and clinicians \n\nÔÅ¨ Streamlined data access using Entity Framework and LINQ within ASP.NET, achieving a 30% reduction in application load times and \n\nimproving the responsiveness of mission-critical healthcare applications, which is essential for timely clinical decision-making \n\nÔÅ¨ Implemented RESTful APIs with ASP.NET Web API to enable secure, standards-based integration between front-end applications, \n\nEHRs, and third-party healthcare services, facilitating interoperability and supporting value-based care initiatives \n\nÔÅ¨ Ensured reliability and regulatory compliance through comprehensive unit and integration testing with NUnit and xUnit, reducing \n\nproduction defects and supporting HIPAA and FDA validation requirements for healthcare software \n\nÔÅ¨ Designed responsive user interfaces with Razor Pages, guaranteeing a consistent, accessible experience for clinicians and patients \n\nacross desktop and mobile devices, in line with healthcare accessibility and usability best practices \n\nÔÅ¨ Accelerated project delivery by 30% by championing Agile SCRUM and Test-Driven Development (TDD), enabling the team to \n\nrapidly adapt to evolving healthcare regulations and client requirements while ensuring continuous compliance and high code \n\nquality - critical in the fast-changing healthcare IT landscape \n \n\n\n\nEDUCATION \n\nVanderbilt University, Nashville, TN  \n\nBachelor of Science, Computer Science
68809a02-4f2f-4286-8509-4d9bd25ec2a4	Oluinc Unknown	oluinc80@gmail.com	Screening		0	James Olusola A. \nDallas, TX \n\noluinc80@gmail.com  \n(469) 381-2386  \n\n \n DEVOPS/PLATFORM ENGINEER \n\n \nProfessional Summary \nCloud-native DevOps Engineer with 12+ years of experience driving reliable, scalable deployments and \nsecure infrastructure across Azure, AWS, GCP, OCI, Kubernetes, AKS, GKE, and EKS. Adept at \nbuilding and automating CI/CD pipelines, orchestrating containerized applications, and implementing \nrobust monitoring and security practices. Skilled in collaborating with development teams to bridge the \ngap between development and operations, ensuring efficient software delivery and operational excellence. \n \n \nProfessional Skills \n\n‚Ä¢ Analyze, design, develop, troubleshoot. Coding, testing and debug software programs using \ncloud technology \n\n‚Ä¢ Write design documentation \n‚Ä¢ Work as an Individual contributor as well as a team member \n‚Ä¢ Provide guidance, assistance, and technical leadership to lower-level Engineers on more \n\ncomplex/large projects \n‚Ä¢ Evaluate new products that could improve our products and processes \n‚Ä¢ Participate in on call rotation and 24/7 support. \n\n‚Ä¢ Experience in provisioning, configuring, and managing operating systems in Linux and \nWindows \n\n‚Ä¢ Experience in cloud engineering, automation and migration with AWS, Azur, and OCI \n‚Ä¢ Experience in microservices infrastructure build with ECS, EKS and AKS, OpenShift, and \n\nKubernetes Solutions. \n‚Ä¢ Experience in build and releases of application or software using CI/CD with Jenkins, Azure \n\nDevops, Gitlab-CI, Github Actions, and ArgoCD \n‚Ä¢ Experience in Monitoring with Prometheus, Grafana, Nagios \n‚Ä¢ Experience managing ACM (HUB) and Spoke environments  \n‚Ä¢ Experience in creating pipeline to manage application build and releases. \n‚Ä¢ Experience in automation with Configuration Management tools such as Ansible and Puppet \n‚Ä¢ Experience in Log Management tools build and configuration such Splunk, Elasticsearch \n‚Ä¢ Experience on release and deployments of application such as Maven, Python, Java, Springboot, \n\n.NET \n‚Ä¢ Experience in microserivices, Apache Kafka, AmazonMQ, RabbitMQ, Upstream Istio, Kiali, \n\nJaegar, and Tempo. \n‚Ä¢ Experience in Database build for Relational Database such as MySQL, PostgreSQL, MsSQL, and \n\nNon-Relational Database such as MongoDB, MariaDB. \n‚Ä¢ Experience in container scanning tools such as Sysdig, Veracode and compliance management \n\nsuch as PCI and SOC2 compliance. \n‚Ä¢ Experience in Single Sign On solutions such as OKTA, PING and AD. \n‚Ä¢ Experience in Cloud Security with IAM management, Guardrails, Config Managed Rules, \n\nCloudtrail Logs, VPC flow logs, Guardduty in AWS, and Gatekeeper. \n \n \n\nmailto:oluinc80@gmail.com\n\n\nProfessional Experience \n \nOracle         Nov 2019 - Present \nSr DevOps/Platform Engineer \n\n \nResponsibilities: \n\n‚Ä¢ Supporting the migration of infrastructure/applications from on-premises to OCI, AWS Cloud \n‚Ä¢ Architect and review application environment built in the cloud. \n‚Ä¢ Providing infrastructure support and build of environment for conversion of monoliths into \n\nmicroservices. \n‚Ä¢ Provisioning and management of Kubernetes cluster in OCI, and Elastic Container Services in \n\nAWS \n‚Ä¢ Provisioning of microservices application using Helm chart and Terraform, Ansible. \n‚Ä¢ Develop, test and implement new microservices; configured and maintained pipeline framework. \n‚Ä¢ Supporting software development and data management projects that prepare large datasets for \n\ndelivery to a shared cloud computing and storage environment. \n‚Ä¢ Provide strategies and requirements for the seamless migration of applications, web services, and \n\ndata from local and server-based systems to the AWS cloud. \n‚Ä¢ Designed and implemented REST APIs using Custom Resource Definitions (CRDs) to expose \n\ncustom platform functionalities to developers. \n‚Ä¢ Built platform services with REST APIs for integration with CI/CD pipelines, automating \n\ndeployments and scaling actions. \n‚Ä¢ Use Ansible-Playbook to automate and configure application stack on cloud deployments and \n\noperations. \n‚Ä¢ Implemented ArgoCD and integrated it with Openshift 4x \n‚Ä¢ Deployment & Provisioning of AWS resources using Terraform with creating custom modules \n\nfor VPC, EC2, S3, RDS, EBS, CloudFront, Elastic Load Balancer, Auto scaling groups. \n‚Ä¢ Work with developers to build a suitable pipeline for application build and releases with \n\ncontinuous build-test-deployment (CI/CD) system. \n‚Ä¢ Experienced in the provisioning and use of Openshift Advance Cluster Management (ACM). \n‚Ä¢ Provisioned OpenShift 4 using terraform and integrated ArgoCD with the cluster for GitOps \n\nsolutions. \n‚Ä¢ Implement kafka, service mesh Istio for secure, connect, run, control and monitor micro services \n‚Ä¢ Worked on policy as code tools such as Gatekeeper and provided the strategy to integrate it into \n\nour existing Kubernetes clusters to enforce controls on resources such as pods, nodes, and \nclusters. \n\n‚Ä¢ Utilize Kubernetes for the runtime environment of the CI/CD system to build, test and deploy. \n‚Ä¢ Increased deployment frequency by 40%by automating CI/CD pipelines in ServiceNow Flow \n\nDesigner. \n\nEnvironment: OCI, AWS, Linux, Kubernetes, ACM, CI/CD GitHub Actions, GitHub, Shell \nScripting, VCS with GIT, Java, Maven, Docker,  \n\n \n \n \nFIS GLOBAL                     Sept 14 - Oct‚Äô 2019 \nDevOps Engineer \n \n\n‚Ä¢ Performed assessment of on-premises infrastructure to create strategies and recommendation for \ncloud migration projects. \n\n‚Ä¢ Designed and implemented Continuous and Continuous Deployment frameworks from code to \ndeploy using Jenkins and Gitlab-CI \n\n‚Ä¢ Designed and implemented Disaster Recovery solutions. \n\n\n\n‚Ä¢ Implemented automation provisioning and configuration frameworks in support of \nInfrastructure-as-code. \n\n‚Ä¢ Collaboration with peers on the development of new automation tools and services used in the \nmanagement and maintenance of various virtual environments. \n\n‚Ä¢ Built and managed AWS as well as Azure resources with Terraform.  \n‚Ä¢ Experienced in the use of Kustomize and Helm in Kubernetes. \n‚Ä¢ Set up various Prometheus scrapes to manage metrics collected on the EKS platform. \n‚Ä¢ Set up Spinnaker to manage deployment of our python-based application into the EKS cluster. \n‚Ä¢ Deployed Portworx to manage storage on our on-prem Kubernetes platform. \n‚Ä¢ Set up Azure devops to manage deployment of our python-based applications into AKS and \n\ninvolved in the troubleshooting of issues on the platform. \n‚Ä¢ Maintain puppet environment which includes writing manifests for automation across multiple \n\nservers. \n‚Ä¢ Involved in deploying the content Cloud platform on Amazon AWS using EC2, S3, and EBS.  \n‚Ä¢ Evaluate Chef and Puppet framework tools to automate the Cloud deployment and operations. \n‚Ä¢ Increased deployment frequency by 40%by automating CI/CD pipelines in ServiceNow Flow \n\nDesigner. \n‚Ä¢ Increased deployment frequency by 40%by automating CI/CD pipelines in ServiceNow Flow \n\nDesigner. \n\n‚Ä¢ Performed application server builds in EC2 environment and monitoring them using cloud \n\nwatch. \n\n‚Ä¢ Design roles and groups using AWS identity and access management (IAM) \n\n‚Ä¢ Implement and maintain the monitoring and alerting of production and corporate \n\nservers/storage using CloudWatch. \n\n‚Ä¢ Created VPC, subnet and configure Network ACL for Cloud infrastructure. Completed manually \nand automated with Cloud Formation \n\n‚Ä¢ Managed the IAM role and policies for users within the environment for access to the cloud \ninfrastructure. \n\n‚Ä¢ Created buckets in S3 and grant access to user for storage and retrieval of object files for \napplication deployment and ensure the contents. \n\n‚Ä¢ Created encrypted custom AMI for EC2 deployments. \n‚Ä¢ Utilizes AWS Secret Manager to manage and store secrets, password and manage rotation. Utilize \n\nAWS SSM for automated patching. \n‚Ä¢ Created templates and clone servers in VMware environment. \n‚Ä¢  \n\nEnvironment: AWS, Linux, Kubernetes, CI/CD Jenkins, Gitlab-CI, Gitlab, Github, Shell Scripting, VCS \nwith GIT, Java, Maven, Docker, Snyk, Ansible, Puppet. \n \n\n \n\nNTT DATA       Sep‚Äô 12 ‚Äì Jul‚Äô 16 \nSystem Engineer \n \n\n‚Ä¢ Installation/configuration of Linux using kickstart Server and Windows OS \n‚Ä¢ Packages and integrating servers to Active Directory, etc. \n‚Ä¢ Maintain puppet environment for automation across multiple servers. \n‚Ä¢ Worked on setting up Veritas clustering. \n‚Ä¢ Worked with Oracle DBA‚Äôs for restore of Oracle Instance and Building Oracle RAC Cluster. \n‚Ä¢ Worked on creating Virtual machines using VMware software. \n\n\n\n‚Ä¢ Performed hardware, operating system, security and application updates/patches on these systems \nas well as operating system hardening based in industry standards. \n\n‚Ä¢ Experienced working on Datacenter Migration Projects. \n‚Ä¢ Worked with Enterprise Security Manager to get Security certification for servers before moving \n\nthem in to production. \n‚Ä¢ Responsible for Failover/Pre-Failback/Failback and verification of the same in case of outage in \n\nthe high environment using VCS (Veritas Cluster Server). \n‚Ä¢ Working very closely with vendors (IBM/HP/Sun/EMC) in resolving any hardware/ Storage and \n\nNetwork issues. \n‚Ä¢ Monitoring the system performance and doing the kernel tuning to enhance the system \n\nperformance. \n‚Ä¢ Troubleshooting Production Server Problems related to web applications, Sendmail, disk space, \n\nfile system, DNS and network connectivity.  \n‚Ä¢ Responsible for patching both manually and with automation. \n‚Ä¢ Monitoring the system performance and doing the kernel tuning to enhance the system \n\nperformance. \n‚Ä¢ Install and configure Splunk for Data retention and log management. \n\n \n \n\n \n\n \n\nEDUCATION & TRAINING: \n\n‚Ä¢ Cisco Certified Network Associate \n\n‚Ä¢ AWS Certified Solutions Architect ‚Äì Associate \n\n‚Ä¢ Oracle Cloud Infrastructure Certified  \n \n‚Ä¢ Certified Kubernetes Administrator (CKA) \n\n‚Ä¢ Microsoft Certified Professional (MCP) \n\n‚Ä¢ Bachelor of Science; Babcock University
1bc3a5ad-b9cc-4b48-898d-13afb6ef544a	Philip S luther	philip.s.luther727@gmail.com	Screening	Lead Product Engineer	7	Cover Le(er \n\nDear Hiring Manager, \n\nI am excited to apply for the Lead Product Engineer position at Green Dot. With over eight years of experience \nbuilding enterprise-grade .NET applications, leading Azure migration strategies, and leveraging AI-enhanced \ndevelopment workflows, I bring the technical expertise and leadership skills required to make an immediate \nimpact on your team. \n\nAt Discord, I led the modernization of cloud-native applications, integrating AI copilots to accelerate code \ndevelopment, testing, and bug detection. At Salesforce, I focused on API-driven financial systems and Azure \ncloud transformations, while at HashiCorp, I honed my expertise in infrastructure automation and DevOps \npractices. Across all these roles, I have consistently delivered scalable, secure, and business-focused solutions \nwhile mentoring teams and fostering a culture of continuous learning. \n\nGreen Dot‚Äôs mission to deliver smart money management solutions aligns deeply with my background in \nfinancial services technology and my passion for building secure, scalable cloud systems. I am particularly \nexcited by your emphasis on AI-driven SDLC workflows, which mirror my recent work in pairing AI with \nengineering processes to accelerate delivery and improve code quality. \n\nI would welcome the opportunity to bring my skills in .NET, Azure, cloud-native architectures, and AI-driven \nengineering to Green Dot. I am confident in my ability to lead initiatives that deliver measurable impact and \nhelp drive your vision of smarter financial technology. \n\nThank you for considering my application. I look forward to the opportunity to contribute to Green Dot‚Äôs \nmission. \n\nSincerely, \nPhilip Luther Philip Luther \nLead Product Engineer \nüìçUniversal City, TX, USA | +1 (814) 300-8646 | philip.s.luther727@gmail.com \n\n\t\n\nProfessional Summary \n\nExperienced Lead Product Engineer with deep expertise in .NET, C#, SQL Server, and Azure cloud technologies. \nProven ability to architect, modernize, and migrate enterprise-grade applications to cloud-native environments. Skilled \nin leveraging AI-enhanced development lifecycles (AIDLC), including GitHub Copilot and Claude, to accelerate \ncoding, testing, and system optimization. Adept at mentoring teams, implementing CI/CD pipelines, and driving \nintelligent automation for financial services and enterprise-grade platforms. Demonstrated success across roles at \nDiscord, Salesforce, and HashiCorp, delivering business-critical software with a balance of scalability, performance, \nand compliance. \n\n\t\n\nCore Skills \n\n‚Ä¢ .NET, C#, SQL Server, ASP.NET Core, Entity Framework \n‚Ä¢ Azure Services (AKS, App Services, Cosmos DB, Functions, Azure DevOps) \n‚Ä¢ Cloud-Native Architecture & Azure Migration \n‚Ä¢ AI-Driven Development (Copilot, Claude, Code Assistants) \n‚Ä¢ CI/CD Automation (GitHub Actions, GitLab CI/CD, Jenkins) \n‚Ä¢ Microservices, APIs (REST/GraphQL), Event-Driven Systems \n‚Ä¢ TDD, Automated Testing, Intelligent Testing Frameworks \n‚Ä¢ Docker, Kubernetes, Helm, Terraform \n‚Ä¢ Financial Services & Payments Systems Engineering \n‚Ä¢ Leadership, Mentorship, Agile Collaboration \n\n\t\n\nProfessional Experience \n\nDiscord ‚Äì San Francisco, CA \n\nLead Product Engineer | Sep 2021 ‚Äì May 2025 \nAt Discord, I led initiatives focused on designing and scaling cloud-native applications while driving Azure migration \nstrategies and implementing AI-enhanced development workflows. I worked on backend and full-stack systems that \nsupported millions of users while maintaining high security and compliance standards crucial for financial and \ncommunication services. \n\n‚Ä¢ Directed design and implementation of enterprise-grade applications using .NET, C#, SQL Server, and Azure \nservices, ensuring high performance and scalability across payment and messaging systems. \n\n‚Ä¢ Architected Azure migration strategies, modernizing legacy systems into re-platformed, cloud-native \napplications, leveraging AKS, Cosmos DB, and Functions for optimized infrastructure. \n\n‚Ä¢ Operated within an AI-driven SDLC, using copilots to translate requirements into specifications, pair-\nprogramming with AI for code refactoring, bug prediction, and test automation. \n\nmailto:philip.s.luther727@gmail.com\n\n\n‚Ä¢ Designed and executed intelligent testing frameworks that auto-generated cases, enabling predictive bug \ndetection and self-healing capabilities in production. \n\n‚Ä¢ Built APIs supporting financial integrations and communication features, ensuring API governance, security, \nand optimized throughput. \n\n‚Ä¢ Mentored junior developers on cloud-native engineering and AI-assisted workflows, fostering a culture of \ncontinuous learning. \n\n‚Ä¢ Collaborated with product, design, and DevOps teams to enhance developer productivity, improve CI/CD \npipelines, and streamline deployments. \n\n‚Ä¢ Consistently delivered business-critical software balancing engineering rigor with rapid delivery, enabling \nsignificant improvements in system availability and customer experience. \n\n\t\n\nSalesforce ‚Äì San Francisco, CA \n\nSenior Software Engineer | Feb 2019 ‚Äì Aug 2021 \nAt Salesforce, I contributed to large-scale financial services platforms, building secure, API-driven systems using \n.NET, C#, and Azure. My work focused on enabling customer-facing applications while modernizing Salesforce‚Äôs \nfinancial workflows with Azure migration and AI-assisted development. \n\n‚Ä¢ Designed and developed robust .NET and C# applications integrated with SQL Server, optimizing performance \nand scalability for high-transaction environments. \n\n‚Ä¢ Executed large-scale Azure migrations, modernizing legacy applications into cloud-native solutions leveraging \nAzure App Services, Cosmos DB, and Kubernetes. \n\n‚Ä¢ Collaborated with AI copilots to accelerate feature development, leveraging automation in testing, bug \ndetection, and architecture refinement. \n\n‚Ä¢ Built intelligent APIs consumed by customer-facing applications, ensuring compliance with security standards \nand improving developer experience across teams. \n\n‚Ä¢ Implemented CI/CD pipelines using GitHub Actions and Azure DevOps, automating deployments, improving \nreliability, and reducing release cycle times. \n\n‚Ä¢ Championed TDD practices and integrated intelligent testing frameworks, ensuring that automated testing \nevolved with feature development. \n\n‚Ä¢ Worked across cross-functional teams to align technical solutions with evolving business goals, especially \nwithin financial services and customer engagement systems. \n\n‚Ä¢ Mentored engineers on cloud migration best practices, AI-assisted coding, and scalable architecture design. \n\n\t\n\nHashiCorp ‚Äì San Francisco, CA \n\nSoftware Engineer | Nov 2017 ‚Äì Dec 2018 \nAt HashiCorp, I focused on infrastructure automation, cloud orchestration, and backend engineering for enterprise \nclients. My role required designing scalable solutions leveraging .NET, Python, and cloud infrastructure. \n\n‚Ä¢ Developed cloud-native back-end services integrating .NET and Python applications with SQL Server, ensuring \nhigh performance and compliance for enterprise customers. \n\n‚Ä¢ Supported infrastructure-as-code development using Terraform and Ansible, automating deployments and \nreducing manual configuration overhead. \n\n\n\n‚Ä¢ Built secure APIs and service connectors for enterprise-grade platforms, focusing on scalability, observability, \nand compliance. \n\n‚Ä¢ Worked on containerized workloads using Docker and Kubernetes, improving resiliency and portability of \napplications. \n\n‚Ä¢ Applied AI-assisted coding practices to enhance productivity and identify optimization opportunities in large \ncodebases. \n\n‚Ä¢ Participated in CI/CD design, integrating automated testing and intelligent monitoring for infrastructure \nservices. \n\n‚Ä¢ Contributed to developer tooling and platform enablers that improved engineering workflows and accelerated \ndeployments. \n\n‚Ä¢ Collaborated with engineering leads to refine architecture decisions, balancing business value with technical \nfeasibility. \n\n\t\n\nEducation \n\nBachelor of Science in Computer Engineering \nUniversity of Texas at Dallas | 2013 ‚Äì 2017 \n\n\t\n\nProjects \n\n‚Ä¢ Azure Migration Platform: Designed and executed migration of enterprise applications to Azure, re-\nplatforming legacy systems into scalable AKS-based architectures. \n\n‚Ä¢ AI-Enhanced CI/CD Pipelines: Built CI/CD pipelines with AI-driven testing frameworks that predicted bugs \nand self-healed during deployments. \n\n‚Ä¢ Financial API Suite: Led development of secure APIs for financial services and payment systems, ensuring \ncompliance with security standards. \n\n‚Ä¢ Cloud-Native Developer Toolkit: Built enablers and AI-assisted developer tools that improved engineering \nworkflows and developer productivity. \n\n‚Ä¢ Enterprise Microservices Architecture: Delivered microservices-based backend with .NET, C#, and Azure \nFunctions, improving resiliency and reducing system complexity.
ceedd780-1cab-41c0-88b8-5e76caf0330e	Rai Prashantk	rai.prashantk@gmail.com	Screening	Technology Architect	20	Prashant Rai\n\nCredentials\n\nKey Expertise\n\nOverview\n\nRelevant Experience\n\n? Accenture Celebrates Excellence Award\n? Avanade ORANGE Award\n? Amazon Alexa Skills Challenge\n? Accenture TechSummit\n\n? Designing Azure AI Solution (AI-102)\n? Azure Solutions Architect (AZ-305)\n? Microsoft DevOps Solutions (AZ-400)\n\n? Implementing Microsoft Azure Infra Solutions\n? Certified Information Technology Architect (CITA)\n? Masters Technology Architect Certification (TA)\n\nAw\nar\n\nds\n\nFull Stack Technology Architect | Lead | Big Data | Gen AI\n     rai.prashantk@gmail.com         +1 (312)-522-9258\n    Employer: ACCENTURE (Chicago, USA)\n\nCloud\nAzure, AWS, GCP, PCF; Azure Functions, Logic Apps, Service Bus, \nKeyVault, Docker / Container, Kubernetes, APIM, CosmosDB, \nMongoDB, Datadog\n\nProgra\nmming\n\nVisual Studio, .NET 8, C#, REST API, WCF, Web Services, ASP.NET, \nMVC, NodeJS, Angular, React, PowerShell, Python\nSpring Framework (Spring Boot, Spring MVC, Spring Data)\n\nGen AI Azure OpenAI Service, AI Studio, AI Search, LangChain, LangGraph, \nGitHub Copilot, RAG\n\nData\nAzure Data Factory, Data Lake, DataBricks, Synapse, Fabric, \nAlation, Power BI, Power Apps, Automate, SQL Server, MySQL, \nDB2, AuGR\n\nDevOps\nAzure DevOps, GitHub, Snyk, Checkmarx, CyberArk, Terraform, \nFlyway, Bicep, Pulumi, Ansible, Octopus, SonarQube, IaC\n\nOthers Okta, Salesforce, ServiceNow, Kentico, Apigee, MuleSoft, \nDocuSign, SharePoint, SmartComm, FileNet, CloudHealth, Wiz\n\n? Multi-skilled Technology Architect, Full stack, Big Data, Microsoft certified \nwith 17+ years of exp and specialized in Cloud technologies\n\n? Multi-cloud exposure - cloud / digital modernization, transformation, \napplication and data migration strategy across the enterprise\n\n? Gen AI Solutions - experience in developing, deploying Gen AI apps\n? Unified approach for Enterprise API development and integrations\n? Strategy for Application performance engineering, application logging, \n\nmonitoring, security, and optimization \n? Service management process standardization and automation strategy\n? Hands on exposure on setting up DevOps and DevSecOps processes\n? Supports business growth opportunities, pre-sales and deals (RFE)\n? Well-versed in Agile (Scrum), SAFe, and Waterfall methodologies\n? Managing client enterprise delivery for large scale complex programs \n\nhaving global team model of onshore and offshore\n\nModern Engineering Tower (API Integrations and Data Foundation) Aug | 2019 - Present\n\n? Collaborating with client Enterprise Architects - develop Multi-Cloud strategy, establish a Landing Zone, implement a Cloud \nAdoption Framework and Zero-Trust Security model \n\n? Formulating a Cloud Enablement strategy - that incorporates Hub & Spoke Cloud Architecture, Infrastructure as a Code (IaC), \nPolicy as a Code ? addressing Modernization and Migration along with Data strategy across the Enterprise\n\n? Leading the Generative AI Solutions ? Developed detailed business case and reference architecture, use cases, POCs\n? Revamping Enterprise API Solutions - building reusable APIs using latest cloud technologies, defining API-first approach, adhering \n\nto OpenAPI specifications and API-led architecture, including serverless and containerized APIs\n? Streamlining integration for Document Generation and management process - using SmartComm, FileNet and DocuSign\n? Implementing API Management solutions and Security measures, along with defining Integration strategy for multiple downstream \n\nsystems. PAS (AuMine, AS400, Majesco), and other platforms including  Oracle CX, Salesforce \n? Developing platform migration strategy - Colo to Cloud, PCF to Azure, multi-org strategy for Datadog integration\n? Establishing Governance and Security model - Standardizing security, Identity and access management\n? Setting up Azure DevOps and DevSceOps practices including Infra Provisioning strategy and CI/CD pipelines\n? Responsible for overseeing planning, execution, and enterprise delivery for large-scale complex programs, utilizing a global team \n\nstructure model of onshore and offshore, defining the project scope, objectives, budget, and timeline\n\nData Foundation Capabilities\n? Designed and implemented data integration, migration strategy from legacy on-prem to modern cloud-based solutions\n? Architected scalable data warehousing solution, led the deployment and migration of cloud-based data warehouse\n? Defining strategy and solutions for enterprise Master Data Management - Operational and Transaction Data Stores \n? Development of Data Management and Datawarehouse solutions - Data Ingestion, Modeling, Reporting and Visualization\n? Migrated legacy SSRS reports using MDX/SQL to Power BI with integrated data models for enhanced analytics\n? Canonical Data Modeling - Standardization of schemas to align with industry standards (ACORD, Salesforce) \n? Roadmap and data governance framework ? standards, metadata, lineage, data quality, security and compliance\n\nApplication Support and Maintenance Capabilities\n? Establishing a strategy for delivering round-the-clock support and overseeing various applications within the enterprise - Incident, \n\nProblem and IT Change management - including minor enhancements, platform upgrades\n? Implementing a standardization and adoption program for service management processes using Service Now (SNOW)\n? Define strategies to meet  service level agreements (SLAs) and monitor key performance indicators (KPIs)\n? Establish integration between Azure DevOps and ServiceNow ? bring incidents insights to Azure DevOps and consistency\n\nmailto:rai.prashantk@gmail.com\n\n\tSlide 1 PRASHANT RAI \nEmail : rai.prashantk@gmail.com  \n\nMobile : +1 (312) 522-9258 \n \n\nPROFESSIONAL SYNOPSIS \n \n\n? Multi-skilled, Fullstack Sr. Technology and Data Architect, having 17+ years of experience, working with Accenture LLP, leading \nmultiple architectural roles from assessment to execution, migration, and operations support for various large solutions \n\n? Design scalable data architecture solutions and governance strategy using cloud-native technologies and platforms \n? Managing client enterprise delivery for large scale complex programs having global team of onshore and offshore model \n? Multi-cloud exposure ? cloud and digital modernization, application migration strategy across the enterprise \n? Unified strategy and approach for Enterprise API development and integrations along with API management solutions \n? Gen AI Solutions ? great exposure with developing, deploying Gen AI applications along with wrapper for core APIs \n? Driving Data transformation from legacy data and analytics systems to cloud based modern data architectures \n? Establishing Governance and Security model - standardizing security, identity and access management, Okta integration \n? Focused on continuous improvement - client centric innovations and initiatives including modern engineering platform, \n\nnewIT, automation architecture and design of IT systems and applications \n? Great exposure in solutioning - pre-sales and deal support, architecture assessment and project management \n? Strategy and design for Application performance engineering, application logging, monitoring, and optimization  \n? Hands on exposure of DevOps, DevSecOps processes including Agile (Scrum), SAFe and Waterfall methodologies \n\n \n \n\n \n\nIT SKILLS \n \n\nGen AI Solutions: Azure OpenAI Service, AI Studio, AI (Cognitive) Search, LangChain, LangGraph, Python, GitHub Copilot \n\nCloud Computing: \n\nAzure: Azure DevOps, Azure APIM, Azure Kubernetes Service (AKS), Logic Apps, Functions, Keyvault, App Services, \nAzure IoT, Static Web Apps, Datadog \n\nAWS: AWS Lambda, DynamoDB, S3, Amazon Alexa Skills etc. \n\nCloud Foundry (PCF): Orgs and Spaces, Containers, Deployments etc. \n\nProgramming Skills / \nTechnologies: \n\n.NET 8, Visual Studio Code, Visual Studio 2022, C#, Web API, MVC, ASP.NET, LINQ, Entity Framework \n\nUnqork, Angular, TypeScript, NodeJS, NestJS, HapiJS, RxJS, Redis, Material Design, ReactJS, JQuery \n\nJestJS, Karma, Jasmine, Angular Mock, Protractor \n\nHigh Charts, Telerik Rad Controls, Kendo UI Controls, DevExpress Controls, NetSuite \n\nServices / API: REST API, WCF, Web Services, Lucene.Net, Apigee, MuleSoft (Basic) \n\nCMS / Other: Kentico, Sitecore (Basic), SmartComm, FileNet, DocuSign \n\nDatabase:                   CosmosDB, MongoDB, MS SQL Server 2019, Azure SQL MI, MySQL, DB2 \n\nData Analytics / BI: Azure Data Factory, Data Lake, DataBricks, Synapse, Snowflake, Fabric, Power Apps, Power BI, SSRS, SSIS, SSAS \n\nDev / Testing Tools: NUnit, Moq, Fx-Cop, Style-Cop, Nuget, Log4Net, Lint, AppFabric, Mobile Labs, BrowserStack \n\nQuality Control: Snyk, Checkmarx, CyberArk, ReSharper, SonarQube, Coded UI Testing, Performance and Load Testing \n\nDevOps: Azure DevOps, GitHub, TFS, Team City, Octopus Deploy, JFrog, PowerShell, Terraform \n\nAPM Tools: App Insights, App Dynamics, New Relic, Splunk \n\nCollaboration Tools: Confluence, HipChat, Slack, Microsoft Teams, Ideaboardz, PlanItPoker \n\nMethodology / SDM: Agile (SCRUM), Scaled Agile Framework (SAFe), DevOps, Waterfall \n \n \n\nREWARDS / CERTIFICSTIONS  \n \n\nCertifications \n\nDesigning Azure AI Solution (AI-102) Microsoft Azure Architect Design (AZ-301) \n\nMicrosoft Azure Solutions Architect (AZ-305) Architecting Microsoft Azure Solutions (70-534) \n\nDesigning and Implementing DevOps Solutions (AZ-400) Developing Microsoft Azure Solutions (70-532) \n\nCertified Information Technology Architect (CITA-F) Implementing Microsoft Azure Infrastructure Solutions (70-533) \n\nMasters Technology Architect (MTA) Certification (TA) Microsoft Azure Fundamentals (AZ-900) \n\nAwards \n\n? ACE (Accenture Celebrates Excellence) Award \n? Avanade ORANGE Award \n\n? Amazon Alexa Skills Challenge \n\n? Accenture TechSummit Award \n? Accenture Technopia Award \n\n? Best Asset Award \n \n \n \n \n \n\nmailto:rai.prashantk@gmail.com\n\n\nPROFESSIONAL EDUCATION  \n \n\nExamination Period Board / University \n\nMaster of Computer Applications (MCA) 2001 ? 2004 Uttar Pradesh Technical University, Lucknow \n\nBachelor of Science (B.Sc.) 1998 ? 2001 University of Delhi, Delhi \n \n\nEMPLOYMENT HIGHLIGHTS  \n \n\nEmployer Period Role \n\nAccenture Solutions Pvt. Ltd. August/2014 ? Present Sr. Technology Architect \n\nOSC Services Pvt. Ltd. May/2014 ? August/2014 Technical Lead / Architect \n\nNIIT Technologies Ltd. March/2010 ? May/2014 Technology Consultant / Architect \n\nEspire Infolabs Pvt. Ltd. April/2008 ? March/2010 Sr. Analyst \n\nFiveTool Software Inc. April/2005 ? April/2008 Sr. Software Engineer \n \n\nPROJECTS HIGHLIGHTS  \n \n\nProject Affinity - Modern Engineering Tower (AON, USA) [Sep/2020 ? Present] \nRoles Sr. Technology Architect, Full Stack, Delivery Lead \n\nResponsibilities \n\n1. Leading modern engineering tower for cloud initiatives, transformations, data and migrations across the enterprise \n2. Collaborating with client Enterprise Architects ? setting up roadmap, develop multi-cloud strategy, establish a \n\nLanding Zone, implement a Cloud Adoption Framework and Zero-Trust Security model \n3. Formulating a Cloud Enablement strategy - that incorporates Hub & Spoke Cloud Architecture, Infrastructure as a \n\nCode (IaC), Policy as a Code (PaC) \n4. Setting up baseline Security Standards and Reference Architecture for each component in the cloud ? building \n\nreusable controls using Terraform for all major services and components in Azure \n5. Leading the Generative AI Solutions - exploring use cases, POCs, designing tailored AI apps and wrapper APIs \n6. Establishing Governance and Security model - standardizing security, policy, compliance, identity and access \n\nmanagement, integration with Okta, and DevSecOps practices \n7. Productivity improvements using Gen AI Copilots - GitHub Copilot significantly improves developer productivity \n8. Code quality, review processes and standards - define best practices and design standards including security, error \n\nhandling, logging, caching, and other nonfunctional requirements \n9. Supporting application?s static and dynamic security testing - pen testing and verification using standard \n\nguidelines (OWASP, NIST, CWE) and client data protection (CDP) measures \n\nTools & \nTechnologies \n\nAzure DevOps, IaC, Terraform, Pulumi, Docker, Visual Studio Code, .NET 8.0, Web API, C#, NodeJS, Unqork, \nTypeScript, Git, Cosmos DB, Azure Kubernetes Services (AKS), Docker, Azure Functions, App Services, MongoDB, WSL, \nEntity Framework, PowerShell, Swagger, GitHub Copilot \n\n \n\nProject Affinity ? API Development and Integrations \n\nResponsibilities \n\n1. Revamping Enterprise API solutions and integrations ? building reusable APIs using latest cloud technologies, along \nwith test driven development, dependency management, branching and merging strategy etc. \n\n2. Defining API-first approach, adhering to OpenAPI specifications encompass serverless architectures, loosely \ncoupled systems, and containerized APIs \n\n3. Setting up Service Discovery and strategy for API-led connectivity for designing reusable and purposeful APIs \n4. Streamlining integration for Doc Generation and management process - using SmartComm, FileNet and DocuSign \n5. Implementing API Management solutions along with defining Integration strategy for multiple downstream \n\nsystems. PAS (AuMine, AS400, Majesco), and other platforms including Oracle CX, Salesforce \n6. Developing platform migration strategy ? from Colo to Cloud, PCF to Azure, On Prem MySQL to Azure SQL including \n\nmulti-org strategy for Datadog integration \n7. Establishing API Governance and Security model ? defining API best practices and standards, APIs versioning \n\nstrategy and documentation platform \n8. Setting up DevSecOps practices ? using Azure DevOps and defining build pipelines for different environments \n\nTools & \nTechnologies: \n\nVisual Studio 2022, .NET 8.0, Web API, C#, Entity Framework Core, NodeJS, Git, TFS, Azure Kubernetes Services (AKS), \nDocker, Azure Functions, Service Bus, MuleSoft, CosmosDB, MongoDB, WSL, Azure DevOps, PowerShell, WSL, Nginx, \nCloud Foundry, MySQL, AS400, AuMine \n\n \n\nProject Data Foundation and Analytics \n\n\n\nResponsibilities 1. Development of data management solutions, encompassing data Ingestion, modeling, reporting and visualization \n2. Leverage extensive data architecture expertise - optimize data infrastructure, enhance data quality, and drive \n\ndata-driven innovation and integrations \n3. Canonical Data Modeling - Standardization of schemas (across multiple line of businesses) to align with industry \n\nstandards (ACORD, Salesforce Velocity) across the enterprise \n4. Design and implementation of data integration and migration strategy - from legacy, complex on-prem \n\nenvironments to modern, cloud-based solutions \n5. Architected scalable data warehousing solution, led the deployment and migration of cloud-based data warehouse \n6. Defining strategy for building real-time Transaction Data Stores (TDS) - integrating data from multiple sources, \n\nimproving data consistency and reducing manual data reconciliation efforts \n7. Defining strategy and solutions for enterprise Master Data Management (MDM) - Operational Data Stores (ODS) \n\nwith Golden Records and Reference Data \n8. Defining automate strategy for data pipelines using modern ETL tools and frameworks for efficiency \n9. Strategy for establishing data governance framework ? data standards, data catalog, metadata management, data \n\nlineage, data quality, data security and compliance \nTools & \nTechnologies \n\nAzure Data Factory, Data Lake, DataBricks, Synapse, Fabrics, Snowflake, Power Apps, Power BI, AuGR, Microsoft \nPurview, Alation, SQL Server Technologies ? Triggers, Service Brokers, Change Data Captures etc. \n\n \nProject MeasureMint HCS (AON, USA) [Jan/2020 ? Aug/2020] \n\nHuman Capital Solutions (HCS) delivers HR consulting, outsourcing, training, and development solutions that help leading organizations \nmake the most out of their people: their most important asset. MeasureMint comes under convergence initiatives to modernize and \nmigrate existing applications by utilizing all latest technology stacks like Modern engineering platform, Cloud technologies, DevOps etc. \n\nRole Technology Architect, Full Stack \n\nResponsibilities \n\n1. Defining the strategy and design next-Gen (micro-services, liquid), loosely coupled architecture using best practices \nand different technology stacks. \n\n2. Defining strategy for managing serverless, containerized applications using Azure, Azure Kubernetes Service (AKS), \nDocker, Azure Functions, .Net Core and other technology stacks. \n\n3. Setting up Windows Subsystem for Linux (WSL) for local development environment and created Linux utilities. \n4. Application modernization and migration strategy - using Cloud computing, and newIT technology stack. \n5. Setting up DevOps by using Azure DevOps and defining build pipelines for different environments. \n6. Setting up and implement Infrastructure as Code (IaC) by utilizing Azure DevOps and Pipelines. \n7. Setting up Test driven development approach using Jest, Karma, Jasmine etc, and improvising client?s processes? \n\n(Agile and Scrum) improvements along with best practices. \n8. Strategy, design and seamless integration approach and architecture for multiple client vendor applications. \n9. Setting up strategy for integrating MIRT engine using R-Code library and expose it as an API.  \n10. Define strategy for request processing pipeline, process and manage multiple background jobs using Hangfire. \n\nIntegration strategy with myWizard (Analytics for Application Management). \n11. Manage code quality and optimization by static and runtime code review, code refactoring, continuously \n\nmonitoring several metrics and code analysis ? leveraging tools like SonarQube, Lint and other extensions etc. \n\nTools & \nTechnologies \n\nVisual Studio Code, .Net Core 3.0, Reactive Programming, MVC, Web API, C#, Angular 10.0, NodeJS, NestJS, RxJS, \nTypeScript, Git, Azure Kubernetes Services (AKS), Docker, Azure Functions, CosmosDB, MongoDB, WSL, Azure DevOps, \nEntity Framework, SonarQube, SwaggerUI, Mobile Labs, BrowserStack, GrayLog, MuleSoft, Hangfire, Akamai. \n\n \n\nProject: GATE, TRP (AON, USA) [Apr/2018 ? Dec/2019] \n\nAon's Talent, Rewards & Performance practice (TRP, HCS) is all about people. It specialises in talent assessments, vendor integrations, \nemployee engagement, rewards, executive remunerations, data analytics etc. \n\nGATE (Global Assessment and Talent Engine) is the online portal, through which, an Aon assessment can be taken. This online feature \nallows for easy accessibility so that the exam can be self- administered and taken from any internet-accessible personal computer, tablet, \nor mobile device. It allows test takers the option to choose from a variety of languages, an easy to use, multi-lingual experience. \n\nRole: Technology Architect / Support Lead \n\n\n\nResponsibilities \n\n1. Defining strategy for providing 24X7 support and managing multiple applications across enterprise using best \npractices and different technology stacks. \n\n2. Extensively provided support as a Level2, Level3 to support 10+ tier 1 applications. Extensive experience in Incident, \nProblem and IT Change management. \n\n3. Great problem-solving approach having strong communication, leadership skills and ability to work in a time-\nconstrained and team-oriented environment. \n\n4. Service management process standardization and driving training and adoption program for Service Now (SNOW) \nacross client and business users across organization. \n\n5. As part of Initiatives and innovations - designing different ?BOTs? to handle multiple tasks for applications and \nminimizing human interventions. \n\n6. Automation architecture and design for managing and monitoring IT systems and applications - Accenture tools \n?myWizard? and ?Accenture myWizard Analytics for Application Management (AAAM). Implement tools like ?Auto-\ntriaging BOT?, ?Accenture Ticket Solver (KM Tool)?, ?Automatic Ticket Resolver BOT (Cognitive tool)? etc. \n\n7. Proactive application processes monitoring, identified enhancements, root cause analysis for a bug, CRs and \ndevelopment requirements.  \n\n8. Define strategy for request processing pipeline, create, process and manage multiple background jobs using \nHangfire and Window Services. Driving integration of myWizard, Service Now (SNOW) and TFS. \n\n9. Application performance engineering, monitoring and optimization - utilizing App Dynamics, New Relic and Splunk. \n10. Log Aggregation ? Defining strategy for centralizing all log data by utilizing tools like Azure, GrayLog2. \n11. Continuous integration and deployment - leveraging tools TeamCity, Octopus Deploy, Git, TFS, etc. Managing \n\nRackspace, Akamai, CDN and configurations for multiple environments. \n\n \n\nRole Technology Architect / Onshore Coordinator Lead \n\nResponsibilities: \n\n1. Defined the strategy and design next-Gen (micro-services, liquid), loosely coupled architecture using best practices \nand different technology stacks. \n\n2. Application modernization and migration strategy - using Cloud Computing and NewIT technology stack. \n3. Define strategy for system Integration architecture and design for Vendor ATS and third-party complex \n\napplications like Workday, Taleo, Kenexa, SuccessFactors, HigherMe and Boomi etc. Service Now (SNOW) \nintegration with Team Foundation Server (TFS). \n\n4. Automation architecture and design for IT systems and applications - Accenture tools ?myWizard? and \n?Accenture myWizard Analytics for Application Management (AAAM). Initiatives and innovations. \n\n5. Define strategy for request processing pipeline, create, process and manage multiple background jobs using \nHangfire and Window Services. Integrating this with myWizard as well. \n\n6. Implement and configure SAML-based Single SignOn (SSO) with Azure and multiple vendor applications. \n7. Application performance engineering, monitoring and optimization - monitoring, measuring and diagnostic. \n8. Responsible for Continuous Improvement - including setting up client?s processes (Agile and Scrum) \n\nimprovements, best practices, quality, architecture etc. \n9. Manage code quality and optimization by static and runtime code review, code refactoring, continuously \n\nmonitoring several metrics and code analysis ? leveraging tools like SonarQube, JSLint, Visual Studio. \n10. Continuous Integration - leveraging tools TeamCity, Octopus Deploy, Git, TFS, etc. \n11. Managing Rackspace, Akamai, CDN and configurations for multiple environments. \n12. Setting up DevOps by using Microsoft Azure DevOps technology stacks and JFrog Artifactory. \n\nTools & \nTechnologies \n\nVisual Studio 2015/2017/Core, MVC 5.0, Web API, C#, Entity Framework, HTML5, Angular, AngularJS, NodeJS, \nLog4Net, Git, TFS, NUnit, PowerShell, SonarQube, SwaggerUI, APM Tool (AppDynamics), SQL Sentry, Mobile Labs, \nBrowserStack, Azure, GrayLog2, Ethereum, MuleSoft, Azure DevOps, JFrog Artifactory, Hangfire, Akamai, Kentico. \n\n \n\nProject IT Foundational (AON, USA) [Mar/2017 ? Feb/2018] \n\nIT Foundational is a division specializes on improving system quality through focus on application performance, process improvement and \ntechnical debt for the TBS platform.  The team focuses on development, planning, and prototyping of strategic platform initiatives like \ncloud enablement, scaling, performance optimization, and development process improvements. \n\nRole Technology Architect \n\nResponsibilities \n\n1. Lead the Tactical team and part of Strategic team. Worked on roadmap and phases deliverables. \n2. High priority performance optimizations of application and user experience improvement. \n3. Evaluating strategic options for addressing performances and process improvement issues like Cloud \n\ntransformation of the application, DevOps etc. \n4. Setup roadmap analysis and risk factors consideration for application?s migration to cloud (Azure) along with \n\nplanning and architecture designing and latest cloud computing features.  \n5. Setup a centralized logging solution so that multiple logs can be aggregated in a central location. \n6. Explore Infrastructure Automation for Feature-Based Deployments and QA Automation. \n7. Refactor Application Auditing solution and improvements. \n8. ALM Improvements and Agile Progression. \n9. Being part of TACG group, also worked on Blockchain as a Service (BaaS) using Ethereum Blockchain technology \n\ninto Azure and other innovations. \n\n\n\nTools & \nTechnologies \n\nVisual Studio 2013/2015, MVC 5.0, Web API, C#, Entity Framework 6, Dapper, Azure, Logic Apps, HTML5, AngularJS, \nLog4Net, ELMAH, Git, TFS, NUnit, PowerShell, SonarQube, Swagger, APM Tool (AppDynamics), NodeJS, Auditing Tools \n(Service Broker), SQL Sentry, Mobile Labs, BrowserStack, InRule, Sequence, Azure, GrayLog, Ethereum. \n\n \n\nProject Greater Insight - TBS (AON, USA) [Dec/2015 ? Feb/2017] \n\nTBS (The Benefits Solution) is one platform for delivering engagement, administration, analytics and value; portal that create consistent, \nengaging and effective communication to optimize costs and maximize return on investment. It delivers greater benefits visibility, \ngovernance and control; ensure benefits remain relevant and competitive; secure the most competitive and commercial terms; deliver \ncomplex employee communications and enhance benefits perception, appreciation and understanding. This portal provides access to 4 \nkey features: Employee Portal, Client Portal, ?Hubble? Benchmarking and e-Broking. \n\nRole Technology Architect \n\nResponsibilities: \n\n1. Designing next-Gen architecture using Visual Studio 2013, AngularJS, MVC, API, and SQL Server 2012. \n2. Planning Security Architecture and setup development architecture including environment, Unit Testing, \n\nConfiguration Management and Code Review Best Practices. \n3. Automated Builds (CI/CD) implementation using TFS/Git, TeamCity and Octopus Deploy. \n4. Implemented ?Agile? methodology across work-streams and its best practices. \n5. Application Performance Engineering using profiling, measuring, diagnostic and optimization. \n6. Setup auditing mechanism using Asynchronous Triggers and Service Broker. \n7. Implementing Google Analytics and Azure CDN to the application. \n8. API Documentation and Discoverability using Swagger. \n9. Providing mentoring and training to the team on different technologies required into project. \n\nTools & \nTechnologies \n\nVisual Studio 2013, Asp.Net, MVC 5.0, Web API, C#, Entity Framework 6, Dapper, HTML5, AngularJS, Log4Net, \nELMAH, Git, TFS, NUnit, Moq, PowerShell, Fx-Cop, SonarQube, Style-Cop, Fiddler, neXpert, Swagger, APM Tool \n(AppDynamics), NodeJS, Jasmine, Karma, Angular-Mock, Auditing Tools (Service Broker), SQL Sentry, Mobile Labs, \nBrowserStack, InRule, Sequence, Azure. \n\n \n\nProject GIRO (Schlumberger, UAE) [Mar/2015 ? Dec/2015] \n\nThe Global International Rotator Optimization Project (GIRO) basically helps the international commuters for their compensation and \nbenefits packages to enable segments to better manage their compensation costs, align the international commuter compensation with \nmarket trends (more cash and less deferred benefits focused), streamline processes and systems used for international commuters? \npayroll, time-off and benefits administration. It also automates the Employee Self Service options ? Health Care, Insurance, Deferred \nBenefits, and Designation of beneficiary. Reducing the number of Manual processes  \n\nRole Technology Architect \n\nResponsibilities \n\n1. Setup strong communication with client for did Gap Analysis at Process and Architecture level. \n2. Requirement Analysis, Planning for Development and QA environments. \n3. Architecture Re-design with minimum impacts and along with all required Non-Functional requirements. \n4. TFS best practices for planning Code Repository along with Branching and Merging. \n5. Unit Testing, Build Automation using Continuous Integration. \n6. Maintaining Code Quality with Code analysis, Code review, Code refactoring, and proper documentation. \n7. Application Performance Engineering using profiling, measuring, diagnostic and optimization. \n8. Planning for Application Scalability and its proper State Management. \n9. Planning for High availability and Disaster recovery. \n10. End to end Delivery with meeting all qualification criteria gates and deliverables. \n\nTools & \nTechnologies \n\nVisual Studio 2013, Asp.Net, MVC 5.0, Web API, C#, Entity Framework, HTML5, AngularJS, Log4Net, ELMAH, ADFS, \nTFS, PowerShell, Fx-Cop, Style-Cop, Fiddler, neXpert, AutoMapper. \n\n \n\nProject iBuddy for Visually Challenged (Accenture, IDC) [Jan/15 ? Mar/15] \n\nThe innovation is all about how we leverage the emerging and assistive technologies to enable the indoor navigation for visually \nchallenged people, especially where No GPS exists. iBuddy works as a 'digital stick' for a visually impaired person and provide interactive \nnavigation guidance using context aware devices like beacons and sensors. One of the key features is its eye-free user interface with \none touch swipe and select. Text to speech and voice recognition are key components of iBuddy. This idea got first prize in Accenture \nTechnology Delivery Innovation Summit. \n\nRole Technology Architect \n\nResponsibilities \n\n1. Requirement Analysis, Planning for Development environment on DCS, along with TFS Service. \n2. Created layered and SOA based Solution Architecture and guided team to use. \n3. Created Admin Portal for managing settings and master data. \n4. Planning for infrastructures for deployment on Azure using Accenture Cloud Platform (ACP). \n5. Team Management, Task Distribution, Prioritization, Feedback and Evaluation. \n\nTools & \nTechnologies \n\nVisual Studio 2013, Xamarin, MVC 4.0, Web API, C#, Entity Framework, HTML5, Angular, jQuery, Azure (IaaS), ADFS, \nTFS/Git, PowerShell.
579a928c-7d89-4f3b-96bf-e65c37d0f7be	Rodolfovaldez Tech	rodolfovaldez.tech@gmail.com	Screening	Senior Software Engineer	11	Rodolfo Valdez\n\trodolfovaldez.tech@gmail.com\n\t(469) 638-3433\n\tDuncanville, TX 75137\n\n\nSUMMARY\nSenior Software Engineer with 12 years of experience designing, developing, and delivering enterprise-grade software solutions. Specialized in .NET, C#, SQL Server, and Azure cloud-native applications, with a strong record of leading migration strategies, microservices architecture, and AI-assisted development workflows. Skilled in CI/CD pipelines, automated testing, and AI code copilots to build scalable, reliable, and production-ready solutions. Adept at mentoring engineers, collaborating across teams, and driving innovation in high-paced environments, particularly in healthtech and financial services.\nSKILLS\n¬∑ Languages & Frameworks: .NET, C#, ASP.NET Core, JavaScript, TypeScript, Python\n¬∑ Cloud & Infrastructure: Azure (AKS, App Services, Functions, Cosmos DB, DevOps), Docker, Kubernetes\n¬∑ Databases: SQL Server, PostgreSQL, MySQL\n¬∑ Development Practices: Microservices, AI-assisted development (GitHub Copilot, Claude), TDD, BDD, CI/CD, Agile/Scrum\n¬∑ Testing & Automation: Automated Unit & Integration Testing, Intelligent Testing Frameworks, API Testing Tools\n¬∑ Other Tools: Terraform, Git, GitHub Actions, Azure DevOps Pipelines\nEDUCATION\nBachelor of Science in Computer Science\nUniversity of Texas ‚Äì Austin | Austin, TX \t\t\t\t\t\t         Aug 2008 ‚Äì May 2012\nPROFESSIONAL EXPERIENCE\nSenior Software Engineer\nSesame | New York, NY \t\t\t\t\t\t\t\t\t  Apr 2021 ‚Äì Present\n¬∑ Designed and developed enterprise-grade applications using .NET and C#, supporting real-time health and payment systems.\n¬∑ Led Azure migration strategies, re-platforming legacy services into cloud-native architectures leveraging Azure App Services, Functions, and Cosmos DB.\n¬∑ Built and optimized microservices deployed on Azure Kubernetes Service (AKS) to ensure scalability and maintainability.\n¬∑ Collaborated with AI copilots (GitHub Copilot, Claude) to accelerate code development, refactoring, and testing, enabling faster delivery of production-grade solutions.\n¬∑ Applied AI-assisted workflows to translate stakeholder requirements into technical specifications and system designs.\n¬∑ Developed intelligent automated testing frameworks that generated test cases, predicted bugs, and reduced regression defects.\n¬∑ Implemented CI/CD pipelines with Azure DevOps and GitHub Actions, ensuring seamless deployments and continuous delivery.\n¬∑ Conducted concurrent test automation during development to guarantee code quality and maintain full coverage.\n¬∑ Partnered with product managers and architects to define cloud-first application designs aligned with business objectives.\n¬∑ Guided a team of engineers in adopting TDD and AI-driven development practices, promoting consistency and high-quality outcomes.\n¬∑ Mentored junior engineers in .NET, Azure cloud services, and AI-assisted programming best practices.\n¬∑ Designed and maintained SQL Server databases, optimizing performance and scalability of data-heavy applications.\n¬∑ Implemented API testing frameworks to validate integrations across health and financial data services.\n¬∑ Drove re-platforming of monolithic applications into modular, service-oriented solutions.\n¬∑ Spearheaded codebase modernization, using AI tools to identify technical debt and implement efficient refactoring strategies.\n¬∑ Enhanced security, compliance, and data protection measures across cloud-hosted services.\n¬∑ Played a leadership role in cross-functional teams, ensuring strong collaboration and successful product delivery in a fast-paced startup environment.\nSoftware Engineer\nCode&Care | Austin, TX \t\t\t\t\t\t\t\t\tJan 2018 ‚Äì Jan 2021\n¬∑ Developed custom web and enterprise applications using .NET, C#, and SQL Server, serving clients across finance, healthcare, and retail.\n¬∑ Assisted client teams in Azure migration initiatives, re-hosting on-premise systems to cloud-native environments.\n¬∑ Designed and consumed REST APIs for data exchange between distributed systems.\n¬∑ Built microservices and modular application components, improving scalability and maintainability for client solutions.\n¬∑ Collaborated with QA and DevOps to integrate CI/CD pipelines and enforce automated testing practices.\n¬∑ Leveraged AI code assistants during development to accelerate coding and refactoring tasks.\n¬∑ Worked closely with stakeholders to transform business requirements into technical architecture and clean code.\n¬∑ Participated in Agile ceremonies, driving sprint planning, backlog refinement, and collaborative reviews.\nSoftware Developer\nSyberry Corporation | Austin, TX \t\t\t\t\t\t\t\tApr 2014 ‚Äì Dec 2017\n¬∑ Developed .NET and C# web applications for clients in e-commerce, finance, and logistics.\n¬∑ Implemented SQL Server database schemas, stored procedures, and performance optimizations.\n¬∑ Built cloud-ready applications, gaining early exposure to Azure services and deployment strategies.\n¬∑ Supported modernization of legacy monolithic systems into modular, service-oriented architectures.\n¬∑ Contributed to automated testing suites and introduced unit testing best practices to client teams.\n¬∑ Collaborated with senior developers and architects to design and deliver enterprise-grade solutions.\n¬∑ Ensured adherence to Agile methodologies, participating in sprints, stand-ups, and retrospectives.\n¬∑ Partnered with cross-functional teams to deliver software aligned with client requirements and deadlines.
f0a335b1-3247-4f9e-a2f8-50cb418f9664	Rothluebbert Unknown	rothluebbert@gmail.com	Screening	Senior Software Engineer	7	Trevor Rothluebber\nrothluebbert@gmail.com\n\nPrescott, AZ\n\n+18143511541\n\ngithub.com/unibuzz12\n\nProfile\n\nLead Product Engineer with 8+ years of experience designing and deploying .NET/C# applications, \narchitecting Azure cloud-native solutions, and driving legacy-to-cloud migrations. Proven success \nin financial services, SaaS, and enterprise-scale platforms. Skilled in SQL Server, Azure services \n(AKS, Cosmos DB, Functions, App Services), AI-assisted SDLC, CI/CD, microservices, and \ncontainerization. Adept at leveraging AI copilots (GitHub Copilot, Claude) for code generation, \ntesting, and architecture iteration. Experienced in mentoring teams, leading migration initiatives, \nand delivering scalable, secure, and production-grade applications that meet strict compliance \nand uptime requirements.\n\nProfessional Experience\n\nSenior Software Engineer, Cisco 11/2021 ‚Äì 08/2025  | San Jose, CA\n‚Ä¢Spearheaded Azure migration strategy for multiple enterprise systems, re-platforming legacy \n.NET apps to Azure App Services and containerized microservices in AKS. Reduced infrastructure \ncosts by $350K annually and achieved 99.95% uptime SLAs for mission-critical applications used \nby 10,000+ employees.\n‚Ä¢Led design and deployment of .NET 8/C# applications with SQL Server backends, handling 20M+ \ndaily transactions. Optimized queries and indexing, reducing latency by 55% and cutting cloud \nconsumption by 30%.\n‚Ä¢Applied AI-enhanced SDLC by pairing with GitHub Copilot and Claude to generate unit tests, \nrefactor legacy C# modules, and accelerate feature delivery. Reduced development cycle time by \n40% while maintaining 92% code coverage.\n‚Ä¢Architected microservices and APIs in .NET and Azure Functions to support payment and identity \nservices, processing 1M+ secure API calls/month with sub-150ms latency.\n‚Ä¢Designed intelligent test frameworks with auto-generated test cases and predictive bug \ndetection, reducing QA backlog by 35% and preventing 50+ production incidents.\n‚Ä¢Partnered with DevOps to integrate Azure DevOps pipelines with Terraform and Kubernetes \ndeployments, cutting deployment times from hours to under 15 minutes.\n‚Ä¢Mentored junior engineers on cloud-native design and AI-assisted coding practices, improving \nteam velocity by 25% and adoption of AI tools by 60%.\n‚Ä¢Documented Azure migration patterns, .NET modernization strategies, and AI-enhanced \nworkflows in Confluence, serving as global playbooks for engineering teams.\n\nmailto:rothluebbert@gmail.com\ntel:+18143511541\nhttps://github.com/unibuzz12\n\n\nSoftware Engineer, BlackRock 03/2019 ‚Äì 11/2021  | New York, NY\n‚Ä¢Designed and modernized financial reporting systems with .NET Core, SQL Server, and Azure \ncloud services, processing 10M+ records daily across compliance platforms. Delivered a 40% \nfaster reporting pipeline, saving thousands of analyst hours annually.\n‚Ä¢Architected and executed Azure re-platforming initiatives for on-prem applications, leveraging \nCosmos DB, Functions, and App Services. Improved scalability, disaster recovery, and reduced \ndowntime during migrations to near zero.\n‚Ä¢Leveraged AI copilots (Copilot + Claude) to translate ambiguous stakeholder requests into \nstructured specifications and auto-generate test suites. Increased sprint velocity by 30% while \nimproving requirement traceability.\n‚Ä¢Implemented CI/CD pipelines via Azure DevOps and Bitbucket, orchestrating containerized \ndeployments in Kubernetes clusters. Improved release frequency from quarterly to weekly \nwithout regression spikes.\n‚Ä¢Built intelligent monitoring and alerting frameworks for SQL Server, incorporating anomaly \ndetection and self-healing capabilities. Reduced unplanned outages by 45% and improved SLA \ncompliance.\n‚Ä¢Developed secure microservices in .NET for financial data exchange, ensuring end-to-end \nencryption and ITAR-level compliance. Enabled 100% audit success rate for all services under \nregulatory review.\n‚Ä¢Promoted Agile AI-driven workflows by pairing programming with AI, reducing refactoring \nworkload by 25% and improving maintainability of large legacy codebases.\n‚Ä¢Provided technical leadership across global teams, reviewing architecture proposals and \nmentoring developers on Azure migration strategies, improving project delivery quality across \nthree departments.\n\nSoftware Engineer, ServiceTitan 11/2017 ‚Äì 02/2019  | Glendale, CA\n‚Ä¢Engineered .NET Core and C# applications integrated with SQL Server databases to power ERP-\nlike quoting, ordering, and billing workflows for 2,000+ SMB clients. Reduced customer churn by \n10% and improved order throughput by 20%.\n‚Ä¢Designed cloud-native APIs with .NET and Azure Functions, enabling real-time quoting and \ntransaction flows. Improved customer-facing response times from 1s+ to sub-200ms.\n‚Ä¢Optimized SQL Server queries for large-scale reporting pipelines, reducing query runtime from 24 \nhours to under 2 hours. Delivered near real-time insights for sales and support operations.\n‚Ä¢Adopted AI-enhanced workflows by piloting GitHub Copilot for concurrent test generation and \ncode refactoring. Reduced manual QA handoffs by 35% and enabled faster iteration cycles.\n‚Ä¢Partnered with DevOps to implement CI/CD pipelines in Azure DevOps, automating \nbuild/test/deploy cycles and eliminating 80% of manual deployment steps.\n‚Ä¢Designed and deployed microservices to replace monolithic ERP components, cutting service \ndowntime by 50% and enabling seamless scaling during peak loads.\n‚Ä¢Conducted training workshops on Azure cloud design, automated testing, and AI-assisted \ndevelopment, raising engineering team maturity and readiness for cloud-native projects.\n‚Ä¢Authored technical documentation on cloud migration roadmaps, APIs, and ERP integration \nstrategies, reducing onboarding time for new engineers by 30%.\n\n\n\nSkills\n\n‚Ä¢Backend & Cloud: .NET 8/9, C#, SQL Server, Entity Framework, Azure App Services, Cosmos DB, \nFunctions, AKS\n‚Ä¢AI-Enhanced Development: GitHub Copilot, Claude, AI-assisted SDLC, auto-generated test \nframeworks\n‚Ä¢Architecture & DevOps: Microservices, Azure DevOps, Docker, Kubernetes, Terraform, CI/CD \npipelines\n‚Ä¢Testing & Quality: TDD, automated testing frameworks, API testing, intelligent bug \nprediction/self-healing systems\n‚Ä¢Collaboration: Agile/SCRUM, stakeholder engagement, AI-driven specification translation, \ntechnical mentorship\n\nEducation\n\nBachelor's degree - Computer Science, Virginia Tech 2013 ‚Äì 2017\n\nLanguages\n\nEnglish Chinese\n\nProjects\n\nhttps://www.victusglobal.com/\nhttps://www.bloomberg.com/company\nhttps://foreverclaw.com\nhttps://alwaysreadyrepair.com\nhttps://clawandfun.com\nhttps://playthunderbird.com\n\nhttps://www.victusglobal.com/\nhttps://www.victusglobal.com/\nhttps://www.victusglobal.com/\nhttps://www.bloomberg.com/company\nhttps://www.bloomberg.com/company\nhttps://www.bloomberg.com/company\nhttps://foreverclaw.com/\nhttps://foreverclaw.com/\nhttps://foreverclaw.com/\nhttps://alwaysreadyrepair.com/\nhttps://alwaysreadyrepair.com/\nhttps://alwaysreadyrepair.com/\nhttps://clawandfun.com/\nhttps://clawandfun.com/\nhttps://clawandfun.com/\nhttps://playthunderbird.com/\nhttps://playthunderbird.com/\nhttps://playthunderbird.com/
2ec9bf0d-cdda-45e1-8e00-1ea593ec7cc0	Saisindhum Unknown	saisindhum16@gmail.com	Screening	Lead Software Engineer	8	Sai Sindhu\nsaisindhum16@gmail.com   ? +1(214)-301-9379\n\nPROFESSIONAL PROFILE\n\nA Lead Software Engineer with over 8 years of deep expertise in .NET, C#, and SQL Server. I am passionate about building scalable, cloud-native applications and leading Azure migration initiatives. My experience includes architecting and executing complex re-platforming and modernization of legacy systems. I operate proficiently in an AI-enhanced development lifecycle (AIDLC), leveraging generative AI tools like GitHub Copilot and Claude to translate stakeholder conversations into structured specifications and iterate on user flows and architectures. I have a proven ability to write, test, and produce production-grade code in financial services without relying on external testing teams, implementing intelligent testing frameworks that auto-generate test cases and enable self-healing. I am an excellent communicator with a strong ownership mindset, adept at mentoring junior engineers, and an expert in CI/CD pipelines and API testing. My background includes extensive experience with microservices architecture, containerization, and the entire suite of Azure cloud technologies, including AKS, Cosmos DB, App Services, and Functions, and I have a working knowledge of CNCF projects.\n\nWORK EXPERIENCE\n\nUSAA | Plano, Tx | Lead Software Engineer | May 2022 ? Present\nProject: High ? Performance Investment Platform\nDescription: I developed key features for our investment and account management platforms using Java 17 and Spring Boot 2.6 for the backend, with a React 18 front end. I designed and implemented asynchronous, event-driven microservices with Apache Kafka, which was crucial for real-time transaction processing and communication between our distributed systems. I personally integrated Kafka producers and consumers across services using Spring Boot to ensure our architecture was scalable and decoupled. I also built out middleware and API gateways using Node.js and Express.js to facilitate smooth integration with third-party financial APIs.\nResponsibilities:\n\n¬∑ Led the design, development, and deployment of enterprise-grade financial applications using .NET, C#, and SQL Server, ensuring robust and scalable solutions that meet compliance standards.\n¬∑ Architected and executed a major Azure migration strategy, including the re-platforming of legacy investment systems and the modernization of their underlying APIs to a cloud-native architecture.\n¬∑ Built and optimized new cloud-native solutions, leveraging a suite of Azure services including AKS for container orchestration, App Services for web applications, and Azure Functions for serverless workloads.\n¬∑ Operated within an AI-enhanced development lifecycle (AIDLC), translating complex stakeholder conversations into structured specifications using AI copilots and leveraging generative AI to iterate on user flows and interfaces.\n¬∑ Pair programmed with AI tools like GitHub Copilot to write, refactor, and test code in real-time, significantly increasing development velocity and ensuring high code quality from the start.\n¬∑ Wrote, tested, and produced production-grade code for financial services without relying on other teams for testing, using a TDD approach to build in quality from the ground up.\n¬∑ Implemented intelligent testing frameworks that leveraged AI to auto-generate test cases and predict bugs, ensuring a high level of code coverage and enabling a proactive, self-healing approach to defect management.\n¬∑ Leveraged code assistants to go through large legacy codebases, identify opportunities for modernization and refactoring, and make targeted changes that improved performance and maintainability.\n¬∑ Wrote automated tests concurrently with code development to ensure continuous integration and delivery, and used dedicated API testing tools to validate the functionality and performance of our backend services.\n¬∑ Mentored junior engineers on best practices in cloud engineering and AI-assisted development, promoting a culture of continuous learning and technical excellence across the team.\n¬∑ Demonstrated a strong ownership mindset by taking full responsibility for projects from concept to production, proactively identifying problems and driving solutions in a fast-paced environment.\n¬∑ Provided technical lead experience by guiding offshore teams, reviewing their work, and ensuring a consistent and high-quality output that aligned with our architectural standards.\n¬∑ Contributed to various CNCF projects by implementing open-source standards for containerization and service meshes, ensuring our solutions were interoperable and scalable.\n¬∑ Designed and built scalable microservices architectures and utilized containerization with Docker, deploying applications seamlessly with Azure DevOps and Azure Pipelines for robust CI/CD.\n¬∑ Ensured robust data management by designing and optimizing schemas in SQL Server, and implemented a data-migration pipeline to transition financial data to Cosmos DB, ensuring high availability and global distribution.\n¬∑ Collaborated with product owners, designers, and other teams to define solutions, providing clear communication and technical documentation to ensure alignment across all stakeholders.\n¬∑ Applied continuous delivery practices to ensure new features and bug fixes were delivered to production with minimal friction and risk, maintaining a high level of operational excellence.\n¬∑ Implemented caching strategies using Redis to improve application performance and reduce database load, ensuring a responsive and low-latency user experience.\n¬∑ Engineered and maintained robust integration solutions using Apache Camel and ESB patterns to connect disparate systems and applications, ensuring fault tolerance and message reliability.\n¬∑ Utilized Go and Python to develop highly efficient and scalable serverless functions, leveraging AWS Lambda and Azure Functions to handle specific business logic and integrate with other services.\n\nEdward Jones | St. Louis, MO | Senior Software Developer | June 2021 ? April 2022\nProject: AWS Migration and DevOps Automation\nDescription: I led the successful migration of over 10 enterprise modules to a cloud-native architecture on AWS, which greatly improved our system's scalability and resilience. I was hands-on in automating our deployment pipelines using Docker, Terraform, and GitHub Actions, deploying services to AWS EKS via Kubernetes. To ensure reliability, I implemented comprehensive monitoring using Prometheus, Grafana, and AWS CloudWatch, with centralized logging via the ELK Stack. I also mentored junior engineers, conducted code reviews, and championed best practices in clean code and secure software development.\nResponsibilities:\n\n¬∑ Architected and executed an Azure migration strategy, including the re-platforming and modernization of over 10 enterprise modules from on-premise to a cloud-native architecture on AWS and Azure.\n¬∑ Built and optimized cloud-native solutions by leveraging specific Azure services, including the use of App Services for hosting, Cosmos DB for global data distribution, and Azure Functions for microservices.\n¬∑ Began operating in an early-stage AI-enhanced development lifecycle (AIDLC), leveraging AI tools to assist in translating technical requirements into code and exploring new architectural patterns.\n¬∑ Pair programmed with AI tools to write, refactor, and test code, accelerating the development process and improving the overall quality of the codebase by catching potential issues early.\n¬∑ Wrote, tested, and produced production-grade code for financial services without relying on manual QA teams, implementing automated tests that ran as part of our CI/CD pipelines.\n¬∑ Implemented intelligent testing frameworks that used data-driven approaches to auto-generate test cases, significantly reducing the manual effort required for regression testing.\n¬∑ Leveraged code assistants and went through large codebases to identify opportunities for refactoring and modernization, resulting in a 30% improvement in application performance.\n¬∑ Wrote automated tests concurrently with code development to ensure continuous integration and delivery, and used a variety of tools for API testing, including Postman and custom scripts.\n¬∑ Mentored junior engineers and promoted best practices in cloud engineering, including secure coding and architectural design patterns, to ensure the team was building maintainable and resilient systems.\n¬∑ Maintained a strong ownership mindset, taking responsibility for the health and performance of systems in production and proactively addressing issues before they impacted users.\n¬∑ Applied continuous delivery practices to ensure new features and bug fixes were delivered to production with minimal friction and risk, maintaining a high level of operational excellence.\n¬∑ Gained exposure to AI/ML concepts and tools by contributing to the backend infrastructure supporting AI-driven initiatives focused on personalized investment recommendations.\n¬∑ Designed and built scalable microservices architectures using .NET and deployed them to containerization platforms like Docker, with orchestration on Kubernetes.\n¬∑ Utilized Azure DevOps for CI/CD pipelines, automating the entire software delivery lifecycle from code commit to production deployment and ensuring consistent releases.\n¬∑ Led a project to modernize legacy systems, which included migrating data from a traditional SQL Server database to a new cloud-native solution, ensuring data integrity throughout the process.\n¬∑ Collaborated with offshore teams, providing clear guidance and technical specifications, and conducted regular code reviews to ensure the quality and consistency of their work.\n¬∑ Gained familiarity with CNCF projects and their role in a modern cloud-native stack, including Service Meshes, and contributed to their adoption within the organization.\n¬∑ Implemented caching strategies using Redis to improve application performance and reduce database load, ensuring a responsive and low-latency user experience.\n¬∑ Engineered responsive, real-time UIs with Angular 13, TypeScript, and RxJS, improving interactivity and accessibility for a seamless user experience.\n\nUniversity of Houston Clear Lake| Houston, TX | Research Assistant | Sept 2020 ? May 2021\nProject: Academic Analytics Dashboard\nDescription: I collaborated with professors to design and build a full-stack academic analytics dashboard from scratch. I used Java 15 and Spring Boot to develop RESTful APIs with a MySQL database backend. For the front end, I used Angular 11 and TypeScript to create interactive data visualizations with libraries like Chart.js and D3.js. I also implemented role-based security using Spring Security and JWT to protect sensitive student and research data and used Docker for local deployment.\nResponsibilities:\n\n¬∑ Executed early-stage Azure migration strategies by setting up a proof-of-concept for a full-stack application, including deploying containerized components to AKS and using Azure App Services.\n¬∑ Developed cloud-native solutions by leveraging Azure services, including Azure Functions for specific business logic and Cosmos DB for managing and querying document data.\n¬∑ Explored an early form of the AI-enhanced development lifecycle (AIDLC) by using basic code assistants to write and refactor small code snippets, gaining initial exposure to these tools.\n¬∑ Pair programmed with AI tools to write test cases and validate code, gaining foundational experience in a new development paradigm and improving the efficiency of the project.\n¬∑ Wrote, tested, and produced production-grade code for a research application, ensuring all code was clean, maintainable, and free of bugs before deployment.\n¬∑ Wrote automated tests concurrently with code development to ensure continuous integration, and used tools like Postman to perform basic API testing on backend endpoints.\n¬∑ Leveraged code assistants to navigate and understand large codebases, helping to quickly identify opportunities for improvement and make targeted changes that were validated through testing.\n¬∑ Gained experience with automated testing and continuous delivery practices by integrating Jenkins into the CI/CD pipeline, automating the build and deployment process for the dashboard.\n¬∑ Mentored other researchers on best practices in software development and the use of modern tools, promoting a collaborative and efficient work environment.\n¬∑ Demonstrated a strong ownership mindset by taking full responsibility for the development of specific features, from design to implementation and final deployment.\n¬∑ Gained early technical lead experience by guiding and supporting a small team of researchers on the backend development of the academic dashboard.\n¬∑ Gained familiarity with CNCF projects by exploring how open-source technologies could be used to improve the project's scalability and reliability.\n¬∑ Contributed to the backend infrastructure supporting AI/ML initiatives focused on personalized learning, gaining experience in the ecosystem of LLM-based applications.\n¬∑ Designed, developed, and maintained robust web applications using ASP.NET (Web Forms or MVC) and C# to meet project requirements.\n¬∑ Built and consumed RESTful web services or Web APIs using ASP.NET to facilitate data exchange between different systems.\n¬∑ Collaborated with professors and researchers to design and develop a web-based academic analytics dashboard using Java 15, Spring Boot, and Angular 11 to track and visualize research data and student performance.\n¬∑ Developed interactive front-end components using Angular 11, TypeScript, and Bootstrap 4, and enhanced data visualization through charting libraries like Chart.js and D3.js.\n¬∑ Developed RESTful APIs using Spring MVC, Spring Data JPA, and integrated MySQL as the backend database for managing student and research project data.\n\nCreators Touch Company | Vijayawada, India | Java Developer | June 2017 - Nov 2018\nProject: System-Level Tools & Web Applications\nDescription: I collaborated with professors and graduate researchers to design and develop a web-based academic analytics dashboard using Java 15, Spring Boot, and Angular 11 to track and visualize research data and student performance. I developed modules for backend services and desktop tools in C and C++, focusing on data parsing and memory management. I also designed and maintained Java applications and built Single Page Applications using React for the front end and Node.js/Express with PostgreSQL on the back end.\nResponsibilities:\n\n¬∑ Designed, developed, and deployed backend services and APIs using .NET and C#, focusing on creating robust, reusable, and scalable components for various applications.\n¬∑ Contributed to an early-stage Azure migration proof-of-concept, exploring the re-platforming of legacy services to the cloud and gaining foundational experience with cloud-native architectures.\n¬∑ Built and optimized enterprise applications by leveraging SQL Server for data persistence and designing highly efficient database schemas to improve query performance.\n¬∑ Wrote, tested, and produced production-grade code for backend services, ensuring all code met high standards for quality and was thoroughly tested before deployment.\n¬∑ Wrote automated tests concurrently with code development, including unit and integration tests, to ensure continuous quality and support a robust CI/CD pipeline.\n¬∑ Contributed to the development of a CI/CD pipeline using Jenkins to automate builds and deployments, streamlining the development process and improving efficiency.\n¬∑ Implemented intelligent testing frameworks using custom scripts to perform API testing, ensuring the reliability and functionality of our backend services.\n¬∑ Mentored junior developers on best practices in .NET and C# development, providing technical guidance and conducting code reviews to ensure a high standard of quality.\n¬∑ Gained experience with containerization using Docker, packaging applications and their dependencies to ensure consistent environments across development and production.\n¬∑ Demonstrated an ownership mindset by taking responsibility for the full software development lifecycle of specific modules, from initial design to final deployment and support.\n¬∑ Contributed to the design and development of scalable backend services and APIs using C# and .NET frameworks, focusing on modularity and reusability for various applications.\n¬∑ Implemented RESTful services with ASP.NET Web API to support full-stack applications, handling data exchange between the front end and backend with JSON and XML.\n¬∑ Designed and developed web interfaces using front-end frameworks like React and Angular, focusing on creating responsive and user-friendly designs that met project requirements.\n¬∑ Applied security best practices, including implementing role-based access control and OAuth2, to protect against common vulnerabilities and ensure data integrity.\n¬∑ Worked with SQL and NoSQL databases to design data storage solutions for different applications, ensuring data was accessible, secure, and performant.\n¬∑ Utilized Git for version control and a ticketing system similar to Jira for project management, ensuring an organized and collaborative development workflow.\n¬∑ Designed and built APIs that consumed and produced JSON or XML data for communication between microservices or with client applications.\n¬∑ Contributed to the quality assurance of APIs and integrations through comprehensive unit, functional, and non-functional testing.\n\nTata Consultancy Services| Hyderabad, India | Associate System Engineer | April 2015 - May 2017\nProject: Smart Waste Automation & Infrastructure Modernization\nDescription: TCS collaborated with a global sustainability and infrastructure partner to modernize its waste management systems using robotics, automation, and cloud-native solutions. The initiative aimed to improve operational efficiency, data visibility, and environmental sustainability through intelligent infrastructure and CI/CD automation.\nResponsibilities:\n\n¬∑ Contributed to the development and maintenance of scalable applications using .NET and C#, focusing on optimizing performance for high-volume data processing.\n¬∑ Explored early forms of the AI-enhanced development lifecycle (AIDLC) by using internal tools to assist in code generation and bug prediction.\n¬∑ Wrote automated tests concurrently with code development to support a CI/CD pipeline, ensuring continuous quality and reliability.\n¬∑ Gained foundational experience with Azure services by deploying test applications to Azure App Services, ensuring a basic understanding of cloud-native deployment models.\n¬∑ Contributed to the design of database schemas in SQL Server, focusing on data integrity and creating efficient models for analytics and reporting.\n¬∑ Provided technical guidance to junior developers on best practices for .NET and C# development, focusing on clean code and robust design.\n¬∑ Demonstrated a strong ownership mindset by taking responsibility for the quality and delivery of my work, proactively addressing issues and seeking solutions.\n¬∑ Implemented basic automated testing using a custom tool, gaining foundational experience with API testing to validate backend services before they went to production.\n¬∑ Worked with CI/CD pipelines, version control, and deployment automation tools like Jenkins to ensure smooth and efficient delivery of software updates to production.\n¬∑ Developed responsive web interfaces with modern front-end technologies including HTML, CSS, and JavaScript (ES6+), integrating with backend services via RESTful APIs.\n¬∑ Supported systems to ensure high availability and reliability, performing regular monitoring and maintenance to prevent and quickly resolve any potential issues.\n¬∑ Designed API layers and data storage solutions using a combination of SQL and NoSQL databases, including PostgreSQL and MongoDB, to meet diverse application requirements.\n¬∑ Provided peer feedback through code reviews to maintain code quality and consistency across the team, and contributed to knowledge sharing through documentation and team meetings.\n¬∑ Implemented security best practices, including basic security configurations and access control (RBAC, OAuth2, JWT), to protect sensitive data and ensure system integrity.\n¬∑ Collaborated cross-functionally with hardware engineers, data scientists, and sustainability teams to build robotics-driven solutions aimed at automating waste sorting and recycling.\n¬∑ Designed, developed, and maintained realistic and scalable load test scripts using Apache JMeter to ensure application performance under heavy load.\n¬∑ Developed and maintained cross-platform mobile applications using React Native and Expo, ensuring a consistent user experience across iOS and Android.\n¬∑ Performed tasks related to the deployment, maintenance, and optimization of NoSQL database clusters to ensure they remained performant and reliable.\n¬∑ Contributed to the backend infrastructure supporting AI/ML initiatives focused on personalized investment recommendations, gaining experience in the ecosystem of LLM-based applications.\n\nCORE COMPETENCIES\n\nLanguages & Scripting: C#, .NET, C++, Java (8-21), Python, JavaScript/TypeScript, SQL, Bash/Shell, Node.js\nFrameworks & Libraries: .NET Core, ASP.NET Core, Spring Boot/Security, jQuery, Hibernate, React, Angular, Struts, JSF\nCloud & DevOps: Azure (AKS, Cosmos DB, App Services, Functions), Azure DevOps, AWS (EC2, S3, EKS), Docker, Kubernetes, Terraform, GitHub Actions, Jenkins, CNCF\nData & Messaging: SQL Server, PostgreSQL, MySQL, NoSQL, MongoDB, Redis, Snowflake, Kafka, RabbitMQ\nTesting & Monitoring: API testing tools, JUnit 5, Mockito, Cypress, Jest, Prometheus, Grafana, ELK, SonarQube, intelligent testing frameworks\nMethodologies: AIDLC, Agile/Scrum, CI/CD pipelines, TDD, Micro-services architecture, Ownership Mindset\nAI Tools: GitHub Copilot, Claude, Code assistants\nOperating Systems: Windows, Linux, Unix\n\nEDUCATION\nBachelor of Technology in Information Technology\t\t\t\t\t\tMay 2017\n\tJawaharlal Nehru Technological University (JNTU), Kakinada, AP, India\nMaster?s Degree in Computer Science                                                                                                             May 2021\n             University of Houston Clearlake, Houston, TX
fc10d2b8-fcc1-4e86-bf8b-ba1f3cfe83dc	Stephensamuels Unknown	Stephensamuels1014@gmail.com	Screening	Senior Software Engineer	12	Stephen Samuels\nSenior Software Engineer with 11 years of proven experience\n\n+1 \n\nExperienced Lead Product Engineer with over 11 years in software development, specializing in .NET, C#, and Azure cloud technologies. Proven ability to design scalable cloud-native applications while leading dynamic teams and implementing AI-enhanced development practices.\n\nEDUCATION\n\nUniversity of Southern California,¬†Los Angeles, CA ‚Äì Bachelor‚Äôs Degree in Computer Science\n\nSep 2008 - May 2012\n\nSKILLS\n\n¬∑ Programming Languages : C#, JavaScript, Python, SQL, HTML/CSS\n¬∑ Frameworks : ASP.NET Core, Entity Framework, React, Angular, Node.js\n¬∑ Cloud Technologies : Azure, AWS, Google Cloud Platform, Azure Functions, Azure App Services\n¬∑ Databases : SQL Server, Azure Cosmos DB, PostgreSQL, MongoDB, ElasticSearch\n¬∑ Development Tools : GitHub, Docker, Kubernetes, Azure DevOps, Jenkins\n¬∑ Testing & Automation : JUnit, Selenium, Mocha, Chai, Postman\nEXPERIENCE \nSenior Software Engineer\t\t\t\t\t\t\t          \t       Feb 2021 ‚Äì Present\nBP3 Global | Austin, TX\t\t\n\t\t\t\t\t                                          \n¬∑ Led the design and development of enterprise-grade applications utilizing .NET and C#, focusing on performance optimization and code quality across multiple projects within the cloud services sector.\n¬∑ Architected robust Azure migration strategies that facilitated the modernization of legacy systems, significantly improving scalability and operational efficiency for several high-traffic applications.\n¬∑ Developed cloud-native solutions leveraging Azure services such as AKS and Cosmos DB, enabling seamless data flow and real-time analytics for enhanced user experiences and business insights.\n¬∑ Implemented an AI-driven development lifecycle, collaborating with generative AI tools to enhance user flows and interfaces, which streamlined the development process and reduced time-to-market.\n¬∑ Regularly pair-programmed using AI coding assistants like GitHub Copilot, maximizing productivity and code accuracy by receiving real-time suggestions during coding sessions for various projects.\n¬∑ Designed intelligent testing frameworks capable of auto-generating test cases and predicting potential bugs, significantly reducing the time spent on manual testing processes.\n¬∑ Cultivated a continuous integration and delivery pipeline that automated testing and deployment processes, ensuring high-quality deliverables were consistently produced without downtime.\n¬∑ Mentored junior engineers, fostering a collaborative environment that emphasized best practices in cloud engineering, and promoting a culture of innovation and continuous learning within the team.\n¬∑ Conducted code reviews and provided constructive feedback that improved the overall code quality, ensuring coding standards were maintained across all development projects.\n¬∑ Utilized Agile methodologies to manage project workflows effectively, adapting to changing project requirements and ensuring timely delivery of high-impact solutions.\n¬∑ Collaborated cross-functionally with product managers and stakeholders to translate high-level ideas into structured technical specifications, enhancing understanding and alignment across teams.\n¬∑ Participated in the evaluation and integration of AI tools into the software development lifecycle, paving the way for innovative solutions and improved project outcomes.\n¬∑ Led initiatives to establish coding standards and guidelines that were adopted across the team, successfully increasing coding efficiency and maintainability of enterprise applications.\n\nFull Stack Developer   \t\t\t\t\t\t\t\t       Jul 2016 ‚Äì Sep 2020\nOpendoor | San Francisco, CA\n\n¬∑ Developed fullstack applications for a real estate platform utilizing .NET, C#, and SQL Server, ensuring seamless integration between front-end and back-end functionalities.\n¬∑ Implemented responsive user interfaces using React and Angular, enhancing user engagement through dynamic and interactive design tailored to client needs.\n¬∑ Collaborated with UX/UI designers to create user-centric features that optimized the property searching experience for end-users, focusing on usability and responsiveness across devices.\n¬∑ Utilized Azure DevOps for continuous integration and deployment processes, streamlining workflows and enhancing team collaboration through effective project management and version control.\n¬∑ Conducted thorough unit testing and implemented automated testing strategies using Selenium and Mocha, resulting in improved code reliability and quicker release cycles for web applications.\n¬∑ Managed database design and optimization tasks on SQL Server, ensuring efficient data storage and retrieval processes that supported high-volume transaction scenarios.\n¬∑ Participated in code reviews and maintained coding standards, providing insights that led to better software design and functionality across development teams.\n¬∑ Facilitated Agile scrum meetings and sprint planning sessions, driving team cohesion and ensuring alignment on project goals and timelines for multiple release cycles.\n¬∑ Enhanced application security by implementing best practices for data handling and protection, aligning with compliance standards in the real estate industry.\n¬∑ Worked closely with cross-functional teams to define product features and ensure solutions met market demands and technical feasibility.\n\nSoftware Developer\t\t\t\t\t\t\t\t                     Feb 2013 ‚Äì Jun 2016\nAthenahealth | Austin, TX\n\n¬∑ Designed and developed healthcare applications in .NET that improved patient data management and streamlined communication between healthcare professionals and patients while enhancing system security protocols.\n¬∑ Collaborated with medical staff to gather requirements and translate them into scalable software solutions, ensuring alignment with industry regulations and standards.\n¬∑ Implemented SQL Server databases to manage patient and service data effectively, facilitating rapid access and reporting capabilities necessary for healthcare operations.\n¬∑ Developed user-friendly web applications using ASP.NET Core and JavaScript, ensuring accessibility and compliance with healthcare standards, leading to increased user adoption.\n¬∑ Conducted testing and debugging of applications using cutting-edge tools to ensure a high quality of code and adherence to sophisticated healthcare requirements.\n¬∑ Trained and mentored junior developers in the adoption and implementation of best practices for healthcare software development, enhancing the overall skillset of the team.\n¬∑ Engaged in continuous improvements of software development processes leading to faster delivery times and more reliable software outputs by incorporating feedback from health professionals.\n¬∑ Successfully contributed to multiple projects, delivering enhancements that resulted in better patient outcomes and increased overall efficiency in healthcare services, benefiting thousands of users.
e4ccd924-f355-483a-866d-9ee749521869	Walcottj Unknown	walcottj282@gmail.com	Screening	Lead Software Engineer	15	Jason Walcott            Senior Software Engineer \n170 SAMPSON CT, Covington, GA \n\n+1 912 521 4570 \n\nwalcottj282@gmail.com \n\nSummary \n\nAccomplished Lead Software Engineer with 15+ years of experience building enterprise-grade, cloud-native applications using \n\n.NET, C#, and SQL Server. Proven expertise in Azure migration strategies, microservices, and containerized solutions with AKS, \n\nCosmos DB, and App Services. Adept at working in AI-driven SDLC environments, leveraging GitHub Copilot, Claude, and AI \n\ncopilots to accelerate development, testing, and deployment. Skilled in automated testing frameworks, CI/CD pipelines, and Agile \n\nleadership with a strong track record of mentoring engineers and modernizing legacy systems. Passionate about delivering secure, \n\nscalable, and innovative solutions in fast-paced environments. \n\nSkills \n\nBackend & Cloud: .NET, ASP.NET Core, C#, SQL Server, PostgreSQL, MySQL, Entity Framework, Cosmos DB, Azure \n\n(Functions, App Services, Blob Storage, AKS), AWS (Lambda, EC2, S3, SQS, CloudWatch), Microservices, Containerization, \n\nDocker, Kubernetes, CNCF Projects, Infrastructure-as-Code \n\nAI & Automation: GitHub Copilot, Claude, AI copilots, AIDLC (AI-driven SDLC), Automated Testing, Intelligent Testing \n\nFrameworks, TDD, Self-healing Pipelines \n\nFrontend: React.js, Angular, Vue.js, Blazor, Maui, JavaScript, TypeScript, HTML5, CSS3, Responsive Design \n\nDevOps & Tools: Azure DevOps, GitHub, CI/CD Pipelines, JIRA, Postman, Swagger (OpenAPI), PowerShell, Python, Kafka, \n\nRedis \n\nData & BI: Data Modeling, Stored Procedures, Performance Tuning, Talend, Power BI, SSIS \n\nOther: Secure Coding, Cloud Migration, System Modernization, Agile Methodologies, Leadership, Mentorship, Workflow \n\nStandards, AI/ML Concepts \n\nExperience \n\nMAY 2019 - AUG 2025 \n\nVeritis, Irving, TX - Lead Software Engineer \n\n‚óè Led the design, development, and deployment of cloud-native enterprise applications using .NET, C#, and SQL \n\nServer. \n\n‚óè Architected and executed Azure migration strategies, including re-platforming and modernization of legacy \n\nsystems. \n\n‚óè Built and optimized microservices architectures leveraging Azure AKS, Cosmos DB, Functions, and App Services. \n\n‚óè Applied AI-driven SDLC (AIDLC) by pairing with GitHub Copilot, Claude, and AI copilots to design user flows, write, \n\nand refactor production code. \n\n‚óè Implemented intelligent testing frameworks, including automated test case generation, bug prediction, and \n\nself-healing pipelines. \n\nmailto:walcottj282@gmail.com\n\n\n‚óè Designed API-first architectures, enabling secure integrations and high-performance data flows across systems. \n\n‚óè Guided junior engineers, promoting best practices in AI-assisted development, TDD, and CI/CD pipelines. \n\n‚óè Partnered with cross-functional teams to deliver real-time financial dashboards and interactive BI tools. \n\n‚óè Produced technical documentation and architecture standards to ensure scalable solutions across teams. \n\n‚óè Troubleshot complex production issues with data triage, logs analysis, and rapid defect resolution. \n\nJAN 2015 - APR 2019 \n\nVector Choice, Duluth , GA - Software Developer (Backend) \n\n‚óè Developed API-driven services in .NET Core, GraphQL, and REST, supporting enterprise-scale platforms. \n\n‚óè Supported cloud-native initiatives with SQL Server and PostgreSQL optimizations for scalability. \n\n‚óè Built automation scripts in PowerShell and Python to improve deployment and data transformation. \n\n‚óè Collaborated on containerized deployments and microservices migration projects. \n\n‚óè Integrated AI-assisted development tools to accelerate coding, refactoring, and testing workflows. \n\n‚óè Created data models, stored procedures, and performance-tuned queries, ensuring database reliability. \n\n‚óè Partnered with QA teams to implement test automation frameworks with Cypress, NUnit, and Jest. \n\n‚óè Documented architectural patterns, deployment guides, and integration standards. \n\n‚óè Actively contributed in Agile sprints, including planning, code reviews, and retrospectives. \n\nFEB 2010  - DEC 2014 \n\nArium, Atlanta, GA- .NET Application Developer \n\n‚óè Migrated legacy applications into ASP.NET MVC while maintaining interoperability with VB.NET systems. \n\n‚óè Designed SOAP and WCF services to support integrations with HR and payroll platforms. \n\n‚óè Developed automation and ETL pipelines with PowerShell, PL/SQL, and T-SQL for data cleansing and migration. \n\n‚óè Built and optimized hybrid databases in SQL Server, Oracle, and MongoDB. \n\n‚óè Partnered with teams to design modular APIs and re-usable data components. \n\n‚óè Supported cloud adoption initiatives with AWS S3, IAM, and lifecycle management. \n\n‚óè Delivered secure coding solutions and applied data protection best practices across applications. \n\n‚óè Provided client-facing support with requirements gathering, solution delivery, and training. \n\n‚óè Authored technical documentation and workflow processes for consistent standards. \n\nEducation \n\nSEP  2005 - MAY 2009 \n\nGeorgia State University, Atlanta, GA - Bachelor of Computer Science \n \n \n\n\n\tJason Walcott            Senior Software Engineer \n\tSummary \n\tSkills \n\tExperience \n\tMAY 2019 - AUG 2025 \n\tVeritis, Irving, TX - Lead Software Engineer \n\n\tJAN 2015 - APR 2019 \n\tVector Choice, Duluth , GA - Software Developer (Backend) \n\n\tFEB 2010  - DEC 2014 \n\tArium, Atlanta, GA- .NET Application Developer \n\n\n\tEducation \n\tSEP  2005 - MAY 2009 \n\tGeorgia State University, Atlanta, GA - Bachelor of Computer Science
311c36d7-c8e2-4c76-b01f-3b1f258cce9f	Zherenyang Unknown	zherenyang0125@outlook.com	Screening	Lead Software Engineer	18	Zheren Yang\nzherenyang0125@outlook.com | (315) 202-2996 | | www.linkedin.com/in/yang-z-2545625\n\nPROFESSIONAL SUMMARY\n\nAccomplished software engineer with over 10 years of experience delivering scalable, enterprise-grade\n\napplications with a strong focus on .NET, C#, and SQL Server. Proven expertise in leading Azure cloud migration\n\nprojects and building cloud-native applications leveraging diverse Azure services. Skilled at thriving in dynamic, AI-\n\nenhanced software development lifecycles through effective collaboration with cross-functional teams and AI\n\ntools like GitHub Copilot. Adept at driving delivery excellence, mentoring engineers, and enforcing best practices\n\nin automated testing, TDD, and CI/CD pipelines. Highly adaptable, combining technical leadership with a passion\n\nfor innovation in financial and federal service domains.\n\nSKILLS\n\nProgramming Languages\n\n.NET C# SQL T-SQL PL/SQL JavaScript TypeScript Python PowerShell Bash Java\n\nFrameworks & Libraries\n\n.NET Framework .NET Core Entity Framework ASP.NET ASP.NET Core Azure Functions Microservices\n\nDocker Kubernetes xUnit MSTest Moq NUnit REST APIs gRPC\n\nTools & Platforms\n\nAzure DevOps GitHub Copilot Claude AI Visual Studio Azure Portal AKS Azure App Services\n\nAzure Cosmos DB Azure Functions Azure Logic Apps Azure Monitor Azure Security Center Azure Key Vault\n\nAzure API Management Jenkins Terraform Ansible Helm Prometheus Grafana SonarQube Selenium\n\nPostman JIRA Confluence Git\n\nDatabases\n\nSQL Server Azure Cosmos DB MySQL Oracle PostgreSQL Redis MongoDB Cassandra DB2\n\nSQLite\n\nDevOps & CI/CD\n\nAzure DevOps Pipelines Jenkins GitHub Actions Terraform Ansible Docker Kubernetes Helm\n\nPrometheus SonarQube\n\n\n\nOther Skills\n\nAgile Methodologies Scrum TDD BDD AI-assisted development Generative AI Machine Learning\n\nAutomated Testing Frameworks Microservices Architecture Containerization Cloud Migration Strategies\n\nAPI Testing Security Best Practices Edge Computing IoT Sensor Orchestration Compliance Monitoring\n\nCode Refactoring Pair Programming Performance Optimization Scalability Mentorship\n\nCross-Functional Collaboration Stakeholder Communication Risk Management Regulatory Compliance\n\nPerformance Tuning\n\nCERTIFICATIONS\n\nMicrosoft Certified: Azure Solutions Architect Expert Microsoft Certified: Azure Developer Associate\n\nMicrosoft Certified: Azure DevOps Engineer Expert Microsoft Certified: Azure Fundamentals\n\nWORK EXPERIENCE\n\nLead Software Engineer ‚Äì Cloud and AI-Enhanced Development\n\nAccenture Federal Services\n\n07/2021 - Present\n\nDelivered scalable enterprise applications using .NET, C#, and SQL Server within a complex federal mission\n\ncontext, incorporating advanced Azure cloud services such as Azure Cosmos DB and Azure Functions to\n\nenhance platform resilience and scalability.\n\nLed the design and execution of Azure migration strategies on the FedGenius AI platform, leveraging Azure\n\nKubernetes Service (AKS), Azure App Services, and Azure DevOps pipeline automation to achieve smooth\n\nmodernization of legacy systems.\n\nCollaborated with cross-functional teams and AI copilots like GitHub Copilot and Claude to accelerate iterative\n\ndevelopment, ensuring delivery of high-quality code while enabling effective pairing on cloud-native\n\narchitectures.\n\nArchitected intelligent testing frameworks using xUnit and Selenium that generate automated test cases and\n\nsupport predictive bug detection within a continuously integrated deployment pipeline using Azure DevOps.\n\nMentored junior engineers in adopting TDD, CI/CD best practices, and AI-assisted development tools, driving a\n\nculture of delivery excellence and automated quality assurance.\n\nImplemented secure, compliant data architectures leveraging Azure Key Vault and Azure Security Center to\n\nmeet stringent federal cybersecurity standards while integrating edge-to-cloud IoT sensor orchestration.\n\nExecuted code base-wide refactoring initiatives enabled by AI assistance to optimize for performance and\n\nscalability, reducing system latency and improving transaction throughput for over 100 federal agencies.\n\n\n\nDeveloped RESTful and gRPC APIs to facilitate seamless integration between AI-driven decision modules and\n\nlegacy government systems with C# microservices deployed in Docker containers orchestrated by Kubernetes.\n\nAutomated complex compliance monitoring workflows with Azure Logic Apps and integrated real-time\n\noperational dashboards using Azure Monitor and Grafana for proactive system health insights.\n\nSpearheaded adoption of container orchestration patterns and implemented Helm charts for consistent\n\nenvironment provisioning and streamlined DevOps workflows.\n\nCoordinated threat modeling and built cyber defense mechanisms detecting and blocking attacks using cloud-\n\nnative tools and customized AI models in the FedGenius platform.\n\nLed architecture reviews and AI-driven system design sessions translating stakeholder requirements into\n\nmaintainable and extensible technical specifications.\n\nOversaw continuous deployment cycles using Azure DevOps Pipelines integrated with automated testing suites\n\nensuring zero-downtime releases and high availability.\n\nCollaborated with AI teams to embed generative AI capabilities in service centers aiming for intelligent\n\nautomation of client service operations.\n\nDesigned data models optimized for high throughput and low latency in SQL Server and Azure Cosmos DB,\n\nmapping complex federal compliance requirements efficiently.\n\nImplemented robust API gateways and usage analytics using Azure API Management, enhancing security and\n\nusage insights.\n\nIntegrated self-healing mechanisms and service health monitoring driven by AI tools to reduce manual\n\nintervention and accelerate incident response.\n\nFostered a culture of innovation by aligning agile methodologies with AI-enhanced workflows promoting rapid\n\nprototyping and iterative delivery.\n\nDeveloped infrastructure as code leveraging Terraform and Ansible to provision Azure resources reproducibly\n\nacross multiple environments.\n\nEngaged in proactive knowledge sharing and technical writing, documenting cloud architectures, migration\n\nstrategies, and AI integration processes for internal teams.\n\nSoftware Engineer\n\nSICPA\n\n09/2010 - 01/2021\n\nEngineered secure and scalable applications utilizing .NET, C#, and SQL Server as part of the SICPATRACE¬Æ\n\nplatform, integrating real-time authentication and traceability systems enhanced by embedded molecular\n\nmarker data.\n\nLed modernization efforts by migrating legacy tracking systems toward cloud-native architectures on Azure\n\nwith containerized components deployed via Kubernetes and managed through Azure DevOps.\n\nCollaborated with AI developers integrating generative AI techniques to improve authentication workflows and\n\npredict counterfeit risks using AI-assisted analysis tools.\n\nDeveloped comprehensive automated testing infrastructure leveraging MSTest and Postman API tests executed\n\nwithin continuous integration pipelines to ensure robust system integrity and compliance.\n\n\n\nArchitected microservices-based APIs to enable seamless cross-border data sharing, utilizing Azure Functions\n\nand Azure Cosmos DB for low-latency distributed data processing.\n\nEmployed advanced SQL Server design patterns for efficient storage and retrieval of large volumes of\n\ntraceability data aligned with global regulatory standards.\n\nIntegrated secure cloud identity and access management configurations using Azure Active Directory and\n\nAzure Key Vault to protect sensitive product authentication data.\n\nSupported container orchestration and service discovery through Helm charts and Prometheus monitoring,\n\nenhancing platform resilience and observability.\n\nParticipated in agile sprints adopting AI-assisted code generation tools to accelerate feature delivery and\n\nmaintain high code quality across distributed offshore teams.\n\nImplemented real-time data capture mechanisms interfacing with IoT sensors, processing telemetry and\n\nauthentication data flows across Azure Event Hub pipelines.\n\nFacilitated cloud migration readiness assessments and devised phased migration roadmaps transforming\n\nmonolithic systems into modular microservices suitable for cloud deployment.\n\nDesigned and executed secure API gateways with Azure API Management enforcing strict access controls and\n\nanalytics for traceability data consumption.\n\nDeveloped client-facing portals using ASP.NET Core integrated with Azure services to provide transparent real-\n\ntime tracking and compliance dashboards.\n\nSupported performance tuning of SQL Server databases and caching strategies optimizing system\n\nresponsiveness for field authentication devices worldwide.\n\nIntegrated AI-powered testing frameworks automating regression and performance tests, enabling continuous\n\ndelivery with minimal manual intervention.\n\nWorked extensively on CI/CD pipelines using Azure DevOps Pipelines and Git for version control, ensuring\n\nconsistent and repeatable build and release cycles.\n\nCollaborated with cybersecurity teams implementing multi-layered security controls leveraging Azure Security\n\nCenter and custom threat detection algorithms.\n\nMentored junior engineers on modern development practices including Test Driven Development,\n\ncontainerization, and Azure cloud service deployment patterns.\n\nChampioned the use of AI copilots and generative AI in software design sessions, allowing faster iteration on\n\narchitecture and user interface flows.\n\nDocumented system architecture, compliance features, and migration strategies to facilitate knowledge transfer\n\nand ongoing maintenance by global teams.\n\nDatabase Developer\n\nRegistrar Corp\n\n01/2007 - 09/2010\n\nDeveloped robust database solutions primarily using SQL Server and T-SQL within the ComplyHub‚Ñ¢ FDA\n\nCompliance Management platform supporting data integrity and regulatory compliance tracking.\n\n\n\nDesigned complex stored procedures, views, and functions driving automated workflows for FDA registration\n\nrenewals and regulatory status monitoring.\n\nCollaborated closely with software engineers utilizing .NET and C# to integrate database layers with front-end\n\napplications and reporting tools.\n\nOptimized database performance through indexing strategies, query tuning, and partitioning to support high\n\ntransaction volumes across distributed geographies.\n\nContributed to the migration of legacy data repositories toward cloud-hosted solutions with initial exploratory\n\nAWS and Azure database services evaluations.\n\nImplemented database backup and disaster recovery procedures aligning with industry best practices and\n\nregulatory requirements.\n\nDeveloped SQL Server Integration Services (SSIS) packages for data import/export automations accelerating\n\ndata synchronization processes.\n\nAutomated data quality validation and error reporting through stored procedures and custom scripts, improving\n\ndata accuracy and compliance readiness.\n\nPartnered with DevOps teams to build scripts and database deployment pipelines integrated in Jenkins-based\n\nCI/CD workflows for controlled rollouts.\n\nEnhanced data security by implementing role-based access controls and encryption mechanisms compliant with\n\nFDA guidance.\n\nParticipated in cross-functional agile teams applying TDD and continuous integration principles to database\n\nschema updates and refactoring tasks.\n\nAssisted in the development of monitoring dashboards using SQL Reporting Services and Power BI for real-time\n\ncompliance status visualization.\n\nResolved production database issues and supported incident response protocols minimizing downtime and data\n\nloss risks.\n\nCreated detailed technical documentation for database structures, ETL processes, and integration points for\n\nfuture reference and audits.\n\nCollaborated with QA teams automating database regression tests as part of broader automated testing\n\nstrategies using SQL unit testing frameworks.\n\nProvided mentorship and training to junior DBAs and developers on SQL best practices and performance\n\noptimization techniques.\n\nWorked with stakeholders to translate compliance regulations into technical database requirements and\n\nvalidation rules.\n\nParticipated in standards committees recommending governance for data access, modifications, and auditing\n\npractices within FDA-regulated environments.\n\nLed initiatives to incorporate AI-assisted query optimization and predictive analytics for proactive compliance\n\nrisk assessment.\n\nEngaged in continuous learning and certification efforts focusing on cloud migration readiness, database\n\nsecurity, and advanced SQL Server features.\n\n\n\nEDUCATION\n\nMaster's Degree in Computer Science, Old Dominion University, 2004
